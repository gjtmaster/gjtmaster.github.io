<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="心有多大，舞台就有多大！"><title>kafka生产者Producer参数设置及调优 | Joker's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">kafka生产者Producer参数设置及调优</h1><a id="logo" href="/.">Joker's Blog</a><p class="description">高金涛</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">kafka生产者Producer参数设置及调优</h1><div class="post-meta">Sep 3, 2018<span> | </span><span class="category"><a href="/categories/消息中间件/">消息中间件</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer核心工作流程"><span class="toc-number">1.</span> <span class="toc-text">Producer核心工作流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#producer-主要参数设置"><span class="toc-number">2.</span> <span class="toc-text">producer 主要参数设置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#producer-参数acks-设置（无数据丢失）"><span class="toc-number">2.1.</span> <span class="toc-text">producer 参数acks 设置（无数据丢失）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#producer参数-buffer-memory-设置（吞吐量）"><span class="toc-number">2.2.</span> <span class="toc-text">producer参数 buffer.memory 设置（吞吐量）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#producer参数-compression-type-设置（lZ4）"><span class="toc-number">2.3.</span> <span class="toc-text">producer参数 compression.type 设置（lZ4）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#producer参数-retries设置-注意消息乱序-EOS"><span class="toc-number">2.4.</span> <span class="toc-text">producer参数 retries设置(注意消息乱序,EOS)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#producer参数batch-size设置-吞吐量和延时性能"><span class="toc-number">2.5.</span> <span class="toc-text">producer参数batch.size设置(吞吐量和延时性能)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#producer参数linger-ms设置-吞吐量和延时性能"><span class="toc-number">2.6.</span> <span class="toc-text">producer参数linger.ms设置(吞吐量和延时性能)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#producer参数max-in-flight-requests-per-connection设置-吞吐量和延时性能"><span class="toc-number">2.7.</span> <span class="toc-text">producer参数max.in.flight.requests.per.connection设置(吞吐量和延时性能)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Java客户端"><span class="toc-number">3.</span> <span class="toc-text">Java客户端</span></a></li></ol></div></div><div class="post-content"><h2 id="Producer核心工作流程"><a href="#Producer核心工作流程" class="headerlink" title="Producer核心工作流程"></a>Producer核心工作流程</h2><ul>
<li>Producer首先使用用户主线程将待发送的消息封装进一个ProducerRecord类实例中。</li>
<li>进行序列化后，发送给Partioner，由Partioner确定目标分区后，发送到Producer程序中的一块内存缓冲区中。</li>
<li>Producer的另一个工作线程（即Sender线程），则负责实时地从该缓冲区中提取出准备好的消息封装到一个批次，统一发送给对应的broker中。</li>
</ul>
<h2 id="producer-主要参数设置"><a href="#producer-主要参数设置" class="headerlink" title="producer 主要参数设置"></a>producer 主要参数设置</h2><h3 id="producer-参数acks-设置（无数据丢失）"><a href="#producer-参数acks-设置（无数据丢失）" class="headerlink" title="producer 参数acks 设置（无数据丢失）"></a>producer 参数acks 设置（无数据丢失）</h3><p>在消息被认为是“已提交”之前，producer需要leader确认的produce请求的应答数。该参数用于控制消息的持久性，目前提供了3个取值：</p>
<p>acks = 0: 表示produce请求立即返回，不需要等待leader的任何确认。这种方案有最高的吞吐率，但是不保证消息是否真的发送成功。</p>
<p>acks = -1: 表示分区leader必须等待消息被成功写入到所有的ISR副本(同步副本)中才认为produce请求成功。这种方案提供最高的消息持久性保证，但是理论上吞吐率也是最差的。</p>
<p>acks = 1: 表示leader副本必须应答此produce请求并写入消息到本地日志，之后produce请求被认为成功。如果此时leader副本应答请求之后挂掉了，消息会丢失。这是个较好的方案，提供了不错的持久性保证和吞吐。</p>
<p><strong>商业环境推荐：</strong></p>
<p>如果要较高的持久性要求以及无数据丢失的需求，设置acks = -1。其他情况下设置acks = 1</p>
<h3 id="producer参数-buffer-memory-设置（吞吐量）"><a href="#producer参数-buffer-memory-设置（吞吐量）" class="headerlink" title="producer参数 buffer.memory 设置（吞吐量）"></a>producer参数 buffer.memory 设置（吞吐量）</h3><p>该参数用于指定Producer端用于缓存消息的缓冲区大小，单位为字节，默认值为：33554432合计为32M。kafka采用的是异步发送的消息架构，prducer启动时会首先创建一块内存缓冲区用于保存待发送的消息，然后由一个专属线程负责从缓冲区读取消息进行真正的发送。</p>
<p><strong>商业环境推荐：</strong></p>
<ul>
<li>消息持续发送过程中，当缓冲区被填满后，producer立即进入阻塞状态直到空闲内存被释放出来，这段时间不能超过max.blocks.ms设置的值，一旦超过，producer则会抛出TimeoutException 异常，因为Producer是线程安全的，若一直报TimeoutException，需要考虑调高buffer.memory 了。</li>
<li>用户在使用多个线程共享kafka producer时，很容易把 buffer.memory 打满。</li>
</ul>
<h3 id="producer参数-compression-type-设置（lZ4）"><a href="#producer参数-compression-type-设置（lZ4）" class="headerlink" title="producer参数 compression.type 设置（lZ4）"></a>producer参数 compression.type 设置（lZ4）</h3><p>producer压缩器，目前支持none（不压缩），gzip，snappy和lz4。</p>
<p><strong>商业环境推荐：</strong></p>
<p>基于公司的大数据平台，试验过目前lz4的效果最好。当然2016年8月，FaceBook开源了Ztandard。官网测试： Ztandard压缩率为2.8，snappy为2.091，LZ4 为2.101 。</p>
<h3 id="producer参数-retries设置-注意消息乱序-EOS"><a href="#producer参数-retries设置-注意消息乱序-EOS" class="headerlink" title="producer参数 retries设置(注意消息乱序,EOS)"></a>producer参数 retries设置(注意消息乱序,EOS)</h3><p>producer重试的次数设置。重试时producer会重新发送之前由于瞬时原因出现失败的消息。瞬时失败的原因可能包括：元数据信息失效、副本数量不足、超时、位移越界或未知分区等。倘若设置了retries &gt; 0，那么这些情况下producer会尝试重试。</p>
<p><strong>商业环境推荐：</strong></p>
<ul>
<li>producer还有个参数：max.in.flight.requests.per.connection。如果设置该参数大约1，那么设置retries就有可能造成发送消息的乱序。</li>
<li>版本为0.11.0.1的kafka已经支持”精确到一次的语义”，因此消息的重试不会造成消息的重复发送。</li>
</ul>
<h3 id="producer参数batch-size设置-吞吐量和延时性能"><a href="#producer参数batch-size设置-吞吐量和延时性能" class="headerlink" title="producer参数batch.size设置(吞吐量和延时性能)"></a>producer参数batch.size设置(吞吐量和延时性能)</h3><p>producer都是按照batch进行发送的，因此batch大小的选择对于producer性能至关重要。producer会把发往同一分区的多条消息封装进一个batch中，当batch满了后，producer才会把消息发送出去。但是也不一定等到满了，这和另外一个参数linger.ms有关。默认值为16K，合计为16384.</p>
<p><strong>商业环境推荐：</strong></p>
<ul>
<li>batch 越小，producer的吞吐量越低，越大，吞吐量越大。</li>
</ul>
<h3 id="producer参数linger-ms设置-吞吐量和延时性能"><a href="#producer参数linger-ms设置-吞吐量和延时性能" class="headerlink" title="producer参数linger.ms设置(吞吐量和延时性能)"></a>producer参数linger.ms设置(吞吐量和延时性能)</h3><p>producer是按照batch进行发送的，但是还要看linger.ms的值，默认是0，表示不做停留。这种情况下，可能有的batch中没有包含足够多的produce请求就被发送出去了，造成了大量的小batch，给网络IO带来的极大的压力。</p>
<p><strong>商业环境推荐：</strong></p>
<ul>
<li>为了减少了网络IO，提升了整体的TPS。假设设置linger.ms=5，表示producer请求可能会延时5ms才会被发送。</li>
</ul>
<h3 id="producer参数max-in-flight-requests-per-connection设置-吞吐量和延时性能"><a href="#producer参数max-in-flight-requests-per-connection设置-吞吐量和延时性能" class="headerlink" title="producer参数max.in.flight.requests.per.connection设置(吞吐量和延时性能)"></a>producer参数max.in.flight.requests.per.connection设置(吞吐量和延时性能)</h3><p>producer的IO线程在单个Socket连接上能够发送未应答produce请求的最大数量。增加此值应该可以增加IO线程的吞吐量，从而整体上提升producer的性能。不过就像之前说的如果开启了重试机制，那么设置该参数大于1的话有可能造成消息的乱序。</p>
<p><strong>商业环境推荐：</strong></p>
<ul>
<li>默认值5是一个比较好的起始点,如果发现producer的瓶颈在IO线程，同时各个broker端负载不高，那么可以尝试适当增加该值.</li>
</ul>
<ul>
<li>过大增加该参数会造成producer的整体内存负担，同时还可能造成不必要的锁竞争反而会降低TPS</li>
</ul>
<h2 id="Java客户端"><a href="#Java客户端" class="headerlink" title="Java客户端"></a>Java客户端</h2><p>KafkaProducer(org.apache.kafka.clients.producer.KafkaProducer)是一个用于向kafka集群发送数据的Java客户端。该Java客户端是线程安全的，多个线程可以共享同一个producer实例，而且这通常比在多个线程中每个线程创建一个实例速度要快些。本文介绍的内容来自于kafka官方文档，详情参见<a href="http://kafka.apache.org/0110/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html" target="_blank" rel="noopener">KafkaProducer</a> </p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">package com.test.kafkaProducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.PartitionInfo;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> class TestProducer &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(<span class="keyword">String</span>[] args) &#123;</span><br><span class="line"></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"bootstrap.servers"</span>, <span class="string">"192.168.137.200:9092"</span>);</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"retries"</span>, <span class="number">0</span>);</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"batch.size"</span>, <span class="number">16384</span>);</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.<span class="built_in">put</span>(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="comment">//生产者发送消息 </span></span><br><span class="line">        <span class="keyword">String</span> topic = <span class="string">"mytopic"</span>;</span><br><span class="line">        Producer&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt; procuder = <span class="keyword">new</span> KafkaProducer&lt;<span class="keyword">String</span>,<span class="keyword">String</span>&gt;(props);</span><br><span class="line">        <span class="built_in">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">String</span> value = <span class="string">"value_"</span> + i;</span><br><span class="line">            ProducerRecord&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt; msg = <span class="keyword">new</span> ProducerRecord&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt;(topic, value);</span><br><span class="line">            procuder.send(msg);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//列出topic的相关信息</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = <span class="keyword">new</span> ArrayList&lt;PartitionInfo&gt;() ;</span><br><span class="line">        partitions = procuder.partitionsFor(topic);</span><br><span class="line">        <span class="built_in">for</span>(PartitionInfo p:partitions)</span><br><span class="line">        &#123;</span><br><span class="line">            System.out.<span class="built_in">println</span>(p);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.<span class="built_in">println</span>(<span class="string">"send message over."</span>);</span><br><span class="line">        procuder.<span class="built_in">close</span>(<span class="number">100</span>,TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>producer包含一个用于保存待发送消息的缓冲池，缓冲池中消息是还没来得及传输到kafka集群的消息。位于底层的kafka I/O线程负责将缓冲池中的消息转换成请求发送到集群。如果在结束produce时，没有调用close()方法，那么这些资源会发生泄露。<br>用于建立消费者的相关参数说明及其默认值参见producerconfigs，此处对代码中用到的几个参数进行解释：<br>bootstrap.servers:用于初始化时建立链接到kafka集群，以host:port形式，多个以逗号分隔host1:port1,host2:port2；<br>acks:生产者需要server端在接收到消息后，进行反馈确认的尺度，主要用于消息的可靠性传输；acks=0表示生产者不需要来自server的确认；acks=1表示server端将消息保存后即可发送ack，而不必等到其他follower角色的都收到了该消息；acks=all(or acks=-1)意味着server端将等待所有的副本都被接收后才发送确认。<br>retries:生产者发送失败后，重试的次数<br>batch.size:当多条消息发送到同一个partition时，该值控制生产者批量发送消息的大小，批量发送可以减少生产者到服务端的请求数，有助于提高客户端和服务端的性能。<br>linger.ms:默认情况下缓冲区的消息会被立即发送到服务端，即使缓冲区的空间并没有被用完。可以将该值设置为大于0的值，这样发送者将等待一段时间后，再向服务端发送请求，以实现每次请求可以尽可能多的发送批量消息。<br>batch.size和linger.ms是两种实现让客户端每次请求尽可能多的发送消息的机制，它们可以并存使用，并不冲突。<br>buffer.memory:生产者缓冲区的大小，保存的是还未来得及发送到server端的消息，如果生产者的发送速度大于消息被提交到server端的速度，该缓冲区将被耗尽。<br>key.serializer,value.serializer说明了使用何种序列化方式将用户提供的key和vaule值序列化成字节。</p>
</blockquote>
<p><strong>kafka客户端的API</strong>  </p>
<p><strong>KafkaProducer对象实例化方法</strong>,可以使用map形式的键值对或者Properties对象来配置客户端的属性</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *keySerializer:发送数据key值的序列化方法，该方法实现了Serializer接口</span></span><br><span class="line"><span class="comment"> *valueSerializer:发送数据value值的序列化方法，该方法实现了Serializer接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">KafkaProducer</span><span class="params">(Map&lt;String,Object&gt; configs)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">KafkaProducer</span><span class="params">(Map&lt;String,Object&gt; configs, Serializer&lt;K&gt; keySerializer,Serializer&lt;V&gt; valueSerializer)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">KafkaProducer</span><span class="params">(Properties properties)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">KafkaProducer</span><span class="params">(Properties properties, Serializer&lt;K&gt; keySerializer,Serializer&lt;V&gt; valueSerializer)</span></span>;</span><br></pre></td></tr></table></figure>

<p><strong>消息发送方法send()</strong></p>
<figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *record:key-value形式的待发送数据</span></span><br><span class="line"><span class="comment"> *callback:到发送的消息被borker端确认后的回调函数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span>(<span class="params">ProducerRecord&lt;K,V&gt; record</span>)</span>; <span class="comment">// Equivalent to send(record, null)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span>(<span class="params">ProducerRecord&lt;K,V&gt; record,Callback callback</span>)</span>;</span><br></pre></td></tr></table></figure>

<p>send方法负责将缓冲池中的消息异步的发送到broker的指定topic中。异步发送是指，方法将消息存储到底层待发送的I/O缓存后，将立即返回，这可以实现并行无阻塞的发送更多消息。send方法的返回值是RecordMetadata类型，它含有消息将被投递的partition信息，该条消息的offset，以及时间戳。<br>因为send返回的是Future对象，因此在该对象上调用get()方法将阻塞，直到相关的发送请求完成并返回元数据信息；或者在发送时抛出异常而退出。<br>阻塞发送的方法如下：</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">String</span> <span class="built_in">key</span> = <span class="string">"Key"</span>;</span><br><span class="line"><span class="keyword">String</span> value = <span class="string">"Value"</span>;</span><br><span class="line">ProducerRecord&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt;(<span class="built_in">key</span>, value);</span><br><span class="line">producer.send(record).<span class="built_in">get</span>();</span><br></pre></td></tr></table></figure>

<p>可以充分利用回调函数和异步发送方式来确认消息发送的进度:</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;<span class="keyword">String</span>,<span class="keyword">String</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;<span class="keyword">String</span>,<span class="keyword">String</span>&gt;(<span class="string">"the-topic"</span>, <span class="built_in">key</span>, value);</span><br><span class="line">producer.send(myRecord, <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> onCompletion(RecordMetadata metadata, Exception e) &#123;</span><br><span class="line">                        <span class="keyword">if</span>(e != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            System.out.<span class="built_in">println</span>(<span class="string">"The offset of the record we just sent is: "</span> + metadata.offset());</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br></pre></td></tr></table></figure>

<p><strong>flush</strong> </p>
<p>立即发送缓存数据</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flush</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>

<p>调用该方法将使得缓冲区的所有消息被立即发送（即使linger.ms参数被设置为大于0），且会阻塞直到这些相关消息的发送请求完成。flush方法的前置条件是：之前发送的所有消息请求已经完成。一个请求被视为完成是指：根据acks参数配置项收到了相应的确认，或者发送中抛出异常失败了。<br>下面的例子展示了从一个topic消费后发到另一个topic，flush方法在此非常有用，它提供了一种方便的方法来确保之前发送的消息确实已经完成了：</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">for</span>(ConsumerRecord&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt; record: consumer.poll(<span class="number">100</span>))</span><br><span class="line">    producer.send(<span class="keyword">new</span> ProducerRecord(<span class="string">"my-topic"</span>, record.key(), record.value());</span><br><span class="line">producer.<span class="built_in">flush</span>();  <span class="comment">//将缓冲区的消息立即发送</span></span><br><span class="line">consumer.commit(); <span class="comment">//消费者手动确认消费进度</span></span><br></pre></td></tr></table></figure>

<p><strong>partitionsFor</strong></p>
<figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获取指定topic的partition元数据信息</span></span><br><span class="line"><span class="keyword">public</span> <span class="built_in">List</span>&lt;PartitionInfo&gt; partitionsFor(<span class="built_in">String</span> topic);</span><br></pre></td></tr></table></figure>

<p><strong>close</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//关闭producer，方法将被阻塞，直到之前的发送请求已经完成</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;<span class="comment">//  equivalent to close(Long.MAX_VALUE, TimeUnit.MILLISECONDS)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(<span class="keyword">long</span> timeout,TimeUnit timeUnit)</span></span>; <span class="comment">//同上，方法将等待timeout时长，以让未完成的请求完成发送</span></span><br></pre></td></tr></table></figure>

</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>gaojintao999@163.com</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/09/03/kafka生产者Producer参数设置及调优/">https://gjtmaster.github.io/2018/09/03/kafka生产者Producer参数设置及调优/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/Kafka/">Kafka</a><a href="/tags/消息中间件/">消息中间件</a></div><div class="post-nav"><a class="pre" href="/2018/09/04/kafka消费者Consumer参数设置及调优/">kafka消费者Consumer参数设置及调优</a><a class="next" href="/2018/09/02/kafka集群Broker端参数设置及调优/">kafka集群Broker端参数设置及调优</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/JVM/">JVM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/实时计算框架/">实时计算框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据存储格式/">数据存储格式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据的导入导出/">数据的导入导出</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/日志框架/">日志框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息中间件/">消息中间件</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/实时计算/" style="font-size: 15px;">实时计算</a> <a href="/tags/Flink-on-Yarn/" style="font-size: 15px;">Flink on Yarn</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/消息中间件/" style="font-size: 15px;">消息中间件</a> <a href="/tags/FlinkSQL/" style="font-size: 15px;">FlinkSQL</a> <a href="/tags/Logback/" style="font-size: 15px;">Logback</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/内存回收/" style="font-size: 15px;">内存回收</a> <a href="/tags/ogg/" style="font-size: 15px;">ogg</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/08/19/Flink 进阶：Time 深度解析/">Flink 进阶：Time 深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/19/Flink 进阶：Flink Connector详解/">Flink 进阶：Flink Connector详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/16/Flink 进阶：增量 Checkpoint 详解/">Flink 进阶：增量 Checkpoint 详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/15/Flink 进阶：Runtime 核心机制剖析/">Flink 进阶：Runtime 核心机制剖析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/15/Flink1.7.1与Kafka0.11.0.1/">Flink1.7.1与Kafka0.11.0.1</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/Flink on Yarn HA/">Flink On Yarn HA</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/Flink On Yan集群部署/">Flink On Yarn集群部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/Flink使用Logback作为日志框架的相关配置/">Flink使用Logback作为日志框架的相关配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/18/FlinkSQL深度解析/">Flink SQL 深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/17/kafka rebalance 机制与Consumer多种消费模式案例应用实战/">kafka rebalance机制与Consumer多种消费模式案例</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://matt33.com/" title="Matt's Blog" target="_blank">Matt's Blog</a><ul></ul><a href="https://www.haomwei.com/technology/maupassant-hexo.html" title="Maupassant's usage" target="_blank">Maupassant's usage</a><ul></ul><a href="https://www.jianshu.com/p/f4332764e8bd" title="hexo's usage" target="_blank">hexo's usage</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Joker's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>