<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="心有多大，舞台就有多大！"><title>kafka集群基于可用性指标进行性能调优 | Joker's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">kafka集群基于可用性指标进行性能调优</h1><a id="logo" href="/.">Joker's Blog</a><p class="description">高金涛</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">kafka集群基于可用性指标进行性能调优</h1><div class="post-meta">Sep 7, 2018<span> | </span><span class="category"><a href="/categories/消息中间件/">消息中间件</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#可用性"><span class="toc-number">1.</span> <span class="toc-text">可用性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Topic角度看问题"><span class="toc-number">2.</span> <span class="toc-text">Topic角度看问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer角度看问题"><span class="toc-number">3.</span> <span class="toc-text">Producer角度看问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker角度看问题"><span class="toc-number">4.</span> <span class="toc-text">Broker角度看问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer角度看问题"><span class="toc-number">5.</span> <span class="toc-text">Consumer角度看问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参数清单"><span class="toc-number">6.</span> <span class="toc-text">参数清单</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">7.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="post-content"><h2 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h2><ul>
<li>可用性反映了kafka集群应对崩溃的能力，调优可用性就是为了让Kafka更快的从崩溃中恢复过来。</li>
</ul>
<h2 id="Topic角度看问题"><a href="#Topic角度看问题" class="headerlink" title="Topic角度看问题"></a>Topic角度看问题</h2><ul>
<li>Controller就是broker，主要负责副本分配方案和分区上线的工作（根据副本的分配方案）。</li>
<li>副本状态机制</li>
<li>分区状态机制</li>
<li>注意Topic的分区数越多，一旦分区的leader副本所在broker发生崩溃，就需要进行leader的选举，虽然Leader的选举时间很短，大概几毫秒，但是Controller处理请求时单线程的，controller通过Zookeeper可实时侦测broker状态。一旦有broker挂掉了，controller可立即感知并为受影响分区选举新的leader，但是在新的分配方案出来后，发布到各个broker进行元数据更新就要浪费网络I/O了。</li>
<li>建议分区不要过大，可能会影响可用性。</li>
</ul>
<h2 id="Producer角度看问题"><a href="#Producer角度看问题" class="headerlink" title="Producer角度看问题"></a>Producer角度看问题</h2><ul>
<li>首推参数是acks，当acks设置为all时，broker端参数min.insync.replicas的效果会影响Producer端的可用性。该参数越大，kafka会强制进行越多的follower副本同步写入日志，当出现ISR缩减到min.insync.replicas值时，producer会停止对特定分区发送消息，从而影响了可用性。</li>
</ul>
<h2 id="Broker角度看问题"><a href="#Broker角度看问题" class="headerlink" title="Broker角度看问题"></a>Broker角度看问题</h2><ul>
<li>Broker端高可用性直接的表现形式就是broker崩溃，崩溃之后leader选举有两种：1：从ISR中选择。2：通过unclean.leader.election.enable值决定是否从ISR中选择。第二种情况会出现数据丢失的风险。</li>
<li>另一个参数是broker崩溃恢复调优，即num.recovery.threads.per.data.dir。场景是这样的，当broker从崩溃中重启恢复后，broker会扫描并加载底层的分区数据执行清理和与其他broker保持同步。这一工程被称为日志加载和日志恢复。默认情况下是单线程的。假设某个Broker的log.dirs配置了10个日志目录，那么单线程可能就吭哧吭哧扫描加载，太慢了。实际使用中，建议配置为日志的log.dirs磁盘数量。</li>
</ul>
<h2 id="Consumer角度看问题"><a href="#Consumer角度看问题" class="headerlink" title="Consumer角度看问题"></a>Consumer角度看问题</h2><ul>
<li><p>对于Consumer而言，高可用性主要是基于组管理的consumer group来体现的，当group下某个或某些consumer实例“挂了”，group的coordinator能够自动检测出这种崩溃并及时的开启rebalance，进而将崩溃的消费分区分配到其他存活的consumer上。</p>
</li>
<li><p>consumer端参数session.timeout.ms就是定义了能检测出failure的时间间隔。若要实现高可用，必须设置较低的值，比如5-10秒。一旦超过该值，就会开启新一轮的reblance。</p>
</li>
<li><p>消息处理时间参数很牛，<code>max.poll.interval.ms</code>，参数设置了consumer实例所需要的消息处理时间，一旦超过该值，就是高负荷状态，此时consumer将停止发送心跳，并告知coordinator要离开group。<code>消费者在创建时会有一个属性max.poll.interval.ms</code>，该属性意思为kafka消费者在每一轮poll()调用之间的最大延迟,消费者在获取更多记录之前可以空闲的时间量的上限。如果此超时时间期满之前poll()没有被再次调用，则消费者被视为失败，并且分组将重新平衡，以便将分区重新分配给别的成员</p>
</li>
<li><p><code>hearbeat.interval.ms</code> 当coordinator决定开启新一轮的reblance时，他会把这个决定以REBALANCE_IN_PROCESS异常的形式塞进consumer心跳的请求响应中，这样就可以飞快的感知到新的分区分配方案。</p>
</li>
<li><p>kafka调优经典的独白：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">上线两个月都没有问题，为什么最近突然出现问题了。我想肯定是业务系统有什么动作，我就去问了一个下，</span><br><span class="line">果然头一天风控系统kafka挂掉了，并进行了数据重推，导致了数据阻塞。但是我又想即使阻塞了也会慢慢消费掉啊，不应</span><br><span class="line">该报错呀。后来我看了一下kafka官网上的参数介绍，发现max.poll.records默认是<span class="number">2147483647</span> </span><br><span class="line">（<span class="number">0.10</span><span class="number">.0</span><span class="number">.1</span>版本），也就是kafka里面有多少poll多少，如果消费者拿到的这些数据在制定时间内消费不完，就会手动提交</span><br><span class="line">失败，数据就会回滚到kafka中，会发生重复消费的情况。如此循环，数据就会越堆越多。后来咨询了公司的kafka大神，他</span><br><span class="line">说我的kafka版本跟他的集群版本不一样让我升级kafka版本。于是我就升级到了<span class="number">0.10</span><span class="number">.2</span><span class="number">.1</span>，查阅官网发现这个版本的max.po</span><br><span class="line">ll.records默认是<span class="number">500</span>，可能kafka开发团队也意识到了这个问题。并且这个版本多了一个max.poll.interval.ms这个参数，</span><br><span class="line">默认是<span class="number">300</span>s。这个参数的大概意思就是kafka消费者在一次poll内，业务处理时间不能超过这个时间。后来升级了kafka版本</span><br><span class="line">，把max.poll.records改成了<span class="number">50</span>个之后，上了一次线，准备观察一下。上完线已经晚上<span class="number">9</span>点了，于是就打卡回家了，明天看</span><br><span class="line">结果。第二天早起满心欢喜准备看结果，以为会解决这个问题，谁曾想还是堆积。我的天，思来想去，也想不出哪里有问题</span><br><span class="line">。于是就把处理各个业务的代码前后执行时间打印出来看一下，添加代码，提交上线。然后观察结果，发现大部分时间都用</span><br><span class="line">在数据库IO上了，并且执行时间很慢，大部分都是<span class="number">2</span>s。于是想可能刚上线的时候数据量比较小，查询比较快，现在数据量大</span><br><span class="line">了，就比较慢了。当时脑子里第一想法就是看了一下常用查询字段有没有添加索引，一看没有，然后马上添加索引。加完索</span><br><span class="line">引观察了一下，处理速度提高了好几倍。虽然单条业务处理的快了， </span><br><span class="line">但是堆积还存在，后来发现，业务系统大概<span class="number">1</span>s推送<span class="number">3</span>、<span class="number">4</span>条数据，但是我kafka现在是单线程消费，速度大概也是这么多。再</span><br><span class="line">加上之前的堆积，所以消费还是很慢。于是业务改成多线程消费，利用线程池，开启了<span class="number">10</span>个线程，上线观察。几分钟就消费</span><br><span class="line">完了。大功告成，此时此刻，心里舒坦了好多。不容易呀！</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="参数清单"><a href="#参数清单" class="headerlink" title="参数清单"></a>参数清单</h2><p><strong>Broker端</strong></p>
<ul>
<li>避免过多分区</li>
<li>设置unclean.leader.election.enable=true（为了可用性，数据丢失不考虑）</li>
<li>设置min.insync.replicas=1（减轻同步压力）</li>
<li>设置num.recovery.threads.per.data.dir=broker 日志的log.dirs磁盘数</li>
</ul>
<p><strong>Producer端</strong></p>
<ul>
<li>设置acks=1，设置为all时，遵循min.insync.replicas=1</li>
</ul>
<p><strong>consumer端</strong></p>
<ul>
<li>设置session.timeout.ms为较低的值，比如100000</li>
<li>设置max.poll.interval.ms消息平均处理时间，可适当调大。</li>
<li>设置max.poll.records和max.partition.fetch.bytes减少消息处理总时长，避免频繁的rebalance。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>num.recovery.threads.per.data.dir以及max.partition.fetch.bytes以及max.poll.records重点关注一下。</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>gaojintao999@163.com</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/09/07/kafka集群基于可用性指标进行性能调优/">https://gjtmaster.github.io/2018/09/07/kafka集群基于可用性指标进行性能调优/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/Kafka/">Kafka</a><a href="/tags/消息中间件/">消息中间件</a></div><div class="post-nav"><a class="pre" href="/2018/09/13/利用ogg实现oracle到kafka的增量数据实时同步/">利用ogg实现oracle到kafka的增量数据实时同步</a><a class="next" href="/2018/09/06/kafka集群基于持久性指标进行性能调优/">kafka集群基于持久性指标进行性能调优</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/JVM/">JVM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/实时计算框架/">实时计算框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据存储格式/">数据存储格式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据的导入导出/">数据的导入导出</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/日志框架/">日志框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息中间件/">消息中间件</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/实时计算/" style="font-size: 15px;">实时计算</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/Flink-on-Yarn/" style="font-size: 15px;">Flink on Yarn</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/消息中间件/" style="font-size: 15px;">消息中间件</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/FlinkSQL/" style="font-size: 15px;">FlinkSQL</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/内存回收/" style="font-size: 15px;">内存回收</a> <a href="/tags/Logback/" style="font-size: 15px;">Logback</a> <a href="/tags/ogg/" style="font-size: 15px;">ogg</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/09/17/Flink 进阶：Time 深度解析/">Flink 进阶：Time 深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/16/Flink 进阶：Runtime 核心机制剖析/">Flink 进阶：Runtime 核心机制剖析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/15/Flink1.7.1与Kafka0.11.0.1/">Flink1.7.1与Kafka0.11.0.1</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/Flink on Yarn HA/">Flink On Yarn HA</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/Flink On Yan集群部署/">Flink On Yarn集群部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/Flink使用Logback作为日志框架的相关配置/">Flink使用Logback作为日志框架的相关配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/18/FlinkSQL深度解析/">Flink SQL 深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/13/利用ogg实现oracle到kafka的增量数据实时同步/">利用ogg实现oracle到kafka的增量数据实时同步</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/07/kafka集群基于可用性指标进行性能调优/">kafka集群基于可用性指标进行性能调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/06/kafka集群基于持久性指标进行性能调优/">kafka集群基于持久性指标进行性能调优</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://matt33.com/" title="Matt's Blog" target="_blank">Matt's Blog</a><ul></ul><a href="https://www.haomwei.com/technology/maupassant-hexo.html" title="Maupassant's usage" target="_blank">Maupassant's usage</a><ul></ul><a href="https://www.jianshu.com/p/f4332764e8bd" title="hexo's usage" target="_blank">hexo's usage</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Joker's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>