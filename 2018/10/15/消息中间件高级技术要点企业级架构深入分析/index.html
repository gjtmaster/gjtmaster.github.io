<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="心有多大，舞台就有多大！"><title>消息中间件高级技术要点企业级架构深入分析 | Joker's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">消息中间件高级技术要点企业级架构深入分析</h1><a id="logo" href="/.">Joker's Blog</a><p class="description">高金涛</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">消息中间件高级技术要点企业级架构深入分析</h1><div class="post-meta">Oct 15, 2018<span> | </span><span class="category"><a href="/categories/消息中间件/">消息中间件</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#消息中间件系统如何进行技术选型"><span class="toc-number">1.</span> <span class="toc-text">消息中间件系统如何进行技术选型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消息队列的常见使用场景"><span class="toc-number">1.1.</span> <span class="toc-text">消息队列的常见使用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#消息队列技术选型"><span class="toc-number">1.2.</span> <span class="toc-text">消息队列技术选型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#消息中间件系统高可用实践"><span class="toc-number">2.</span> <span class="toc-text">消息中间件系统高可用实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RabbitMQ的高可用性"><span class="toc-number">2.1.</span> <span class="toc-text">RabbitMQ的高可用性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka的高可用性"><span class="toc-number">2.2.</span> <span class="toc-text">kafka的高可用性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#消息中间件系统消费幂等性实践"><span class="toc-number">3.</span> <span class="toc-text">消息中间件系统消费幂等性实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消息中间件系统重复消费"><span class="toc-number">3.1.</span> <span class="toc-text">消息中间件系统重复消费</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#如何保证幂等性"><span class="toc-number">3.2.</span> <span class="toc-text">如何保证幂等性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#消息中间件系统消息零丢失实践"><span class="toc-number">4.</span> <span class="toc-text">消息中间件系统消息零丢失实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rabbitmq-消息零丢失实践"><span class="toc-number">4.1.</span> <span class="toc-text">rabbitmq 消息零丢失实践</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka消息零丢失实践"><span class="toc-number">4.2.</span> <span class="toc-text">kafka消息零丢失实践</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#消息中间件系统消息的顺序性实践"><span class="toc-number">5.</span> <span class="toc-text">消息中间件系统消息的顺序性实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#顺序会错乱的场景"><span class="toc-number">5.1.</span> <span class="toc-text">顺序会错乱的场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#顺序性实践"><span class="toc-number">5.2.</span> <span class="toc-text">顺序性实践</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#消息队列的消息延时以及过期失效实践"><span class="toc-number">6.</span> <span class="toc-text">消息队列的消息延时以及过期失效实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#消息队列的延时以及过期场景"><span class="toc-number">6.1.</span> <span class="toc-text">消息队列的延时以及过期场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#消息队列的延时以及过期问题解决思路"><span class="toc-number">6.2.</span> <span class="toc-text">消息队列的延时以及过期问题解决思路</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何设计完善的消息中间件系统"><span class="toc-number">7.</span> <span class="toc-text">如何设计完善的消息中间件系统</span></a></li></ol></div></div><div class="post-content"><h2 id="消息中间件系统如何进行技术选型"><a href="#消息中间件系统如何进行技术选型" class="headerlink" title="消息中间件系统如何进行技术选型"></a>消息中间件系统如何进行技术选型</h2><h3 id="消息队列的常见使用场景"><a href="#消息队列的常见使用场景" class="headerlink" title="消息队列的常见使用场景"></a>消息队列的常见使用场景</h3><p>比较核心的有3个：解耦、异步、削峰。</p>
<ul>
<li>解耦：举例如下：A系统发送个数据到BCD三个系统，接口调用发送，那如果E系统也要这个数据呢？那如果C系统现在不需要了呢？现在A系统又要发送第二种数据了呢？A系统负责人濒临崩溃中。。。再来点更加崩溃的事儿，A系统要时时刻刻考虑BCDE四个系统如果挂了咋办？我要不要重发？我要不要把消息存起来？头发都白了啊。。。</li>
<li>异步：举例如下：A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要3ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是3 + 300 + 450 + 200 = 953ms，接近1s，时间延迟过大。</li>
<li>削峰：每天0点到11点，A系统风平浪静，每秒并发请求数量就100个。结果每次一到11点~1点，每秒并发请求数量突然会暴增到1万条。但是系统最大的处理能力就只能是每秒钟处理1000个请求啊。导致系统崩溃。</li>
</ul>
<h3 id="消息队列技术选型"><a href="#消息队列技术选型" class="headerlink" title="消息队列技术选型"></a>消息队列技术选型</h3><p><img src="https://user-gold-cdn.xitu.io/2019/3/3/16941b629c04ea6e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img"></p>
<p><img src="https://user-gold-cdn.xitu.io/2019/3/3/16941b6a4bbeb3f1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img"></p>
<p><img src="https://user-gold-cdn.xitu.io/2019/3/3/16941b757ae18e42?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img"></p>
<h2 id="消息中间件系统高可用实践"><a href="#消息中间件系统高可用实践" class="headerlink" title="消息中间件系统高可用实践"></a>消息中间件系统高可用实践</h2><h3 id="RabbitMQ的高可用性"><a href="#RabbitMQ的高可用性" class="headerlink" title="RabbitMQ的高可用性"></a>RabbitMQ的高可用性</h3><p>rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式。</p>
<p>普通集群模式模式是在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。</p>
<p>镜像集群模式是，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。</p>
<p>rabbitmq并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已。rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。无法真正实现集群的扩容。</p>
<h3 id="kafka的高可用性"><a href="#kafka的高可用性" class="headerlink" title="kafka的高可用性"></a>kafka的高可用性</h3><p>kafka由多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。</p>
<p>kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。</p>
<p>kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。</p>
<p>写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。</p>
<p>消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。</p>
<h2 id="消息中间件系统消费幂等性实践"><a href="#消息中间件系统消费幂等性实践" class="headerlink" title="消息中间件系统消费幂等性实践"></a>消息中间件系统消费幂等性实践</h2><h3 id="消息中间件系统重复消费"><a href="#消息中间件系统重复消费" class="headerlink" title="消息中间件系统重复消费"></a>消息中间件系统重复消费</h3><p>既然是消费消息，那肯定要考虑考虑会不会重复消费？能不能避免重复消费？或者重复消费了也别造成系统异常可以吗？这个是MQ领域的基本问题，其实本质上如何使用消息队列保证幂等性。</p>
<p>kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。</p>
<p>但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。</p>
<h3 id="如何保证幂等性"><a href="#如何保证幂等性" class="headerlink" title="如何保证幂等性"></a>如何保证幂等性</h3><ul>
<li>比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧</li>
<li>比如你是写redis，那没问题了，反正每次都是set，天然幂等性。</li>
<li>比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</li>
<li>基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据。</li>
</ul>
<h2 id="消息中间件系统消息零丢失实践"><a href="#消息中间件系统消息零丢失实践" class="headerlink" title="消息中间件系统消息零丢失实践"></a>消息中间件系统消息零丢失实践</h2><h3 id="rabbitmq-消息零丢失实践"><a href="#rabbitmq-消息零丢失实践" class="headerlink" title="rabbitmq 消息零丢失实践"></a>rabbitmq 消息零丢失实践</h3><ul>
<li><p>基于rabbitmq提供的事务功能，</p>
<p>生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。</p>
</li>
<li><p>基于rabbitmq开启confirm模式</p>
<p>在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p>
</li>
<li><p>事务机制和cnofirm机制不同之处</p>
<p>事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。</p>
</li>
<li><p>消费端手动ACK机制实现</p>
<p>rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。</p>
<p>这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。</p>
</li>
</ul>
<h3 id="kafka消息零丢失实践"><a href="#kafka消息零丢失实践" class="headerlink" title="kafka消息零丢失实践"></a>kafka消息零丢失实践</h3><ul>
<li><p>消费端手动ACK机制实现</p>
<p>唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p>
<p>这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p>
<p>生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。</p>
<p>然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了。</p>
</li>
<li><p>kafka broker 数据零丢失保证</p>
<p>比如kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。</p>
<p>生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了</p>
<p>所以此时一般是要求起码设置如下4个参数：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1</span>)topic设置replication.factor参数：这个值必须大于<span class="number">1</span>，要求每个partition必须有至少<span class="number">2</span>个副本</span><br><span class="line"></span><br><span class="line">(<span class="number">2</span>)kafka服务端设置min.insync.replicas参数：这个值必须大于<span class="number">1</span>，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧</span><br><span class="line"></span><br><span class="line">(<span class="number">3</span>)producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了</span><br><span class="line"></span><br><span class="line">(<span class="number">4</span>)producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了</span><br></pre></td></tr></table></figure>

<p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失。</p>
</li>
<li><p>kafka分区partition挂掉之后如何恢复？</p>
<p>在kafka中有一个partition recovery机制用于恢复挂掉的partition。每个Partition会在磁盘记录一个RecoveryPoint（恢复点）, 记录已经flush到磁盘的最大offset。当broker fail 重启时,会进行loadLogs。 首先会读取该Partition的RecoveryPoint,找到包含RecoveryPoint点上的segment及以后的segment, 这些segment就是可能没有完全flush到磁盘segments。然后调用segment的recover,重新读取各个segment的msg,并重建索引。</p>
<p>优点：</p>
<p>以segment为单位管理Partition数据,方便数据生命周期的管理,删除过期数据简单</p>
<p>在程序崩溃重启时,加快recovery速度,只需恢复未完全flush到磁盘的segment即可</p>
</li>
<li><p>什么原因导致副本与leader不同步的呢？</p>
<p>慢副本：在一定周期时间内follower不能追赶上leader。最常见的原因之一是IO瓶颈导致follower追加复制消息速度慢于从leader拉取速度。</p>
<p>卡住副本：在一定周期时间内follower停止从leader拉取请求。follower replica卡住了是由于GC暂停或follower失效或死亡。</p>
<p>新启动副本：当用户给主题增加副本因子时，新的follower不在同步副本列表中，直到他们完全赶上了leader日志。</p>
<p>一个partition的follower落后于leader足够多时，被认为不在同步副本列表或处于滞后状态。正如上述所说，现在kafka判定落后有两种，副本滞后判断依据是副本落后于leader最大消息数量(replica.lag.max.messages)或rep licas响应partition leader的最长等待时间(replica.lag.time.max.ms)。前者是用来检测缓慢的副本,而后者是用来检测失效或死亡的副本。</p>
<p>注意：新版本中，replica.lag.max.messages已经废弃。</p>
</li>
</ul>
<h2 id="消息中间件系统消息的顺序性实践"><a href="#消息中间件系统消息的顺序性实践" class="headerlink" title="消息中间件系统消息的顺序性实践"></a>消息中间件系统消息的顺序性实践</h2><h3 id="顺序会错乱的场景"><a href="#顺序会错乱的场景" class="headerlink" title="顺序会错乱的场景"></a>顺序会错乱的场景</h3><p>例如：在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。</p>
<p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p>
<ul>
<li>rabbitmq：一个queue，多个consumer，这不明显乱了</li>
<li>kafka：一个topic，一个partition，一个consumer，内部多线程，这不也明显乱了</li>
</ul>
<h3 id="顺序性实践"><a href="#顺序性实践" class="headerlink" title="顺序性实践"></a>顺序性实践</h3><p>（1）rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理</p>
<p>（2）kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可</p>
<p><img src="https://user-gold-cdn.xitu.io/2019/3/2/1693ee61fe5f1667?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img"></p>
<h2 id="消息队列的消息延时以及过期失效实践"><a href="#消息队列的消息延时以及过期失效实践" class="headerlink" title="消息队列的消息延时以及过期失效实践"></a>消息队列的消息延时以及过期失效实践</h2><h3 id="消息队列的延时以及过期场景"><a href="#消息队列的延时以及过期场景" class="headerlink" title="消息队列的延时以及过期场景"></a>消息队列的延时以及过期场景</h3><p>可能你的消费端出了问题，不消费了，或者消费的极其极其慢。导致消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如rabbitmq设置了消息过期时间后就没了怎么办？</p>
<h3 id="消息队列的延时以及过期问题解决思路"><a href="#消息队列的延时以及过期问题解决思路" class="headerlink" title="消息队列的延时以及过期问题解决思路"></a>消息队列的延时以及过期问题解决思路</h3><ul>
<li>大量消息在mq里积压并临时紧急扩容</li>
</ul>
<p>所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉</span><br><span class="line"><span class="number">2</span>）新建一个topic，partition是原来的<span class="number">10</span>倍，临时建立好原先<span class="number">10</span>倍或者<span class="number">20</span>倍的queue数量</span><br><span class="line"><span class="number">3</span>）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的<span class="number">10</span>倍数量的queue</span><br><span class="line"><span class="number">4</span>）接着临时征用<span class="number">10</span>倍的机器来部署consumer，每一批consumer消费一个临时queue的数据</span><br><span class="line"><span class="number">5</span>）这种做法相当于是临时将queue资源和consumer资源扩大<span class="number">10</span>倍，以正常的<span class="number">10</span>倍速度来消费数据</span><br><span class="line"><span class="number">6</span>）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息</span><br></pre></td></tr></table></figure>

<ul>
<li><p>过期问题解决思路</p>
<p>假设你用的是rabbitmq，rabbitmq是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在mq里，而是大量的数据会直接搞丢。</p>
<p>这个情况下，就不是说要增加consumer消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。</p>
<p>这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。</p>
<p>假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次</p>
</li>
<li><p>MQ磁盘爆满解决思路</p>
<p>如果走的方式是消息积压在mq里，那么如果你很长时间都没处理掉，此时导致mq都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据。</p>
</li>
</ul>
<h2 id="如何设计完善的消息中间件系统"><a href="#如何设计完善的消息中间件系统" class="headerlink" title="如何设计完善的消息中间件系统"></a>如何设计完善的消息中间件系统</h2><ul>
<li>mq支持可伸缩性。就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -&gt; topic -&gt; partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？</li>
<li>mq支持数据落地磁盘。落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。</li>
<li>mq支持可用性。采用多副本机制 -&gt; leader &amp; follower -&gt; broker挂了，重新选举leader即可对外服务。</li>
<li>mq支持数据0丢失,参考之前说的那个kafka数据零丢失方案</li>
</ul>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>gaojintao999@163.com</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/10/15/消息中间件高级技术要点企业级架构深入分析/">https://gjtmaster.github.io/2018/10/15/消息中间件高级技术要点企业级架构深入分析/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/Kafka/">Kafka</a><a href="/tags/消息中间件/">消息中间件</a></div><div class="post-nav"><a class="pre" href="/2018/11/15/Flink1.7.1与Kafka0.11.0.1/">Flink1.7.1与Kafka0.11.0.1</a><a class="next" href="/2018/10/13/Kafka 偏移量管理实现精确一次语义在Spark&amp;Flink中的技术实践/">Kafka 偏移量管理实现精确一次语义在Spark&amp;Flink中的技术实践</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/JVM/">JVM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/实时计算框架/">实时计算框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据存储格式/">数据存储格式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据的导入导出/">数据的导入导出</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/日志框架/">日志框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息中间件/">消息中间件</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/实时计算/" style="font-size: 15px;">实时计算</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/Flink-on-Yarn/" style="font-size: 15px;">Flink on Yarn</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/消息中间件/" style="font-size: 15px;">消息中间件</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/内存回收/" style="font-size: 15px;">内存回收</a> <a href="/tags/Logback/" style="font-size: 15px;">Logback</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/FlinkSQL/" style="font-size: 15px;">FlinkSQL</a> <a href="/tags/ogg/" style="font-size: 15px;">ogg</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/08/19/Flink 进阶：Time 深度解析/">Flink 进阶：Time 深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/19/Flink 进阶：Flink Connector详解/">Flink 进阶：Flink Connector详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/16/Flink 进阶：增量 Checkpoint 详解/">Flink 进阶：增量 Checkpoint 详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/15/Flink 进阶：Runtime 核心机制剖析/">Flink 进阶：Runtime 核心机制剖析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/18/FlinkSQL深度解析/">Flink SQL 深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/16/Flink on Yarn HA/">Flink On Yarn HA</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/15/Flink使用Logback作为日志框架的相关配置/">Flink使用Logback作为日志框架的相关配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/15/Flink On Yan集群部署/">Flink On Yarn集群部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/15/Flink1.7.1与Kafka0.11.0.1/">Flink1.7.1与Kafka0.11.0.1</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/消息中间件高级技术要点企业级架构深入分析/">消息中间件高级技术要点企业级架构深入分析</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://matt33.com/" title="Matt's Blog" target="_blank">Matt's Blog</a><ul></ul><a href="https://www.haomwei.com/technology/maupassant-hexo.html" title="Maupassant's usage" target="_blank">Maupassant's usage</a><ul></ul><a href="https://www.jianshu.com/p/f4332764e8bd" title="hexo's usage" target="_blank">hexo's usage</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Joker's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>