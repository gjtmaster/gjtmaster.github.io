<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="心有多大，舞台就有多大！"><title>Flink1.7.1与Kafka0.11.0.1 | Joker's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Flink1.7.1与Kafka0.11.0.1</h1><a id="logo" href="/.">Joker's Blog</a><p class="description">高金涛</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Flink1.7.1与Kafka0.11.0.1</h1><div class="post-meta">Nov 15, 2018<span> | </span><span class="category"><a href="/categories/实时计算框架/">实时计算框架</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.4k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 6</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Flink的Checkpoint"><span class="toc-number">1.</span> <span class="toc-text">Flink的Checkpoint</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#API"><span class="toc-number">1.1.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实例"><span class="toc-number">1.2.</span> <span class="toc-text">实例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#FlinkKafkaConsumer011"><span class="toc-number">2.</span> <span class="toc-text">FlinkKafkaConsumer011</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#API-1"><span class="toc-number">2.1.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实例-1"><span class="toc-number">2.2.</span> <span class="toc-text">实例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#FlinkKafkaProducer011"><span class="toc-number">3.</span> <span class="toc-text">FlinkKafkaProducer011</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#API-2"><span class="toc-number">3.1.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实例-2"><span class="toc-number">3.2.</span> <span class="toc-text">实例</span></a></li></ol></li></ol></div></div><div class="post-content"><a id="more"></a>
<h1 id="Flink的Checkpoint"><a href="#Flink的Checkpoint" class="headerlink" title="Flink的Checkpoint"></a>Flink的Checkpoint</h1><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><ul>
<li>使用StreamExecutionEnvironment.enableCheckpointing方法来设置开启checkpoint；具体可以使用enableCheckpointing(long interval)，或者enableCheckpointing(long interval, CheckpointingMode mode)；interval用于指定checkpoint的触发间隔(单位milliseconds)，而CheckpointingMode默认是CheckpointingMode.EXACTLY_ONCE，也可以指定为CheckpointingMode.AT_LEAST_ONCE</li>
<li>也可以通过StreamExecutionEnvironment.getCheckpointConfig().setCheckpointingMode来设置CheckpointingMode，一般对于超低延迟的应用(大概几毫秒)可以使用CheckpointingMode.AT_LEAST_ONCE，其他大部分应用使用CheckpointingMode.EXACTLY_ONCE就可以</li>
<li>checkpointTimeout用于指定checkpoint执行的超时时间(单位milliseconds)，超时没完成就会被abort掉</li>
<li>minPauseBetweenCheckpoints用于指定checkpoint coordinator上一个checkpoint完成之后最小等多久可以出发另一个checkpoint，当指定这个参数时，maxConcurrentCheckpoints的值为1</li>
<li>maxConcurrentCheckpoints用于指定运行中的checkpoint最多可以有多少个，用于包装topology不会花太多的时间在checkpoints上面；如果有设置了minPauseBetweenCheckpoints，则maxConcurrentCheckpoints这个参数就不起作用了(大于1的值不起作用)</li>
<li>enableExternalizedCheckpoints用于开启checkpoints的外部持久化，但是在job失败的时候不会自动清理，需要自己手工清理state；ExternalizedCheckpointCleanup用于指定当job canceled的时候externalized checkpoint该如何清理，DELETE_ON_CANCELLATION的话，在job canceled的时候会自动删除externalized state，但是如果是FAILED的状态则会保留；RETAIN_ON_CANCELLATION则在job canceled的时候会保留externalized checkpoint state</li>
<li>failOnCheckpointingErrors用于指定在checkpoint发生异常的时候，是否应该fail该task，默认为true，如果设置为false，则task会拒绝checkpoint然后继续运行</li>
</ul>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

// start a checkpoint every 1000 ms
env.enableCheckpointing(1000);

// advanced options:

// set mode to exactly-once (this is the default)
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

// checkpoints have to complete within one minute, or are discarded
env.getCheckpointConfig().setCheckpointTimeout(60000);

// make sure 500 ms of progress happen between checkpoints
env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);

// allow only one checkpoint to be in progress at the same time
env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);

// enable externalized checkpoints which are retained after job cancellation
env.getCheckpointConfig().enableExternalizedCheckpoints(ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);

// This determines if a task will be failed if an error occurs in the execution of the task’s checkpoint procedure.
env.getCheckpointConfig().setFailOnCheckpointingErrors(true);</code></pre><h1 id="FlinkKafkaConsumer011"><a href="#FlinkKafkaConsumer011" class="headerlink" title="FlinkKafkaConsumer011"></a>FlinkKafkaConsumer011</h1><h2 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h2><ul>
<li>setStartFromGroupOffsets()【默认消费策略】<br>默认读取上次保存的offset信息 如果是应用第一次启动，读取不到上次的offset信息，则会根据这个参数auto.offset.reset的值来进行消费数据</li>
<li>setStartFromEarliest() 从最早的数据开始进行消费，忽略存储的offset信息</li>
<li>setStartFromLatest() 从最新的数据进行消费，忽略存储的offset信息</li>
<li>setStartFromSpecificOffsets(Map&lt;KafkaTopicPartition, Long&gt;)</li>
</ul>
<ul>
<li>当checkpoint机制开启的时候，KafkaConsumer会定期把kafka的offset信息还有其他operator的状态信息一块保存起来。当job失败重启的时候，Flink会从最近一次的checkpoint中进行恢复数据，重新消费kafka中的数据。</li>
<li>为了能够使用支持容错的kafka Consumer，需要开启checkpoint env.enableCheckpointing(5000); // 每5s checkpoint一次</li>
<li>Kafka Consumers Offset 自动提交有以下两种方法来设置，可以根据job是否开启checkpoint来区分:<br>(1) Checkpoint关闭时： 可以通过下面两个参数配置<br>enable.auto.commit<br>auto.commit.interval.ms<br>(2) Checkpoint开启时：当执行checkpoint的时候才会保存offset，这样保证了kafka的offset和checkpoint的状态偏移量保持一致。 可以通过这个参数设置<br>setCommitOffsetsOnCheckpoints(boolean)<br>这个参数默认就是true。表示在checkpoint的时候提交offset, 此时，kafka中的自动提交机制就会被忽略</li>
</ul>
<h2 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h2><pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-statebackend-rocksdb_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.1&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-connector-kafka-0.11_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.1&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
    &lt;version&gt;0.11.0.1&lt;/version&gt;
&lt;/dependency&gt;

 public class StreamingKafkaSource {

    public static void main(String[] args) throws Exception {
        //获取Flink的运行环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        //checkpoint配置
        env.enableCheckpointing(5000);
        env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);
        env.getCheckpointConfig().setCheckpointTimeout(60000);
        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);
        env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);

        //设置statebackend
        //env.setStateBackend(new RocksDBStateBackend(&quot;hdfs://hadoop100:9000/flink/checkpoints&quot;,true));


        String topic = &quot;kafkaConsumer&quot;;
        Properties prop = new Properties();
        prop.setProperty(&quot;bootstrap.servers&quot;,&quot;SparkMaster:9092&quot;);
        prop.setProperty(&quot;group.id&quot;,&quot;kafkaConsumerGroup&quot;);

        FlinkKafkaConsumer011&lt;String&gt; myConsumer = new FlinkKafkaConsumer011&lt;&gt;(topic, new SimpleStringSchema(), prop);

        myConsumer.setStartFromGroupOffsets();//默认消费策略

        DataStreamSource&lt;String&gt; text = env.addSource(myConsumer);

        text.print().setParallelism(1);

        env.execute(&quot;StreamingFromCollection&quot;);
    }
}</code></pre><h1 id="FlinkKafkaProducer011"><a href="#FlinkKafkaProducer011" class="headerlink" title="FlinkKafkaProducer011"></a>FlinkKafkaProducer011</h1><h2 id="API-2"><a href="#API-2" class="headerlink" title="API"></a>API</h2><ul>
<li>Kafka Producer的容错-Kafka 0.9 and 0.10</li>
<li>如果Flink开启了checkpoint，针对FlinkKafkaProducer09和FlinkKafkaProducer010 可以提供 at-least-once的语义，还需要配置下面两个参数:<br>setLogFailuresOnly(false)<br>setFlushOnCheckpoint(true)</li>
<li>注意：建议修改kafka 生产者的重试次数retries【这个参数的值默认是0】</li>
<li>Kafka Producer的容错-Kafka 0.11，如果Flink开启了checkpoint，针对FlinkKafkaProducer011 就可以提供 exactly-once的语义,但是需要选择具体的语义<br>Semantic.NONE<br>Semantic.AT_LEAST_ONCE【默认】<br>Semantic.EXACTLY_ONCE</li>
</ul>
<h2 id="实例-2"><a href="#实例-2" class="headerlink" title="实例"></a>实例</h2><pre><code>public class StreamingKafkaSink {
    public static void main(String[] args) throws Exception {
    //获取Flink的运行环境
    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();


    //checkpoint配置
    env.enableCheckpointing(5000);
    env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
    env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);
    env.getCheckpointConfig().setCheckpointTimeout(60000);
    env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);
    env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);

    //设置statebackend

    //env.setStateBackend(new RocksDBStateBackend(&quot;hdfs://SparkMaster:9000/flink/checkpoints&quot;,true));


    DataStreamSource&lt;String&gt; text = env.socketTextStream(&quot;SparkMaster&quot;, 9001, &quot;\n&quot;);

    String brokerList = &quot;SparkMaster:9092&quot;;
    String topic = &quot;kafkaProducer&quot;;

    Properties prop = new Properties();
    prop.setProperty(&quot;bootstrap.servers&quot;,brokerList);

    //第一种解决方案，设置FlinkKafkaProducer011里面的事务超时时间
    //设置事务超时时间
    //prop.setProperty(&quot;transaction.timeout.ms&quot;,60000*15+&quot;&quot;);

    //第二种解决方案，设置kafka的最大事务超时时间,主要是kafka的配置文件设置。

    //FlinkKafkaProducer011&lt;String&gt; myProducer = new FlinkKafkaProducer011&lt;&gt;(brokerList, topic, new SimpleStringSchema());

    //使用EXACTLY_ONCE语义的kafkaProducer
    FlinkKafkaProducer011&lt;String&gt; myProducer = new FlinkKafkaProducer011&lt;&gt;(topic, new KeyedSerializationSchemaWrapper&lt;String&gt;(new SimpleStringSchema()), prop, FlinkKafkaProducer011.Semantic.EXACTLY_ONCE);
    text.addSink(myProducer);

    env.execute(&quot;StreamingFromCollection&quot;);

  }
}</code></pre></div><iframe src="/donate/?AliPayQR=/img/AliPayQR.png&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>gaojintao999@163.com</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2018/11/15/Flink1.7.1与Kafka0.11.0.1/">https://gjtmaster.github.io/2018/11/15/Flink1.7.1与Kafka0.11.0.1/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/Flink/">Flink</a><a href="/tags/实时计算/">实时计算</a><a href="/tags/Kafka/">Kafka</a><a href="/tags/消息中间件/">消息中间件</a></div><div class="post-nav"><a class="next" href="/2018/11/10/Flink on Yarn HA/">Flink On Yarn HA</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/JVM/">JVM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/实时计算框架/">实时计算框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据存储格式/">数据存储格式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据的导入导出/">数据的导入导出</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/日志框架/">日志框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息中间件/">消息中间件</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/实时计算/" style="font-size: 15px;">实时计算</a> <a href="/tags/Flink-on-Yarn/" style="font-size: 15px;">Flink on Yarn</a> <a href="/tags/FlinkSQL/" style="font-size: 15px;">FlinkSQL</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/内存回收/" style="font-size: 15px;">内存回收</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/消息中间件/" style="font-size: 15px;">消息中间件</a> <a href="/tags/Logback/" style="font-size: 15px;">Logback</a> <a href="/tags/ogg/" style="font-size: 15px;">ogg</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/11/15/Flink1.7.1与Kafka0.11.0.1/">Flink1.7.1与Kafka0.11.0.1</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/Flink on Yarn HA/">Flink On Yarn HA</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/Flink On Yan集群部署/">Flink On Yarn集群部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/13/Flink使用Logback作为日志框架的相关配置/">Flink使用Logback作为日志框架的相关配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/18/FlinkSQL深度解析/">Flink SQL 深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/13/利用ogg实现oracle到kafka的增量数据实时同步/">利用ogg实现oracle到kafka的增量数据实时同步</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/02/kafka生产者和消费者吞吐量测试/">kafka生产者和消费者吞吐量测试</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/kafka生产环境规划/">kafka生产环境规划</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/Kafka0.11版本+Zookeeper-3.4.10集群部署/">Kafka0.11版本+Zookeeper-3.4.10集群部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/17/JsonSchema全套解决方案/">JsonSchema全套解决方案</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://matt33.com/" title="Matt's Blog" target="_blank">Matt's Blog</a><ul></ul><a href="https://www.haomwei.com/technology/maupassant-hexo.html" title="Maupassant's usage" target="_blank">Maupassant's usage</a><ul></ul><a href="https://www.jianshu.com/p/f4332764e8bd" title="hexo's usage" target="_blank">hexo's usage</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Joker's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>