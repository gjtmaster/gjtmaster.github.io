<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Joker&#39;s Blog</title>
  
  <subtitle>高金涛</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://gjtmaster.github.io/"/>
  <updated>2019-07-27T05:59:18.146Z</updated>
  <id>https://gjtmaster.github.io/</id>
  
  <author>
    <name>高金涛</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink1.7.1与Kafka0.11.0.1</title>
    <link href="https://gjtmaster.github.io/2018/11/15/Flink1.7.1%E4%B8%8EKafka0.11.0.1/"/>
    <id>https://gjtmaster.github.io/2018/11/15/Flink1.7.1与Kafka0.11.0.1/</id>
    <published>2018-11-15T02:17:01.000Z</published>
    <updated>2019-07-27T05:59:18.146Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h1 id="Flink的Checkpoint"><a href="#Flink的Checkpoint" class="headerlink" title="Flink的Checkpoint"></a>Flink的Checkpoint</h1><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><ul><li>使用StreamExecutionEnvironment.enableCheckpointing方法来设置开启checkpoint；具体可以使用enableCheckpointing(long interval)，或者enableCheckpointing(long interval, CheckpointingMode mode)；interval用于指定checkpoint的触发间隔(单位milliseconds)，而CheckpointingMode默认是CheckpointingMode.EXACTLY_ONCE，也可以指定为CheckpointingMode.AT_LEAST_ONCE</li><li>也可以通过StreamExecutionEnvironment.getCheckpointConfig().setCheckpointingMode来设置CheckpointingMode，一般对于超低延迟的应用(大概几毫秒)可以使用CheckpointingMode.AT_LEAST_ONCE，其他大部分应用使用CheckpointingMode.EXACTLY_ONCE就可以</li><li>checkpointTimeout用于指定checkpoint执行的超时时间(单位milliseconds)，超时没完成就会被abort掉</li><li>minPauseBetweenCheckpoints用于指定checkpoint coordinator上一个checkpoint完成之后最小等多久可以出发另一个checkpoint，当指定这个参数时，maxConcurrentCheckpoints的值为1</li><li>maxConcurrentCheckpoints用于指定运行中的checkpoint最多可以有多少个，用于包装topology不会花太多的时间在checkpoints上面；如果有设置了minPauseBetweenCheckpoints，则maxConcurrentCheckpoints这个参数就不起作用了(大于1的值不起作用)</li><li>enableExternalizedCheckpoints用于开启checkpoints的外部持久化，但是在job失败的时候不会自动清理，需要自己手工清理state；ExternalizedCheckpointCleanup用于指定当job canceled的时候externalized checkpoint该如何清理，DELETE_ON_CANCELLATION的话，在job canceled的时候会自动删除externalized state，但是如果是FAILED的状态则会保留；RETAIN_ON_CANCELLATION则在job canceled的时候会保留externalized checkpoint state</li><li>failOnCheckpointingErrors用于指定在checkpoint发生异常的时候，是否应该fail该task，默认为true，如果设置为false，则task会拒绝checkpoint然后继续运行</li></ul><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><pre><code>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();// start a checkpoint every 1000 msenv.enableCheckpointing(1000);// advanced options:// set mode to exactly-once (this is the default)env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);// checkpoints have to complete within one minute, or are discardedenv.getCheckpointConfig().setCheckpointTimeout(60000);// make sure 500 ms of progress happen between checkpointsenv.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);// allow only one checkpoint to be in progress at the same timeenv.getCheckpointConfig().setMaxConcurrentCheckpoints(1);// enable externalized checkpoints which are retained after job cancellationenv.getCheckpointConfig().enableExternalizedCheckpoints(ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);// This determines if a task will be failed if an error occurs in the execution of the task’s checkpoint procedure.env.getCheckpointConfig().setFailOnCheckpointingErrors(true);</code></pre><h1 id="FlinkKafkaConsumer011"><a href="#FlinkKafkaConsumer011" class="headerlink" title="FlinkKafkaConsumer011"></a>FlinkKafkaConsumer011</h1><h2 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h2><ul><li>setStartFromGroupOffsets()【默认消费策略】<br>默认读取上次保存的offset信息 如果是应用第一次启动，读取不到上次的offset信息，则会根据这个参数auto.offset.reset的值来进行消费数据</li><li>setStartFromEarliest() 从最早的数据开始进行消费，忽略存储的offset信息</li><li>setStartFromLatest() 从最新的数据进行消费，忽略存储的offset信息</li><li>setStartFromSpecificOffsets(Map&lt;KafkaTopicPartition, Long&gt;)</li></ul><ul><li>当checkpoint机制开启的时候，KafkaConsumer会定期把kafka的offset信息还有其他operator的状态信息一块保存起来。当job失败重启的时候，Flink会从最近一次的checkpoint中进行恢复数据，重新消费kafka中的数据。</li><li>为了能够使用支持容错的kafka Consumer，需要开启checkpoint env.enableCheckpointing(5000); // 每5s checkpoint一次</li><li>Kafka Consumers Offset 自动提交有以下两种方法来设置，可以根据job是否开启checkpoint来区分:<br>(1) Checkpoint关闭时： 可以通过下面两个参数配置<br>enable.auto.commit<br>auto.commit.interval.ms<br>(2) Checkpoint开启时：当执行checkpoint的时候才会保存offset，这样保证了kafka的offset和checkpoint的状态偏移量保持一致。 可以通过这个参数设置<br>setCommitOffsetsOnCheckpoints(boolean)<br>这个参数默认就是true。表示在checkpoint的时候提交offset, 此时，kafka中的自动提交机制就会被忽略</li></ul><h2 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h2><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;    &lt;artifactId&gt;flink-statebackend-rocksdb_2.11&lt;/artifactId&gt;    &lt;version&gt;1.7.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;    &lt;artifactId&gt;flink-connector-kafka-0.11_2.11&lt;/artifactId&gt;    &lt;version&gt;1.7.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;    &lt;version&gt;0.11.0.1&lt;/version&gt;&lt;/dependency&gt; public class StreamingKafkaSource {    public static void main(String[] args) throws Exception {        //获取Flink的运行环境        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        //checkpoint配置        env.enableCheckpointing(5000);        env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);        env.getCheckpointConfig().setCheckpointTimeout(60000);        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);        env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);        //设置statebackend        //env.setStateBackend(new RocksDBStateBackend(&quot;hdfs://hadoop100:9000/flink/checkpoints&quot;,true));        String topic = &quot;kafkaConsumer&quot;;        Properties prop = new Properties();        prop.setProperty(&quot;bootstrap.servers&quot;,&quot;SparkMaster:9092&quot;);        prop.setProperty(&quot;group.id&quot;,&quot;kafkaConsumerGroup&quot;);        FlinkKafkaConsumer011&lt;String&gt; myConsumer = new FlinkKafkaConsumer011&lt;&gt;(topic, new SimpleStringSchema(), prop);        myConsumer.setStartFromGroupOffsets();//默认消费策略        DataStreamSource&lt;String&gt; text = env.addSource(myConsumer);        text.print().setParallelism(1);        env.execute(&quot;StreamingFromCollection&quot;);    }}</code></pre><h1 id="FlinkKafkaProducer011"><a href="#FlinkKafkaProducer011" class="headerlink" title="FlinkKafkaProducer011"></a>FlinkKafkaProducer011</h1><h2 id="API-2"><a href="#API-2" class="headerlink" title="API"></a>API</h2><ul><li>Kafka Producer的容错-Kafka 0.9 and 0.10</li><li>如果Flink开启了checkpoint，针对FlinkKafkaProducer09和FlinkKafkaProducer010 可以提供 at-least-once的语义，还需要配置下面两个参数:<br>setLogFailuresOnly(false)<br>setFlushOnCheckpoint(true)</li><li>注意：建议修改kafka 生产者的重试次数retries【这个参数的值默认是0】</li><li>Kafka Producer的容错-Kafka 0.11，如果Flink开启了checkpoint，针对FlinkKafkaProducer011 就可以提供 exactly-once的语义,但是需要选择具体的语义<br>Semantic.NONE<br>Semantic.AT_LEAST_ONCE【默认】<br>Semantic.EXACTLY_ONCE</li></ul><h2 id="实例-2"><a href="#实例-2" class="headerlink" title="实例"></a>实例</h2><pre><code>public class StreamingKafkaSink {    public static void main(String[] args) throws Exception {    //获取Flink的运行环境    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();    //checkpoint配置    env.enableCheckpointing(5000);    env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);    env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);    env.getCheckpointConfig().setCheckpointTimeout(60000);    env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);    env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);    //设置statebackend    //env.setStateBackend(new RocksDBStateBackend(&quot;hdfs://SparkMaster:9000/flink/checkpoints&quot;,true));    DataStreamSource&lt;String&gt; text = env.socketTextStream(&quot;SparkMaster&quot;, 9001, &quot;\n&quot;);    String brokerList = &quot;SparkMaster:9092&quot;;    String topic = &quot;kafkaProducer&quot;;    Properties prop = new Properties();    prop.setProperty(&quot;bootstrap.servers&quot;,brokerList);    //第一种解决方案，设置FlinkKafkaProducer011里面的事务超时时间    //设置事务超时时间    //prop.setProperty(&quot;transaction.timeout.ms&quot;,60000*15+&quot;&quot;);    //第二种解决方案，设置kafka的最大事务超时时间,主要是kafka的配置文件设置。    //FlinkKafkaProducer011&lt;String&gt; myProducer = new FlinkKafkaProducer011&lt;&gt;(brokerList, topic, new SimpleStringSchema());    //使用EXACTLY_ONCE语义的kafkaProducer    FlinkKafkaProducer011&lt;String&gt; myProducer = new FlinkKafkaProducer011&lt;&gt;(topic, new KeyedSerializationSchemaWrapper&lt;String&gt;(new SimpleStringSchema()), prop, FlinkKafkaProducer011.Semantic.EXACTLY_ONCE);    text.addSink(myProducer);    env.execute(&quot;StreamingFromCollection&quot;);  }}</code></pre>]]></content>
    
    <summary type="html">
    
      本文主要讲述Flink1.7.1与Kafka0.11.0.1交互相关API的使用与案例。
    
    </summary>
    
      <category term="实时计算框架" scheme="https://gjtmaster.github.io/categories/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
    
      <category term="Flink" scheme="https://gjtmaster.github.io/tags/Flink/"/>
    
      <category term="实时计算" scheme="https://gjtmaster.github.io/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Kafka" scheme="https://gjtmaster.github.io/tags/Kafka/"/>
    
      <category term="消息中间件" scheme="https://gjtmaster.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>Flink On Yarn HA</title>
    <link href="https://gjtmaster.github.io/2018/11/10/Flink%20on%20Yarn%20HA/"/>
    <id>https://gjtmaster.github.io/2018/11/10/Flink on Yarn HA/</id>
    <published>2018-11-10T05:15:07.000Z</published>
    <updated>2019-08-25T08:49:04.146Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 关闭防火墙</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配好主机映射</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置免密登录</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 准备好安装包 hadoop-2.8.5.tar.gz、flink-1.7.1-bin-hadoop28-scala_2.11.tar.gz</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建flink用户，后续操作均在flink用户下操作</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将Hadoop安装包解压至flink01节点的/data/apps路径下</span></span><br><span class="line">tar -zxvf ~/hadoop-2.8.5.tar.gz -C /data/apps</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将flink安装包解压至flink01节点的/data/apps路径下</span></span><br><span class="line">tar -zxvf ~/flink-1.7.1-bin-hadoop28-scala_2.11.tar.gz -C /data/apps</span><br><span class="line"><span class="meta">#</span><span class="bash"> 节点配置如下：</span></span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">IP</th><th align="center">hostname</th><th align="center">配置</th><th align="center">节点名称</th></tr></thead><tbody><tr><td align="center">192.168.23.51</td><td align="center">flink01</td><td align="center">4核cpu/8G内存/50G硬盘</td><td align="center">QuorumPeerMain、JournalNode、NodeManager、NameNode、DFSZKFailoverController、DataNode</td></tr><tr><td align="center">192.168.23.52</td><td align="center">flink02</td><td align="center">4核cpu/8G内存/50G硬盘</td><td align="center">QuorumPeerMain、JournalNode、NodeManager、 NameNode、DFSZKFailoverController、DataNode、ResourceManager</td></tr><tr><td align="center">192.168.23.53</td><td align="center">flink03</td><td align="center">4核cpu/8G内存/50G硬盘</td><td align="center">QuorumPeerMain、JournalNode、NodeManager、ResourceManager、DataNode</td></tr></tbody></table><h2 id="Hadoop-HA配置"><a href="#Hadoop-HA配置" class="headerlink" title="Hadoop HA配置"></a>Hadoop HA配置</h2><h3 id="进入hadoop配置目录"><a href="#进入hadoop配置目录" class="headerlink" title="进入hadoop配置目录"></a>进入hadoop配置目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 进入hadoop配置目录</span></span><br><span class="line">cd /data/apps/hadoop-2.8.5/etc/hadoop</span><br></pre></td></tr></table></figure><h3 id="修改Java环境配置"><a href="#修改Java环境配置" class="headerlink" title="修改Java环境配置"></a>修改Java环境配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 修改hadoop-env.sh中的JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_181</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置yarn-env.sh中的JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_181</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置mapred-env.sh中的JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_181</span><br></pre></td></tr></table></figure><h3 id="配置slaves"><a href="#配置slaves" class="headerlink" title="配置slaves"></a>配置slaves</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim slaves   内容如下</span><br></pre></td></tr></table></figure><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fli<span class="symbol">nk01</span></span><br><span class="line">fli<span class="symbol">nk02</span></span><br><span class="line">fli<span class="symbol">nk03</span></span><br></pre></td></tr></table></figure><h3 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置core-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hdfs的nameservice为ns1 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 修改hadoop临时保存目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/apps/hadoop-2.8.5/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定zookeeper地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>flink01:2181,flink02:2181,flink03:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ipc.client.connect.max.retries<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>ipc.client.connect.retry.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置hdfs-site-xml"><a href="#配置hdfs-site-xml" class="headerlink" title="配置hdfs-site.xml"></a>配置hdfs-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置HDFS 的复制因子 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 关闭HDFS 权限检查，在hdfs-site.xml文件中增加如下配置信息 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/apps/hadoop-2.8.5/tmp/dfs/name1,/data/apps/hadoop-2.8.5/tmp/dfs/name2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/apps/hadoop-2.8.5/tmp/dfs/data1,/data/apps/hadoop-2.8.5/tmp/dfs/data2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn1的RPC通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn1的http通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn2的RPC通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink02:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nn2的http通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink02:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://flink01:8485;flink02:8485;flink03:8485/ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/apps/hadoop-2.8.5/tmp/journal<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启NameNode失败自动切换 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置失败自动切换实现方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行</span></span><br><span class="line"><span class="comment">sshfence:当Active出问题后，standby切换成Active，此时，原Active又没有停止服务，这种情况下会被强制杀死进程。</span></span><br><span class="line"><span class="comment">shell(/bin/true)：NN Active和它的ZKFC一起挂了，没有人通知ZK，ZK长期没有接到通知，standby要切换，此时，standby调一个shell（脚本内容），这个脚本返回true则切换成功。</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">sshfence</span><br><span class="line">shell(/bin/true)</span><br><span class="line"><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 使用隔离机制时需要ssh免登陆 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/flink/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置sshfence隔离机制超时时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.connect-timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置mapred-site-xml"><a href="#配置mapred-site-xml" class="headerlink" title="配置mapred-site.xml"></a>配置mapred-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置Mapreduce 框架运行名称yarn --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 单个Map task 申请的内存大小 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 单个Reduce task 申请的内存大小 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Uber模式是Hadoop2中针对小文件作业的一种优化，如果作业量足够小，可以把一个task，在一个JVM中运行完成.--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置历史服务器 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>flink01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置yarn-site-xml"><a href="#配置yarn-site-xml" class="headerlink" title="配置yarn-site.xml"></a>配置yarn-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 开启RM高可用 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定RM的cluster id --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>rmcluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定RM的名字 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 分别指定RM的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定zookeeper集群的地址--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink01:2181,flink02:2181,flink03:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--启用自动恢复--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置yarn中的服务类 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>A comma separated list of services where service name should only</span><br><span class="line">      contain a-zA-Z0-9_ and can not start with numbers<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line"><span class="comment">&lt;!-- AM重启最大尝试次数 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum number of application attempts. It's a global</span><br><span class="line">    setting for all application masters. Each application master can specify</span><br><span class="line">    its individual maximum number of application attempts via the API, but the</span><br><span class="line">    individual number cannot be more than the global upper bound. If it is,</span><br><span class="line">    the resourcemanager will override it. The default number is set to 2, to</span><br><span class="line">    allow at least one retry for AM.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启物理内存限制 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether physical memory limits will be enforced for</span><br><span class="line">    containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line"><span class="comment">&lt;!-- 关闭虚拟内存限制 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether virtual memory limits will be enforced for</span><br><span class="line">    containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存和物理内存比例 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Ratio between virtual memory to physical memory when</span><br><span class="line">        setting memory limits for containers. Container allocations are</span><br><span class="line">        expressed in terms of physical memory, and virtual memory usage</span><br><span class="line">        is allowed to exceed this allocation by this ratio.</span><br><span class="line">        <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最小内存 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at the RM,</span><br><span class="line">    in MBs. Memory requests lower than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最大内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the RM,</span><br><span class="line">    in MBs. Memory requests higher than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>6144<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最小virtual CPU cores --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at the RM,</span><br><span class="line">    in terms of virtual CPU cores. Requests lower than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最大virtual CPU cores --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the RM,</span><br><span class="line">    in terms of virtual CPU cores. Requests higher than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 限制 NodeManager 能够使用的最大物理内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Flag to determine if logical processors(such as</span><br><span class="line">    hyperthreads) should be counted as cores. Only applicable on Linux</span><br><span class="line">    when yarn.nodemanager.resource.cpu-vcores is set to -1 and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is true.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>6144<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- 限制 NodeManager 能够使用的最大virtual CPU cores --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of vcores that can be allocated</span><br><span class="line">    for containers. This is used by the RM scheduler when allocating</span><br><span class="line">    resources for containers. This is not used to limit the number of</span><br><span class="line">    CPUs used by YARN containers. If it is set to -1 and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is true, it is</span><br><span class="line">    automatically determined from the hardware in case of Windows and Linux.</span><br><span class="line">    In other cases, number of vcores is 8 by default.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 启用日志聚集功能 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether to enable log aggregation. Log aggregation collects</span><br><span class="line">      each container's logs and moves these logs onto a file-system, for e.g.</span><br><span class="line">      HDFS, after the application completes. Users can configure the</span><br><span class="line">      "yarn.nodemanager.remote-app-log-dir" and</span><br><span class="line">      "yarn.nodemanager.remote-app-log-dir-suffix" properties to determine</span><br><span class="line">      where these logs are moved to. Users can access the logs via the</span><br><span class="line">      Application Timeline Server.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置HDFS上日志的保存时间,默认设置为7天--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Time in seconds to retain user logs. Only applicable if</span><br><span class="line">    log aggregation is disabled<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置capacity-scheduler-xml"><a href="#配置capacity-scheduler-xml" class="headerlink" title="配置capacity-scheduler.xml"></a>配置capacity-scheduler.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.maximum-am-resource-percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>集群中可用于运行application master的资源比例上限.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="启动Zookeeper集群"><a href="#启动Zookeeper集群" class="headerlink" title="启动Zookeeper集群"></a>启动Zookeeper集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink01、flink02、flink03执行以下命令</span></span><br><span class="line">bin/zkServer.sh start</span><br></pre></td></tr></table></figure><h3 id="初始化Hadoop环境"><a href="#初始化Hadoop环境" class="headerlink" title="初始化Hadoop环境"></a>初始化Hadoop环境</h3><p>启动journalnode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink01、flink02、flink03执行以下命令</span></span><br><span class="line">sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure><p>格式化namenode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink01执行以下命令</span></span><br><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure><p>格式化zk</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink01执行以下命令</span></span><br><span class="line">bin/hdfs zkfc -formatZK</span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行完成后，会在zookeeper 上创建一个目录，查看是否创建成功：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入zookeeper家目录，执行bin/zkCli.sh客户端连接ZK。在ZK客户端的shell命令行查看：ls /</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 出现hadoop-ha即表示成功。</span></span><br></pre></td></tr></table></figure><p>启动主namenode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink01执行以下命令</span></span><br><span class="line">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><p>备用NN 同步主NN信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink02执行以下命令</span></span><br><span class="line">bin/hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure><p>关闭已启动的所有journalnode和主namenode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink01执行以下命令</span></span><br><span class="line">sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure><h3 id="启动hadoop集群"><a href="#启动hadoop集群" class="headerlink" title="启动hadoop集群"></a>启动hadoop集群</h3><p>启动HDFS</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink01执行以下命令（建议先启动所有journalnode以防出现namenode连接journalnode超时）</span></span><br><span class="line">sbin/start-dfs.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看两个namenode的状态</span></span><br><span class="line">bin/hdfs haadmin -getServiceState nn1     #查看nn1状态</span><br><span class="line">bin/hdfs haadmin -getServiceState nn2     #查看nn2状态</span><br><span class="line"><span class="meta">#</span><span class="bash"> 手动切换namenode状态（此处禁用，有需要再执行）</span></span><br><span class="line">bin/hdfs haadmin -transitionToActive nn1##切换成active</span><br><span class="line">bin/hdfs haadmin -transitionToStandby nn1##切换成standby</span><br></pre></td></tr></table></figure><p>启动Yarn</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在flink02执行以下命令</span></span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在flink03执行以下命令</span></span><br><span class="line">sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看两个Resourcemanager的状态</span></span><br><span class="line">bin/yarn rmadmin -getServiceState rm1      ##查看rm1的状态</span><br><span class="line">bin/yarn rmadmin -getServiceState rm2      ##查看rm2的状态</span><br><span class="line"><span class="meta">#</span><span class="bash"> 当flink02的ResourceManager是Active状态的时候，访问flink03的ResourceManager会自动跳转到flink02的web页面</span></span><br></pre></td></tr></table></figure><h2 id="Flink-HA配置"><a href="#Flink-HA配置" class="headerlink" title="Flink HA配置"></a>Flink HA配置</h2><h3 id="进入flink配置目录"><a href="#进入flink配置目录" class="headerlink" title="进入flink配置目录"></a>进入flink配置目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/apps/flink-1.7.1/conf</span><br></pre></td></tr></table></figure><h3 id="修改flink-conf-yaml"><a href="#修改flink-conf-yaml" class="headerlink" title="修改flink-conf.yaml"></a>修改flink-conf.yaml</h3><p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8/ops/config.html" target="_blank" rel="noopener">点此查看flink配置说明</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The config parameter defining the network address to connect to <span class="keyword">for</span> communication with the job manager. This value is only interpreted <span class="keyword">in</span> setups <span class="built_in">where</span> a single JobManager with static name or address exists (simple standalone setups, or container setups with dynamic service name resolution). It is not used <span class="keyword">in</span> many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</span></span><br><span class="line">jobmanager.rpc.address: flink01</span><br><span class="line"><span class="meta">#</span><span class="bash"> JVM heap size <span class="keyword">for</span> the JobManager.</span></span><br><span class="line">jobmanager.heap.size: 1024m</span><br><span class="line"><span class="meta">#</span><span class="bash"> JVM heap size <span class="keyword">for</span> the TaskManagers, <span class="built_in">which</span> are the parallel workers of the system. On YARN setups, this value is automatically configured to the size of the TaskManager<span class="string">'s YARN container, minus a certain tolerance value.</span></span></span><br><span class="line">taskmanager.heap.size: 2048m</span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of parallel operator or user <span class="keyword">function</span> instances that a single TaskManager can run. If this value is larger than 1, a single TaskManager takes multiple instances of a <span class="keyword">function</span> or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or <span class="keyword">function</span> instances. This value is typically proportional to the number of physical CPU cores that the TaskManager<span class="string">'s machine has (e.g., equal to the number of cores, or half the number of cores).</span></span></span><br><span class="line">taskmanager.numberOfTaskSlots: 4</span><br><span class="line"><span class="meta">#</span><span class="bash"> Default parallelism <span class="keyword">for</span> <span class="built_in">jobs</span>.</span></span><br><span class="line">parallelism.default: 2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Defines high-availability mode used <span class="keyword">for</span> the cluster execution. To <span class="built_in">enable</span> high-availability, <span class="built_in">set</span> this mode to <span class="string">"ZOOKEEPER"</span> or specify FQN of factory class.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> high-availability mode (required): The high-availability mode has to be <span class="built_in">set</span> <span class="keyword">in</span> conf/flink-conf.yaml to zookeeper <span class="keyword">in</span> order to <span class="built_in">enable</span> high availability mode. Alternatively this option can be <span class="built_in">set</span> to FQN of factory class Flink should use to create HighAvailabilityServices instance.</span></span><br><span class="line">high-availability: zookeeper</span><br><span class="line"><span class="meta">#</span><span class="bash"> File system path (URI) <span class="built_in">where</span> Flink persists metadata <span class="keyword">in</span> high-availability setups.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Storage directory (required): JobManager metadata is persisted <span class="keyword">in</span> the file system storageDir and only a pointer to this state is stored <span class="keyword">in</span> ZooKeeper.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The storageDir stores all metadata needed to recover a JobManager failure.</span></span><br><span class="line">high-availability.storageDir: hdfs://ns1/flink/recovery</span><br><span class="line"><span class="meta">#</span><span class="bash"> The ZooKeeper quorum to use, when running Flink <span class="keyword">in</span> a high-availability mode with ZooKeeper.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ZooKeeper quorum (required): A ZooKeeper quorum is a replicated group of ZooKeeper servers, <span class="built_in">which</span> provide the distributed coordination service.</span></span><br><span class="line">high-availability.zookeeper.quorum: flink01:2181,flink02:2181,flink03:2181</span><br><span class="line"><span class="meta">#</span><span class="bash"> The root path under <span class="built_in">which</span> Flink stores its entries <span class="keyword">in</span> ZooKeeper.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ZooKeeper root (recommended): The root ZooKeeper node, under <span class="built_in">which</span> all cluster nodes are placed.</span></span><br><span class="line">high-availability.zookeeper.path.root: /flink</span><br><span class="line"><span class="meta">#</span><span class="bash"> yarn.application-attempts: The number of ApplicationMaster (+ its TaskManager containers) attempts. If this value is <span class="built_in">set</span> to 1 (default), the entire YARN session will fail when the Application master fails. Higher values specify the number of restarts of the ApplicationMaster by YARN.</span></span><br><span class="line">yarn.application-attempts: 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The state backend to be used to store and checkpoint state.</span></span><br><span class="line">state.backend: rocksdb</span><br><span class="line"><span class="meta">#</span><span class="bash"> The default directory used <span class="keyword">for</span> storing the data files and meta data of checkpoints <span class="keyword">in</span> a Flink supported filesystem. The storage path must be accessible from all participating processes/nodes(i.e. all TaskManagers and JobManagers).</span></span><br><span class="line">state.checkpoints.dir: hdfs://ns1/flink/flink-checkpoints</span><br><span class="line"><span class="meta">#</span><span class="bash"> The default directory <span class="keyword">for</span> savepoints. Used by the state backends that write savepoints to file systems (MemoryStateBackend, FsStateBackend, RocksDBStateBackend).</span></span><br><span class="line">state.savepoints.dir: hdfs://ns1/flink/save-checkpoints</span><br><span class="line"><span class="meta">#</span><span class="bash"> Option whether the state backend should create incremental checkpoints, <span class="keyword">if</span> possible. For an incremental checkpoint, only a diff from the previous checkpoint is stored, rather than the complete checkpoint state. Some state backends may not support incremental checkpoints and ignore this option.</span></span><br><span class="line">state.backend.incremental: true</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Directories <span class="keyword">for</span> temporary files, separated by<span class="string">","</span>, <span class="string">"|"</span>, or the system<span class="string">'s java.io.File.pathSeparator.</span></span></span><br><span class="line">io.tmp.dirs: /data/apps/flinkapp/tmp</span><br></pre></td></tr></table></figure><p>切记：Flink On Yarn HA一定不要手动配置high-availability.cluster-id</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The ID of the Flink cluster, used to separate multiple Flink clusters from each other. Needs to be <span class="built_in">set</span> <span class="keyword">for</span> standalone clusters but is automatically inferred <span class="keyword">in</span> YARN and Mesos.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ZooKeeper cluster-id (recommended): The cluster-id ZooKeeper node, under <span class="built_in">which</span> all required coordination data <span class="keyword">for</span> a cluster is placed.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The ID of the Flink cluster, used to separate multiple Flink clusters from each other. Needs to be <span class="built_in">set</span> <span class="keyword">for</span> standalone clusters but is automatically inferred <span class="keyword">in</span> YARN and Mesos.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Important: You should not <span class="built_in">set</span> this value manually when running a YARN cluster, a per-job YARN session, or on another cluster manager. In those cases a cluster-id is automatically being generated based on the application id. Manually setting a cluster-id overrides this behaviour <span class="keyword">in</span> YARN. Specifying a cluster-id with the -z CLI option, <span class="keyword">in</span> turn, overrides manual configuration. If you are running multiple Flink HA clusters on bare metal, you have to manually configure separate cluster-ids <span class="keyword">for</span> each cluster.</span></span><br><span class="line">high-availability.cluster-id: /default</span><br></pre></td></tr></table></figure><h3 id="替换日志框架为logback"><a href="#替换日志框架为logback" class="headerlink" title="替换日志框架为logback"></a>替换日志框架为logback</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 移除flink的lib目录下log4j及slf4j-log4j12的jar(如log4j-1.2.17.jar及slf4j-log4j12-1.7.15.jar)；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 移除flink的conf目录下log4j相关的配置文件（如log4j-cli.properties、log4j-console.properties、log4j.properties、log4j-yarn-session.properties）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加logback-classic.jar、logback-core.jar、log4j-over-slf4j.jar到flink的lib目录下</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 自定义logback的配置，覆盖flink的conf目录下的logback.xml、logback-console.xml、logback-yarn.xml</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用flink-daemon.sh启动的flink使用的logback配置文件是logback.xml；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用flink-console.sh启动的flink使用的logback配置文件是logback-console.xml；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用yarn-session.sh启动的flink使用的logback配置文件是logback-yarn.xml</span></span><br></pre></td></tr></table></figure><p><strong>logback-yarn.xml配置示例</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"60 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义日志文件的存储目录,勿使用相对路径--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LOG_HOME"</span> <span class="attr">value</span>=<span class="string">"/data/apps/flinkapp/logs"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %msg：日志消息，%n是换行符--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"pattern"</span> <span class="attr">value</span>=<span class="string">"%d&#123;yyyyMMdd:HH:mm:ss.SSS&#125; [%thread] %-5level  %msg%n"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 控制台输出 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>System.out<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--  &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt;</span></span><br><span class="line"><span class="comment">            &lt;level&gt;INFO&lt;/level&gt;</span></span><br><span class="line"><span class="comment">        &lt;/filter&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$&#123;pattern&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- INFO_FILE --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"INFO_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;LOG_HOME&#125;/info/info.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--只输出INFO--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>INFO<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LOG_HOME&#125;/info/info_%d&#123;yyyy-MM-dd&#125;.log.%i.gz<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>10MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$&#123;pattern&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- ERROR_FILE --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"ERROR_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;LOG_HOME&#125;/error/error.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--只输出ERROR--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>ERROR<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LOG_HOME&#125;/error/error_%d&#123;yyyy-MM-dd&#125;.log.%i.gz<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>10MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$&#123;pattern&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.haier.flink"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"INFO_FILE"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"ERROR_FILE"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.Connection"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.Statement"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.PreparedStatement"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--根logger--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"INFO"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Flink-on-Yarn-HA测试说明"><a href="#Flink-on-Yarn-HA测试说明" class="headerlink" title="Flink on Yarn HA测试说明"></a>Flink on Yarn HA测试说明</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开始一个yarn-session（命名为FlinkTestCluster）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> JobManager内存2048M</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 每个TaskManager内存2048M且分配4个slot（The session cluster will automatically allocate additional containers <span class="built_in">which</span> run the Task Managers when <span class="built_in">jobs</span> are submitted to the cluster.）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 分离式模式启动</span></span><br><span class="line">yarn-session.sh -jm 2048 -tm 2048 -s 4 -nm FlinkTestCluster -d</span><br></pre></td></tr></table></figure><table><thead><tr><th>配置</th><th>测试方案</th><th>现象</th><th>备注</th></tr></thead><tbody><tr><td>Job本身配置了Flink的重启策略</td><td>提供bug程序，导致Job失败</td><td>重启失败的Job</td><td>保证Job HA</td></tr><tr><td>Yarn的yarn-site.xml配置了yarn.resourcemanager.am.max-attempts、Flink的flink-conf.yaml配置了yarn.application-attempts</td><td>kill掉YarnSessionClusterEntrypoint进程（<em>JobManager</em>和AM的共同进程）</td><td>重启JobManager和AM，该进程会迁移到其它节点（非必须）且进程号改变，全部Job重启</td><td>保证JobManager HA</td></tr><tr><td>Job本身配置了Flink的重启策略、Yarn的yarn-site.xml配置了yarn.resourcemanager.am.max-attempts、Flink的flink-conf.yaml配置了yarn.application-attempts</td><td>kill掉YarnTaskExecutorRunner进程（TaskManager进程）</td><td>重启TaskManager，该进程会迁移到其它节点（非必须）且进程号改变，被Kill掉的TaskManager包含的Job重启</td><td>保证TaskManager HA</td></tr><tr><td>Yarn的yarn-site.xml配置了yarn.resourcemanager.am.max-attempts、Flink的flink-conf.yaml配置了high-availability.zookeeper.quorum、high-availability.storageDir、high-availability.zookeeper.path.root、yarn.application-attempts</td><td>未主动Cancel掉Flink集群中的Job，但不小心kill掉对应的yarn-session(对应Yarn队列中的一个Application)、之后在命令行重新提交yarn-session</td><td>启动新的yarn-session、之前未Cancel掉的Job自动迁移到当前yarn-session、JobManager和TaskManager自动创建</td><td>保证 YarnSessionHA</td></tr><tr><td>Yarn的yarn-site.xml配置了yarn.resourcemanager.am.max-attempts、Flink的flink-conf.yaml配置了high-availability.zookeeper.quorum、high-availability.storageDir、high-availability.zookeeper.path.root、yarn.application-attempts、配置了Yarn的HA</td><td>Kill掉Resourcemanager</td><td>ResourceManager迁移到另一台节点，yarn-session重启，所有Job重启</td><td>保证Yarn HA</td></tr><tr><td>Yarn的yarn-site.xml配置了yarn.resourcemanager.am.max-attempts、Flink的flink-conf.yaml配置了high-availability.zookeeper.quorum、high-availability.storageDir、high-availability.zookeeper.path.root、yarn.application-attempts（也可在yarn-session提交时通过-D动态配置）、配置了HDFS的HA</td><td>Kill掉NameNode</td><td>NameNode迁移到另一台节点</td><td>保证HDFS HA</td></tr></tbody></table><h2 id="Yarn的基本思想"><a href="#Yarn的基本思想" class="headerlink" title="Yarn的基本思想"></a>Yarn的基本思想</h2><p>YARN的基本思想是将资源管理和作业调度/监视的功能分解为单独的守护进程。我们的想法是拥有一个全局ResourceManager（<em>RM</em>）和每个应用程序ApplicationMaster（<em>AM</em>）。应用程序可以是单个作业，也可以是作业的DAG。</p><p>ResourceManager和NodeManager构成了数据计算框架。ResourceManager是在系统中的所有应用程序之间仲裁资源的最终权限。NodeManager是每台机器上负责Containers的代理框架，监视其资源使用情况（CPU，内存，磁盘，网络）并将其报告给ResourceManager / Scheduler。</p><p>每个应用程序ApplicationMaster实际上是一个含具体库的框架，其任务是协调来自ResourceManager的资源，并与NodeManager一起执行和监视任务。</p><p><img src="https://hadoop.apache.org/docs/r2.8.5/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif" alt="MapReduce NextGen架构"></p><p>ResourceManager有两个主要组件：Scheduler和ApplicationsManager。</p><p>Scheduler负责根据熟悉的容量，队列等约束将资源分配给各种正在运行的应用程序。Scheduler是纯调度程序，因为它不执行应用程序状态的监视或跟踪。此外，当出现应用程序故障或硬件故障，它无法保证重新启动失败的任务。Scheduler根据应用程序的资源需求执行其调度功能; 它是基于资源<em>Container</em>的抽象概念，它包含内存，CPU，磁盘，网络等元素。</p><p>Scheduler具有可插入策略，该策略负责在各种队列，应用程序等之间对集群资源进行分区。当前的调度程序（如<a href="https://hadoop.apache.org/docs/r2.8.5/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html" target="_blank" rel="noopener">CapacityScheduler</a>和<a href="https://hadoop.apache.org/docs/r2.8.5/hadoop-yarn/hadoop-yarn-site/FairScheduler.html" target="_blank" rel="noopener">FairScheduler）</a>将是插件的一些示例。</p><p>ApplicationsManager负责接受作业提交，协商第一个容器以执行特定于应用程序的ApplicationMaster，并提供在失败时重新启动ApplicationMaster容器的服务。每个应用程序ApplicationMaster负责从Scheduler协调适当的资源容器，跟踪其状态并监视进度。</p><h2 id="Flink-on-Yarn的基本思想"><a href="#Flink-on-Yarn的基本思想" class="headerlink" title="Flink on Yarn的基本思想"></a>Flink on Yarn的基本思想</h2><p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.7/fig/FlinkOnYarn.svg" alt="img"></p><p>YARN客户端需要访问Hadoop配置以连接到YARN资源管理器和HDFS。它使用以下策略确定Hadoop配置：</p><ul><li>按顺序测试是否配置<code>YARN_CONF_DIR</code>，<code>HADOOP_CONF_DIR</code>或<code>HADOOP_CONF_PATH</code>。如果设置了其中一个变量，则用于读取配置。</li><li>如果上述策略失败（在正确的YARN设置中不应该这样），则客户端使用配置的<code>HADOOP_HOME</code>环境变量。如果<code>HADOOP_HOME</code>环境变量已配置，则客户端尝试访问<code>$HADOOP_HOME/etc/hadoop</code>（Hadoop 2）或<code>$HADOOP_HOME/conf</code>（Hadoop 1）。</li></ul><p>启动新的Flink YARN会话时，客户端首先检查所请求的资源（ApplicationMaster的memory和vcores）是否可用。之后，它将包含Flink的jar包和配置信息上传到HDFS（步骤1）。</p><p>客户端的下一步是请求（步骤2）YARN容器以启动<em>ApplicationMaster</em>（步骤3）。客户端将配置信息和jar文件注册为容器的资源，在特定机器上运行的NodeManager将负责准备容器（例如下载文件的工作）。完成后，将启动<em>ApplicationMaster</em>（AM）。</p><p>该<em>JobManager</em>和AM在同一容器中运行。一旦它们成功启动，AM就知道JobManager（Flink主机）的地址。它正在为TaskManagers生成一个新的Flink配置文件（以便它们可以连接到JobManager），该文件也上传到HDFS。此外，<em>AM</em>容器还提供Flink的Web界面。YARN代码分配的所有端口都是<em>临时端口</em>。这允许用户并行执行多个Flink YARN会话。</p><p>之后，AM开始为Flink的TaskManagers分配容器（步骤4），这将从HDFS下载jar文件和修改后的配置。完成这些步骤后，即可建立Flink并准备接受作业。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://hadoop.apache.org/docs/r2.8.5/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html" target="_blank" rel="noopener">HDFS High Availability Using the Quorum Journal Manager</a> </p><p><a href="https://hadoop.apache.org/docs/r2.8.5/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html" target="_blank" rel="noopener">ResourceManager High Availability</a></p><p><a href="https://hadoop.apache.org/docs/r2.8.5/hadoop-yarn/hadoop-yarn-site/YARN.html" target="_blank" rel="noopener">Apache Hadoop YARN</a></p><p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/jobmanager_high_availability.html#yarn-cluster-high-availability" target="_blank" rel="noopener">JobManager High Availability (HA)</a></p><p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/deployment/yarn_setup.html" target="_blank" rel="noopener">Flink on Yarn</a></p>]]></content>
    
    <summary type="html">
    
      本文主要讲述了Flink on Yarn 高可用的集群部署方案。
    
    </summary>
    
      <category term="实时计算框架" scheme="https://gjtmaster.github.io/categories/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
    
      <category term="Flink" scheme="https://gjtmaster.github.io/tags/Flink/"/>
    
      <category term="Yarn" scheme="https://gjtmaster.github.io/tags/Yarn/"/>
    
      <category term="Flink on Yarn" scheme="https://gjtmaster.github.io/tags/Flink-on-Yarn/"/>
    
  </entry>
  
  <entry>
    <title>Flink On Yarn集群部署</title>
    <link href="https://gjtmaster.github.io/2018/10/15/Flink%20On%20Yan%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>https://gjtmaster.github.io/2018/10/15/Flink On Yan集群部署/</id>
    <published>2018-10-15T05:15:07.000Z</published>
    <updated>2019-08-03T14:26:05.960Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 关闭防火墙</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配好主机映射</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建flink用户</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置免密登录</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 准备好相关资源：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop-2.8.5.tar.gz</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> flink-1.7.1-bin-hadoop28-scala_2.11</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> logback-classic.jar、logback-core.jar、log4j-over-slf4j.jar</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 节点配置如下：(建议每台NM节点预留2G内存给系统)</span></span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">hostname</th><th align="center">资源配置</th><th align="center">节点名称</th></tr></thead><tbody><tr><td align="center">flink01</td><td align="center">16G/16cores</td><td align="center">NameNode/DataNode/NodeManager</td></tr><tr><td align="center">flink02</td><td align="center">16G/16cores</td><td align="center">ResourceManager/DataNode/NodeManager</td></tr><tr><td align="center">flink03</td><td align="center">16G/16cores</td><td align="center">SecondaryNameNode/DataNode/NodeManager</td></tr><tr><td align="center">flink04</td><td align="center">16G/16cores</td><td align="center">DataNode/NodeManager</td></tr><tr><td align="center">flink05</td><td align="center">16G/16cores</td><td align="center">DataNode/NodeManager</td></tr><tr><td align="center">flink06</td><td align="center">16G/16cores</td><td align="center">DataNode/NodeManager</td></tr></tbody></table><h2 id="Hadoop配置"><a href="#Hadoop配置" class="headerlink" title="Hadoop配置"></a>Hadoop配置</h2><h3 id="将Hadoop安装包解压至flink01节点的-data-apps路径下"><a href="#将Hadoop安装包解压至flink01节点的-data-apps路径下" class="headerlink" title="将Hadoop安装包解压至flink01节点的/data/apps路径下"></a>将Hadoop安装包解压至flink01节点的/data/apps路径下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ~/hadoop-2.8.5.tar.gz -C /data/apps</span><br></pre></td></tr></table></figure><h3 id="进入配置目录"><a href="#进入配置目录" class="headerlink" title="进入配置目录"></a>进入配置目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/apps/hadoop-2.8.5/etc/hadoop</span><br></pre></td></tr></table></figure><h3 id="修改hadoop-env-sh中的JAVA-HOME"><a href="#修改hadoop-env-sh中的JAVA-HOME" class="headerlink" title="修改hadoop-env.sh中的JAVA_HOME"></a>修改hadoop-env.sh中的JAVA_HOME</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_40</span><br></pre></td></tr></table></figure><h3 id="配置yarn-env-sh中的JAVA-HOME"><a href="#配置yarn-env-sh中的JAVA-HOME" class="headerlink" title="配置yarn-env.sh中的JAVA_HOME"></a>配置yarn-env.sh中的JAVA_HOME</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_40</span><br></pre></td></tr></table></figure><h3 id="配置mapred-env-sh中的JAVA-HOME"><a href="#配置mapred-env-sh中的JAVA-HOME" class="headerlink" title="配置mapred-env.sh中的JAVA_HOME"></a>配置mapred-env.sh中的JAVA_HOME</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_40</span><br></pre></td></tr></table></figure><h3 id="配置slaves"><a href="#配置slaves" class="headerlink" title="配置slaves"></a>配置slaves</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim slaves   内容如下</span><br></pre></td></tr></table></figure><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fli<span class="symbol">nk01</span></span><br><span class="line">fli<span class="symbol">nk02</span></span><br><span class="line">fli<span class="symbol">nk03</span></span><br><span class="line">fli<span class="symbol">nk04</span></span><br><span class="line">fli<span class="symbol">nk05</span></span><br><span class="line">fli<span class="symbol">nk06</span></span><br></pre></td></tr></table></figure><h3 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置core-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置HDFS的路径的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://flink01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 修改hadoop临时保存目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/apps/hadoop-2.8.5/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置hdfs-site-xml"><a href="#配置hdfs-site-xml" class="headerlink" title="配置hdfs-site.xml"></a>配置hdfs-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置HDFS 的复制因子 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 关闭HDFS 权限检查，在hdfs-site.xml文件中增加如下配置信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 该属性定义了 HDFS WEB访问服务器的主机名和端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>flink01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 定义secondarynamenode 外部地址 访问的主机和端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>flink03:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置mapred-site-xml"><a href="#配置mapred-site-xml" class="headerlink" title="配置mapred-site.xml"></a>配置mapred-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置Mapreduce 框架运行名称yarn --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 单个Map task 申请的内存大小 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 单个Reduce task 申请的内存大小 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- Uber模式是Hadoop2中针对小文件作业的一种优化，如果作业量足够小，可以把一个task，在一个JVM中运行完成.--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   </span><br><span class="line"><span class="comment">&lt;!-- 配置历史服务器 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>flink01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置yarn-site-xml"><a href="#配置yarn-site-xml" class="headerlink" title="配置yarn-site.xml"></a>配置yarn-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置yarn中的服务类 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>A comma separated list of services where service name should only</span><br><span class="line">      contain a-zA-Z0-9_ and can not start with numbers<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置resourcemanager 的主机位置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">description</span>&gt;</span>The hostname of the RM.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>flink02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- AM重启最大尝试次数 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum number of application attempts. It's a global</span><br><span class="line">    setting for all application masters. Each application master can specify</span><br><span class="line">    its individual maximum number of application attempts via the API, but the</span><br><span class="line">    individual number cannot be more than the global upper bound. If it is,</span><br><span class="line">    the resourcemanager will override it. The default number is set to 2, to</span><br><span class="line">    allow at least one retry for AM.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- 开启物理内存限制 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether physical memory limits will be enforced for</span><br><span class="line">    containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 关闭虚拟内存限制 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether virtual memory limits will be enforced for</span><br><span class="line">    containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存和物理内存比例 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Ratio between virtual memory to physical memory when</span><br><span class="line">        setting memory limits for containers. Container allocations are</span><br><span class="line">        expressed in terms of physical memory, and virtual memory usage</span><br><span class="line">        is allowed to exceed this allocation by this ratio.</span><br><span class="line">        <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">      </span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最小内存 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at the RM,</span><br><span class="line">    in MBs. Memory requests lower than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最大内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the RM,</span><br><span class="line">    in MBs. Memory requests higher than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>7168<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最小virtual CPU cores --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at the RM,</span><br><span class="line">    in terms of virtual CPU cores. Requests lower than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 每个Container请求的最大virtual CPU cores --&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the RM,</span><br><span class="line">    in terms of virtual CPU cores. Requests higher than this will throw a</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 限制 NodeManager 能够使用的最大物理内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Flag to determine if logical processors(such as</span><br><span class="line">    hyperthreads) should be counted as cores. Only applicable on Linux</span><br><span class="line">    when yarn.nodemanager.resource.cpu-vcores is set to -1 and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is true.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>14336<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">&lt;!-- 限制 NodeManager 能够使用的最大virtual CPU cores --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of vcores that can be allocated</span><br><span class="line">    for containers. This is used by the RM scheduler when allocating</span><br><span class="line">    resources for containers. This is not used to limit the number of</span><br><span class="line">    CPUs used by YARN containers. If it is set to -1 and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is true, it is</span><br><span class="line">    automatically determined from the hardware in case of Windows and Linux.</span><br><span class="line">    In other cases, number of vcores is 8 by default.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 启用日志聚集功能 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether to enable log aggregation. Log aggregation collects</span><br><span class="line">      each container's logs and moves these logs onto a file-system, for e.g.</span><br><span class="line">      HDFS, after the application completes. Users can configure the</span><br><span class="line">      "yarn.nodemanager.remote-app-log-dir" and</span><br><span class="line">      "yarn.nodemanager.remote-app-log-dir-suffix" properties to determine</span><br><span class="line">      where these logs are moved to. Users can access the logs via the</span><br><span class="line">      Application Timeline Server.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置HDFS上日志的保存时间,默认设置为7天--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Time in seconds to retain user logs. Only applicable if</span><br><span class="line">    log aggregation is disabled<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>含义</th><th>值</th><th>备注</th></tr></thead><tbody><tr><td>yarn.nodemanager.aux-services</td><td>设置yarn中的服务类</td><td>mapreduce_shuffle</td><td></td></tr><tr><td>yarn.resourcemanager.hostname</td><td>配置resourcemanager 的主机位置</td><td>flink02</td><td></td></tr><tr><td>yarn.resourcemanager.am.max-attempts</td><td>AM重启最大尝试次数</td><td>4</td><td></td></tr><tr><td>yarn.nodemanager.pmem-check-enabled</td><td>开启物理内存限制</td><td>true</td><td>检测物理内存的使用是否超出分配值，若任务超出分配值，则将其杀掉，默认true。</td></tr><tr><td>yarn.nodemanager.vmem-check-enabled</td><td>关闭虚拟内存限制</td><td>false</td><td>检测虚拟内存的使用是否超出；若任务超出分配值，则将其杀掉，默认true。在确定内存不会泄漏的情况下可以设置此项为 False；</td></tr><tr><td>yarn.scheduler.minimum-allocation-mb</td><td>每个Container请求的最小内存</td><td>1024</td><td>单个容器/调度器可申请的最少物理内存量，默认是1024（MB）；一般每个contain都分配这个值；即：capacity memory:3072, vCores:1，如果提示物理内存溢出，提高这个值即可；</td></tr><tr><td>yarn.scheduler.maximum-allocation-mb</td><td>每个Container请求的最大内存</td><td>7168</td><td>单个容器/调度器可申请的最大物理内存量</td></tr><tr><td>yarn.scheduler.minimum-allocation-vcores</td><td>每个Container请求的最小virtual CPU cores</td><td>1</td><td></td></tr><tr><td>yarn.scheduler.maximum-allocation-vcores</td><td>每个Container请求的最大virtual CPU cores</td><td>16</td><td></td></tr><tr><td>yarn.nodemanager.resource.memory-mb</td><td>限制 NodeManager 能够使用的最大物理内存</td><td>14336</td><td>该节点上YARN可使用的物理内存总量，【向操作系统申请的总量】默认是8192（MB）</td></tr><tr><td>yarn.nodemanager.resource.cpu-vcores</td><td>限制 NodeManager 能够使用的最大virtual CPU cores</td><td>16</td><td>该节点上YARN可使用的总核心数；一般设为cat /proc/cpuinfo| grep “processor”| wc -l 的值。默认是8个</td></tr><tr><td>yarn.log-aggregation-enable</td><td>启用日志聚集功能</td><td>true</td><td></td></tr><tr><td>yarn.nodemanager.log.retain-seconds</td><td>设置HDFS上日志的保存时间,默认设置为7天</td><td>10800</td><td></td></tr><tr><td>yarn.nodemanager.vmem-pmem-ratio</td><td>虚拟内存率</td><td>5</td><td>任务每使用1MB物理内存，最多可使用虚拟内存量比率，默认2.1；关闭虚拟内存限制的情况下，配置此项就无意义了</td></tr></tbody></table><h3 id="修改capacity-scheduler-xml"><a href="#修改capacity-scheduler-xml" class="headerlink" title="修改capacity-scheduler.xml"></a>修改capacity-scheduler.xml</h3><p><strong>（flink yarn session启用的jobmanager占用的资源总量受此参数限制）</strong></p><pre><code>&lt;property&gt;    &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt;    &lt;value&gt;0.3&lt;/value&gt;    &lt;description&gt;集群中可用于运行application master的资源比例上限.&lt;/description&gt;&lt;/property&gt;</code></pre><h3 id="快速安装Hadoop"><a href="#快速安装Hadoop" class="headerlink" title="快速安装Hadoop"></a>快速安装Hadoop</h3><p><strong>（使用此脚本安装完后需要单独修改capacity-scheduler.xml）</strong></p><p><strong>将安装脚本和安装包放在相同路径下并执行以下命令可快速完成上述配置步骤！</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 默认相关资源已放在当前用户的~路径下</span></span><br><span class="line">sh ~/install-hadoop.sh</span><br></pre></td></tr></table></figure><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br><span class="line">加入以下内容（这里提前加上了flink的环境变量）：</span><br><span class="line">export FLINK_HOME = /data/apps/flink-1.7.1</span><br><span class="line">export HADOOP_HOME=/data/apps/hadoop-2.8.5</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line">export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$FLINK_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h3><p>格式化NameNode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><p>在NameNode所在节点启动HDFS</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure><p>在ResourceManager所在节点启动YARN</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure><h2 id="Flink集群"><a href="#Flink集群" class="headerlink" title="Flink集群"></a>Flink集群</h2><h3 id="将Hadoop安装包解压至kafka01节点的-data-apps路径下"><a href="#将Hadoop安装包解压至kafka01节点的-data-apps路径下" class="headerlink" title="将Hadoop安装包解压至kafka01节点的/data/apps路径下"></a>将Hadoop安装包解压至kafka01节点的/data/apps路径下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ~/flink-1.7.1-bin-hadoop28-scala_2.11.tar.gz -C /data/apps</span><br></pre></td></tr></table></figure><h3 id="进入配置目录-1"><a href="#进入配置目录-1" class="headerlink" title="进入配置目录"></a>进入配置目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/apps/flink-1.7.1/conf</span><br></pre></td></tr></table></figure><h3 id="修改flink-conf-yaml"><a href="#修改flink-conf-yaml" class="headerlink" title="修改flink-conf.yaml"></a>修改flink-conf.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">jobmanager.rpc.address: flink01</span><br><span class="line">jobmanager.heap.size: 1024m</span><br><span class="line">taskmanager.heap.size: 1024m</span><br><span class="line">parallelism.default: 2</span><br><span class="line">taskmanager.numberOfTaskSlots: 8</span><br><span class="line">state.backend: rocksdb</span><br><span class="line">state.checkpoints.dir: hdfs://flink01:9000/flink-checkpoints</span><br><span class="line">state.savepoints.dir: hdfs://flink01:9000/flink-savepoints</span><br><span class="line">state.backend.incremental: true</span><br><span class="line">io.tmp.dirs: /data/apps/flinkapp/tmp</span><br><span class="line">yarn.application-attempts: 4</span><br></pre></td></tr></table></figure><h3 id="删除Flink原先使用的日志框架log4j相关资源"><a href="#删除Flink原先使用的日志框架log4j相关资源" class="headerlink" title="删除Flink原先使用的日志框架log4j相关资源"></a>删除Flink原先使用的日志框架log4j相关资源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 移除flink的lib目录下log4j及slf4j-log4j12的jar(如log4j-1.2.17.jar及slf4j-log4j12-1.7.15.jar)；</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 移除flink的conf目录下log4j相关的配置文件（如log4j-cli.properties、log4j-console.properties、log4j.properties、log4j-yarn-session.properties）</span></span><br></pre></td></tr></table></figure><h3 id="更换Flink的日志框架为logback"><a href="#更换Flink的日志框架为logback" class="headerlink" title="更换Flink的日志框架为logback"></a>更换Flink的日志框架为logback</h3><p>（1）添加logback-classic.jar、logback-core.jar、log4j-over-slf4j.jar到flink的lib目录下</p><p>（2）自定义logback的配置，覆盖flink的conf目录下的logback.xml、logback-console.xml、logback-yarn.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用flink-daemon.sh启动的flink使用的logback配置文件是logback.xml；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用flink-console.sh启动的flink使用的logback配置文件是logback-console.xml；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用yarn-session.sh启动的flink使用的logback配置文件是logback-yarn.xml</span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"60 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义日志文件的存储目录,勿使用相对路径--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LOG_HOME"</span> <span class="attr">value</span>=<span class="string">"/data/apps/flinkapp/logs"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %msg：日志消息，%n是换行符--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"pattern"</span> <span class="attr">value</span>=<span class="string">"%d&#123;yyyyMMdd:HH:mm:ss.SSS&#125; [%thread] %-5level  %msg%n"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 控制台输出 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>System.out<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--  &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt;</span></span><br><span class="line"><span class="comment">            &lt;level&gt;INFO&lt;/level&gt;</span></span><br><span class="line"><span class="comment">        &lt;/filter&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$&#123;pattern&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- INFO_FILE --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"INFO_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;LOG_HOME&#125;/info/info.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--只输出INFO--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>INFO<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LOG_HOME&#125;/info/info_%d&#123;yyyy-MM-dd&#125;.log.%i.gz<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>50MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$&#123;pattern&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- ERROR_FILE --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"ERROR_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;LOG_HOME&#125;/error/error.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--只输出ERROR--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>ERROR<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LOG_HOME&#125;/error/error_%d&#123;yyyy-MM-dd&#125;.log.%i.gz<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>50MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$&#123;pattern&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.haier.flink"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"INFO_FILE"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"ERROR_FILE"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.Connection"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.Statement"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.PreparedStatement"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--根logger--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"INFO"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Flink-on-Yarn的两种运行模式"><a href="#Flink-on-Yarn的两种运行模式" class="headerlink" title="Flink on Yarn的两种运行模式"></a>Flink on Yarn的两种运行模式</h2><h3 id="Start-a-long-running-Flink-cluster-on-YARN"><a href="#Start-a-long-running-Flink-cluster-on-YARN" class="headerlink" title="Start a long-running Flink cluster on YARN"></a>Start a long-running Flink cluster on YARN</h3><p>​    这种方式需要先启动集群，然后在提交Flink-Job（同一个Session中可以提交多个Flink-Job，可以在Flink的WebUI上submit，也可以使用Flink run命令提交）。启动集群时会向yarn申请一块空间，资源永远保持不变。如果资源满了，下一个作业就无法提交，只能等到yarn中的其中一个作业执行完成，释放了资源，那下一个作业才会正常提交.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 默认配置启动flink on yarn（默认启动资源如下）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> &#123;masterMemoryMB=1024, taskManagerMemoryMB=1024,numberTaskManagers=1, slotsPerTaskManager=1&#125;</span></span><br><span class="line">yarn-session.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############# 系统默认使用con/flink-conf.yaml里的配置，Flink on yarn将会覆盖掉几个参数：</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> jobmanager.rpc.address因为jobmanager的在集群的运行位置并不是事先确定的，其实就是AM的地址；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> taskmanager.tmp.dirs使用yarn给定的临时目录;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> parallelism.default也会被覆盖掉，如果在命令行里指定了slot数。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############# 自定义配置可选参数如下 </span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Required     </span></span><br><span class="line"> -n,--container &lt;arg&gt;   Number of YARN container to allocate (=Number of Task Managers)   </span><br><span class="line"><span class="meta">#</span><span class="bash"> Optional     </span></span><br><span class="line"> -D &lt;arg&gt;                        Dynamic properties     </span><br><span class="line"> -d,--detached                   Start detached     </span><br><span class="line"> -jm,--jobManagerMemory &lt;arg&gt;    Memory for JobManager Container with optional unit (default: MB)     </span><br><span class="line"> -nm,--name                      Set a custom name for the application on YARN     </span><br><span class="line"> -q,--query                      Display available YARN resources (memory, cores)     </span><br><span class="line"> -qu,--queue &lt;arg&gt;               Specify YARN queue.     </span><br><span class="line"> -s,--slots &lt;arg&gt;                Number of slots per TaskManager     </span><br><span class="line"> -tm,--taskManagerMemory &lt;arg&gt;   Memory per TaskManager Container with optional unit (default: MB)     </span><br><span class="line"> -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths for HA mode</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例：启动15个TaskManager，1个JobManager，JobManager内存1024M，每个TaskManager内存1024M且含有8个slot，自定义该应用的名称为FlinkOnYarnSession，-d以分离式模式执行（不指定-d则以客户端模式执行）</span></span><br><span class="line">yarn-session.sh -n 15 -jm 1024 -tm 1024 -s 8 -nm FlinkOnYarnSession -d</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 客户端模式指的是在终端启动一个客户端，这种方式是不能断开终端的，断开即相当于<span class="built_in">kill</span>掉Flink集群</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 分离式模式指的是启动Flink on Yarn后，Flink YARN客户端将仅向Yarn提交Flink，然后自行关闭。，要<span class="built_in">kill</span>掉Flink集群需要使用如下命令：</span></span><br><span class="line">yarn application -kill &lt;appId&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> &lt;appId&gt;指的是发布在Yarn上的作业ID，在Yarn集群上可以查到对应的ID</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 对于Flink On Yarn来说，一个JobManager占用一个Container，一个TaskManager占用一个Container</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> JobManager的数量+TaskManager的数量 = 申请的Container的数量</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 以下以6台16核，16G内存的机器举例说明（每台节点预留2G内存给系统）</span></span><br><span class="line">yarn.nodemanager.resource.cpu-vcores=16 每台NodeManager节点为YARN集群分配的cpu为16核</span><br><span class="line">yarn.nodemanager.resource.memory-mb=14336 每台NodeManager节点为YARN集群分配的物理内存为14G</span><br><span class="line">yarn.scheduler.minimum-allocation-vcores=1 每台NodeManager节点上每个Contaniner最小使用1核cpu</span><br><span class="line">yarn.scheduler.minimum-allocation-mb=1024 每台NodeManager节点上每个Contaniner最小使用1G的物理内存</span><br><span class="line"><span class="meta">#</span><span class="bash"> 若所有节点全部用于Flink作业,推荐提供的Flink集群：</span></span><br><span class="line">（总的资源为14*6=84G内存，16*6=96核）</span><br><span class="line">yarn-session.sh -n 8 -jm 4096 -tm 3584 -s 16 -nm FlinkOnYarnSession -d</span><br><span class="line">一共占用32G内存，9cores，申请了1个4G/1cores的JobManager和8个3.5G/1cores/16slots的TaskManager</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############## Recovery behavior of Flink on YARN</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Flink’s YARN client has the following configuration parameters to control how to behave <span class="keyword">in</span> <span class="keyword">case</span> of container failures. These parameters can be <span class="built_in">set</span> either from the conf/flink-conf.yaml or when starting the YARN session, using -D parameters</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> yarn.reallocate-failed : 控制 Flink是否应该重新分配失败的TaskManager容器，默认<span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> yarn.maximum-failed-containers : ApplicationMaster接收container失败的最大次数，默认是TaskManager的次数（-n的值）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> yarn.application-attempts : ApplicationMaster尝试次数。如果这个值为1（默认），那么当Application Master失败时，整个YARN session就会失败。更高的值是指ApplicationMaster重新启动的次数</span></span><br></pre></td></tr></table></figure><h3 id="Run-a-Flink-job-on-YARN（Flink-per-job-cluster模式）"><a href="#Run-a-Flink-job-on-YARN（Flink-per-job-cluster模式）" class="headerlink" title="Run a Flink job on YARN（Flink per-job cluster模式）"></a>Run a Flink job on YARN（Flink per-job cluster模式）</h3><p>这种方式不需要先启动集群，每提交一个Flink-Job都会在Yarn上启动一个Flink集群。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> TaskManager slots number配置</span></span><br><span class="line">这个参数是配置一个TaskManager有多少个并发的slot数。有两种配置方式：</span><br><span class="line">- taskmanager.numberOfTaskSlots. 在conf/flink-conf.yaml中更改，默认值为1，表示默认一个TaskManager只有1个task slot.</span><br><span class="line">- 提交作业时通过参数配置。--yarnslots 1，表示TaskManager的slot数为1.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> TaskManager的个数</span></span><br><span class="line">注意： Per job模式提交作业时并不像session模式能够指定拉起多少个TaskManager，TaskManager的数量是在提交作业时根据并发度动态计算。</span><br><span class="line">首先，根据设定的operator的最大并发度计算，例如，如果作业中operator的最大并发度为10，则 Parallelism/numberOfTaskSlots为向YARN申请的TaskManager数。</span><br></pre></td></tr></table></figure><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#######################示例</span><br><span class="line"># flink run -m yarn-cluster 必须指定</span><br><span class="line"># -d 分离模式启动（不指定则以客户端模式启动）</span><br><span class="line"># 启动<span class="number">1</span>个JobManager，内存占用<span class="number">1024</span>M</span><br><span class="line"># 每台TaskManager指定<span class="number">4</span>个slot、内存占用<span class="number">1024</span>M</span><br><span class="line"># 假设abc.jar所有operator中最大并发度为<span class="number">8</span>，则会启动<span class="number">8</span>/<span class="number">4</span>=<span class="number">2</span>台TaskManager</span><br><span class="line">flink run -m yarn-cluster -d --yarnslots <span class="number">4</span> -yjm <span class="number">1024</span> -ytm <span class="number">1024</span> /data/abc.jar</span><br></pre></td></tr></table></figure><h2 id="Log-Files"><a href="#Log-Files" class="headerlink" title="Log Files"></a>Log Files</h2><p>In cases where the Flink YARN session fails during the deployment itself, users have to rely on the logging capabilities of Hadoop YARN. The most useful feature for that is the <a href="http://hortonworks.com/blog/simplifying-user-logs-management-and-access-in-yarn/" target="_blank" rel="noopener">YARN log aggregation</a>. To enable it, users have to set the <code>yarn.log-aggregation-enable</code>property to <code>true</code> in the <code>yarn-site.xml</code> file. Once that is enabled, users can use the following command to retrieve all log files of a (failed) YARN session.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn logs -applicationId &lt;application ID&gt;</span><br></pre></td></tr></table></figure><p>Note that it takes a few seconds after the session has finished until the logs show up.</p>]]></content>
    
    <summary type="html">
    
      本文主要讲述了Flink On Yarn的集群部署流程以及两种运行模式。
    
    </summary>
    
      <category term="实时计算框架" scheme="https://gjtmaster.github.io/categories/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
    
      <category term="Flink" scheme="https://gjtmaster.github.io/tags/Flink/"/>
    
      <category term="实时计算" scheme="https://gjtmaster.github.io/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Yarn" scheme="https://gjtmaster.github.io/tags/Yarn/"/>
    
  </entry>
  
  <entry>
    <title>Flink使用Logback作为日志框架的相关配置</title>
    <link href="https://gjtmaster.github.io/2018/10/13/Flink%E4%BD%BF%E7%94%A8Logback%E4%BD%9C%E4%B8%BA%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%E7%9A%84%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/"/>
    <id>https://gjtmaster.github.io/2018/10/13/Flink使用Logback作为日志框架的相关配置/</id>
    <published>2018-10-13T08:13:17.000Z</published>
    <updated>2019-07-27T11:44:48.836Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h1 id="Flink切换日志框架为Logback"><a href="#Flink切换日志框架为Logback" class="headerlink" title="Flink切换日志框架为Logback"></a>Flink切换日志框架为Logback</h1><h2 id="client端pom文件配置"><a href="#client端pom文件配置" class="headerlink" title="client端pom文件配置"></a>client端pom文件配置</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Add the two required logback dependencies --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>ch.qos.logback<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>logback-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>ch.qos.logback<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>logback-classic<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Add the log4j -&gt; sfl4j (-&gt; logback) bridge into the classpath</span></span><br><span class="line"><span class="comment">     Hadoop is logging to log4j! --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-over-slf4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.15<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>*<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>*<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>*<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>添加logback-core、logback-classic及log4j-over-slf4j依赖，</li><li>之后对flink-java、flink-streaming-java_2.11、flink-clients_2.11等配置log4j及slf4j-log4j12的exclusions；</li><li><strong>最后通过mvn dependency:tree查看是否还有log4j12，以确认下是否都全部排除了</strong></li></ul><h2 id="服务端配置"><a href="#服务端配置" class="headerlink" title="服务端配置"></a>服务端配置</h2><ul><li><p>添加logback-classic.jar、logback-core.jar、log4j-over-slf4j.jar到flink的lib目录下(<code>比如/opt/flink/lib</code>)</p><p>相关jar包在logback官网上都有，<a href="https://download.csdn.net/download/qq_36643786/11190626" target="_blank" rel="noopener">嫌麻烦的可以点此链接直接下载！</a></p></li><li><p>移除flink的lib目录下(<code>比如/opt/flink/lib</code>)log4j及slf4j-log4j12的jar(<code>比如log4j-1.2.17.jar及slf4j-log4j12-1.7.15.jar</code>)</p></li><li><p>如果要自定义logback的配置的话，可以覆盖flink的conf目录下的logback.xml、logback-console.xml或者logback-yarn.xml</p></li></ul><h3 id="flink-daemon-sh"><a href="#flink-daemon-sh" class="headerlink" title="flink-daemon.sh"></a>flink-daemon.sh</h3><p>flink-release-1.7.1/flink-dist/src/main/flink-bin/bin/flink-daemon.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment">#  Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment">#  or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment">#  distributed with this work for additional information</span></span><br><span class="line"><span class="comment">#  regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment">#  to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment">#  "License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment">#  with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#      http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">#  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">#  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start/stop a Flink daemon.</span></span><br><span class="line">USAGE=<span class="string">"Usage: flink-daemon.sh (start|stop|stop-all) (taskexecutor|zookeeper|historyserver|standalonesession|standalonejob) [args]"</span></span><br><span class="line"></span><br><span class="line">STARTSTOP=<span class="variable">$1</span></span><br><span class="line">DAEMON=<span class="variable">$2</span></span><br><span class="line">ARGS=(<span class="string">"<span class="variable">$&#123;@:3&#125;</span>"</span>) <span class="comment"># get remaining arguments as array</span></span><br><span class="line"></span><br><span class="line">bin=`dirname <span class="string">"<span class="variable">$0</span>"</span>`</span><br><span class="line">bin=`<span class="built_in">cd</span> <span class="string">"<span class="variable">$bin</span>"</span>; <span class="built_in">pwd</span>`</span><br><span class="line"></span><br><span class="line">. <span class="string">"<span class="variable">$bin</span>"</span>/config.sh</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$DAEMON</span> <span class="keyword">in</span></span><br><span class="line">    (taskexecutor)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.taskexecutor.TaskManagerRunner</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (zookeeper)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (historyserver)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.webmonitor.history.HistoryServer</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (standalonesession)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.entrypoint.StandaloneSessionClusterEntrypoint</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (standalonejob)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.container.entrypoint.StandaloneJobClusterEntryPoint</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (*)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Unknown daemon '<span class="variable">$&#123;DAEMON&#125;</span>'. <span class="variable">$USAGE</span>."</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    ;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$FLINK_IDENT_STRING</span>"</span> = <span class="string">""</span> ]; <span class="keyword">then</span></span><br><span class="line">    FLINK_IDENT_STRING=<span class="string">"<span class="variable">$USER</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">FLINK_TM_CLASSPATH=`constructFlinkClassPath`</span><br><span class="line"></span><br><span class="line">pid=<span class="variable">$FLINK_PID_DIR</span>/flink-<span class="variable">$FLINK_IDENT_STRING</span>-<span class="variable">$DAEMON</span>.pid</span><br><span class="line"></span><br><span class="line">mkdir -p <span class="string">"<span class="variable">$FLINK_PID_DIR</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Log files for daemons are indexed from the process ID's position in the PID</span></span><br><span class="line"><span class="comment"># file. The following lock prevents a race condition during daemon startup</span></span><br><span class="line"><span class="comment"># when multiple daemons read, index, and write to the PID file concurrently.</span></span><br><span class="line"><span class="comment"># The lock is created on the PID directory since a lock file cannot be safely</span></span><br><span class="line"><span class="comment"># removed. The daemon is started with the lock closed and the lock remains</span></span><br><span class="line"><span class="comment"># active in this script until the script exits.</span></span><br><span class="line"><span class="built_in">command</span> -v flock &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"><span class="keyword">if</span> [[ $? -eq 0 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exec</span> 200&lt;<span class="string">"<span class="variable">$FLINK_PID_DIR</span>"</span></span><br><span class="line">    flock 200</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ascending ID depending on number of lines in pid file.</span></span><br><span class="line"><span class="comment"># This allows us to start multiple daemon of each type.</span></span><br><span class="line">id=$([ -f <span class="string">"<span class="variable">$pid</span>"</span> ] &amp;&amp; <span class="built_in">echo</span> $(wc -l &lt; <span class="string">"<span class="variable">$pid</span>"</span>) || <span class="built_in">echo</span> <span class="string">"0"</span>)</span><br><span class="line"></span><br><span class="line">FLINK_LOG_PREFIX=<span class="string">"<span class="variable">$&#123;FLINK_LOG_DIR&#125;</span>/flink-<span class="variable">$&#123;FLINK_IDENT_STRING&#125;</span>-<span class="variable">$&#123;DAEMON&#125;</span>-<span class="variable">$&#123;id&#125;</span>-<span class="variable">$&#123;HOSTNAME&#125;</span>"</span></span><br><span class="line"><span class="built_in">log</span>=<span class="string">"<span class="variable">$&#123;FLINK_LOG_PREFIX&#125;</span>.log"</span></span><br><span class="line">out=<span class="string">"<span class="variable">$&#123;FLINK_LOG_PREFIX&#125;</span>.out"</span></span><br><span class="line"></span><br><span class="line">log_setting=(<span class="string">"-Dlog.file=<span class="variable">$&#123;log&#125;</span>"</span> <span class="string">"-Dlog4j.configuration=file:<span class="variable">$&#123;FLINK_CONF_DIR&#125;</span>/log4j.properties"</span> <span class="string">"-Dlogback.configurationFile=file:<span class="variable">$&#123;FLINK_CONF_DIR&#125;</span>/logback.xml"</span>)</span><br><span class="line"></span><br><span class="line">JAVA_VERSION=$(<span class="variable">$&#123;JAVA_RUN&#125;</span> -version 2&gt;&amp;1 | sed <span class="string">'s/.*version "\(.*\)\.\(.*\)\..*"/\1\2/; 1q'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Only set JVM 8 arguments if we have correctly extracted the version</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$&#123;JAVA_VERSION&#125;</span> =~ <span class="variable">$&#123;IS_NUMBER&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$JAVA_VERSION</span>"</span> -lt 18 ]; <span class="keyword">then</span></span><br><span class="line">        JVM_ARGS=<span class="string">"<span class="variable">$JVM_ARGS</span> -XX:MaxPermSize=256m"</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$STARTSTOP</span> <span class="keyword">in</span></span><br><span class="line"></span><br><span class="line">    (start)</span><br><span class="line">        <span class="comment"># Rotate log files</span></span><br><span class="line">        rotateLogFilesWithPrefix <span class="string">"<span class="variable">$FLINK_LOG_DIR</span>"</span> <span class="string">"<span class="variable">$FLINK_LOG_PREFIX</span>"</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print a warning if daemons are already running on host</span></span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="string">"<span class="variable">$pid</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">          active=()</span><br><span class="line">          <span class="keyword">while</span> IFS=<span class="string">''</span> <span class="built_in">read</span> -r p || [[ -n <span class="string">"<span class="variable">$p</span>"</span> ]]; <span class="keyword">do</span></span><br><span class="line">            <span class="built_in">kill</span> -0 <span class="variable">$p</span> &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">            <span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line">              active+=(<span class="variable">$p</span>)</span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">          <span class="keyword">done</span> &lt; <span class="string">"<span class="variable">$&#123;pid&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">          count=<span class="string">"<span class="variable">$&#123;#active[@]&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> [ <span class="variable">$&#123;count&#125;</span> -gt 0 ]; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"[INFO] <span class="variable">$count</span> instance(s) of <span class="variable">$DAEMON</span> are already running on <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">          <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Evaluate user options for local variable expansion</span></span><br><span class="line">        FLINK_ENV_JAVA_OPTS=$(<span class="built_in">eval</span> <span class="built_in">echo</span> <span class="variable">$&#123;FLINK_ENV_JAVA_OPTS&#125;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Starting <span class="variable">$DAEMON</span> daemon on host <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">        <span class="variable">$JAVA_RUN</span> <span class="variable">$JVM_ARGS</span> <span class="variable">$&#123;FLINK_ENV_JAVA_OPTS&#125;</span> <span class="string">"<span class="variable">$&#123;log_setting[@]&#125;</span>"</span> -classpath <span class="string">"`manglePathList "</span><span class="variable">$FLINK_TM_CLASSPATH</span>:<span class="variable">$INTERNAL_HADOOP_CLASSPATHS</span><span class="string">"`"</span> <span class="variable">$&#123;CLASS_TO_RUN&#125;</span> <span class="string">"<span class="variable">$&#123;ARGS[@]&#125;</span>"</span> &gt; <span class="string">"<span class="variable">$out</span>"</span> 200&lt;&amp;- 2&gt;&amp;1 &lt; /dev/null &amp;</span><br><span class="line"></span><br><span class="line">        mypid=$!</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add to pid file if successful start</span></span><br><span class="line">        <span class="keyword">if</span> [[ <span class="variable">$&#123;mypid&#125;</span> =~ <span class="variable">$&#123;IS_NUMBER&#125;</span> ]] &amp;&amp; <span class="built_in">kill</span> -0 <span class="variable">$mypid</span> &gt; /dev/null 2&gt;&amp;1 ; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="variable">$mypid</span> &gt;&gt; <span class="string">"<span class="variable">$pid</span>"</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"Error starting <span class="variable">$DAEMON</span> daemon."</span></span><br><span class="line">            <span class="built_in">exit</span> 1</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (stop)</span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="string">"<span class="variable">$pid</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">            <span class="comment"># Remove last in pid file</span></span><br><span class="line">            to_stop=$(tail -n 1 <span class="string">"<span class="variable">$pid</span>"</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> [ -z <span class="variable">$to_stop</span> ]; <span class="keyword">then</span></span><br><span class="line">                rm <span class="string">"<span class="variable">$pid</span>"</span> <span class="comment"># If all stopped, clean up pid file</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"No <span class="variable">$DAEMON</span> daemon to stop on host <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                sed \<span class="variable">$d</span> <span class="string">"<span class="variable">$pid</span>"</span> &gt; <span class="string">"<span class="variable">$pid</span>.tmp"</span> <span class="comment"># all but last line</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># If all stopped, clean up pid file</span></span><br><span class="line">                [ $(wc -l &lt; <span class="string">"<span class="variable">$pid</span>.tmp"</span>) -eq 0 ] &amp;&amp; rm <span class="string">"<span class="variable">$pid</span>"</span> <span class="string">"<span class="variable">$pid</span>.tmp"</span> || mv <span class="string">"<span class="variable">$pid</span>.tmp"</span> <span class="string">"<span class="variable">$pid</span>"</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">kill</span> -0 <span class="variable">$to_stop</span> &gt; /dev/null 2&gt;&amp;1; <span class="keyword">then</span></span><br><span class="line">                    <span class="built_in">echo</span> <span class="string">"Stopping <span class="variable">$DAEMON</span> daemon (pid: <span class="variable">$to_stop</span>) on host <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">                    <span class="built_in">kill</span> <span class="variable">$to_stop</span></span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    <span class="built_in">echo</span> <span class="string">"No <span class="variable">$DAEMON</span> daemon (pid: <span class="variable">$to_stop</span>) is running anymore on <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">                <span class="keyword">fi</span></span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"No <span class="variable">$DAEMON</span> daemon to stop on host <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (stop-all)</span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="string">"<span class="variable">$pid</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">            mv <span class="string">"<span class="variable">$pid</span>"</span> <span class="string">"<span class="variable">$&#123;pid&#125;</span>.tmp"</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="built_in">read</span> to_stop; <span class="keyword">do</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">kill</span> -0 <span class="variable">$to_stop</span> &gt; /dev/null 2&gt;&amp;1; <span class="keyword">then</span></span><br><span class="line">                    <span class="built_in">echo</span> <span class="string">"Stopping <span class="variable">$DAEMON</span> daemon (pid: <span class="variable">$to_stop</span>) on host <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">                    <span class="built_in">kill</span> <span class="variable">$to_stop</span></span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    <span class="built_in">echo</span> <span class="string">"Skipping <span class="variable">$DAEMON</span> daemon (pid: <span class="variable">$to_stop</span>), because it is not running anymore on <span class="variable">$HOSTNAME</span>."</span></span><br><span class="line">                <span class="keyword">fi</span></span><br><span class="line">            <span class="keyword">done</span> &lt; <span class="string">"<span class="variable">$&#123;pid&#125;</span>.tmp"</span></span><br><span class="line">            rm <span class="string">"<span class="variable">$&#123;pid&#125;</span>.tmp"</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (*)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Unexpected argument '<span class="variable">$STARTSTOP</span>'. <span class="variable">$USAGE</span>."</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><ul><li>使用flink-daemon.sh启动的flink使用的logback配置文件是logback.xml</li></ul><h3 id="flink-console-sh"><a href="#flink-console-sh" class="headerlink" title="flink-console.sh"></a>flink-console.sh</h3><p>flink-release-1.7.1/flink-dist/src/main/flink-bin/bin/flink-console.sh</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line">################################################################################</span><br><span class="line">#  Licensed to the Apache Software Foundation (ASF) under one</span><br><span class="line">#  or more contributor license agreements.  See the NOTICE file</span><br><span class="line">#  distributed <span class="keyword">with</span> this work for additional information</span><br><span class="line">#  regarding copyright ownership.  The ASF licenses this file</span><br><span class="line">#  to you under the Apache License, Version <span class="number">2.0</span> (the</span><br><span class="line">#  <span class="string">"License"</span>); you may not use this file except <span class="keyword">in</span> compliance</span><br><span class="line">#  <span class="keyword">with</span> the License.  You may obtain a copy <span class="keyword">of</span> the License at</span><br><span class="line">#</span><br><span class="line">#      http:<span class="comment">//www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line">#</span><br><span class="line">#  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">#  distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span><br><span class="line">#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">#  See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line">################################################################################</span><br><span class="line"></span><br><span class="line"># Start a Flink service <span class="keyword">as</span> a console application. Must be stopped <span class="keyword">with</span> Ctrl-C</span><br><span class="line"># or <span class="keyword">with</span> SIGTERM by kill or the controlling process.</span><br><span class="line">USAGE=<span class="string">"Usage: flink-console.sh (taskexecutor|zookeeper|historyserver|standalonesession|standalonejob) [args]"</span></span><br><span class="line"></span><br><span class="line">SERVICE=$<span class="number">1</span></span><br><span class="line">ARGS=(<span class="string">"$&#123;@:2&#125;"</span>) # get remaining arguments <span class="keyword">as</span> array</span><br><span class="line"></span><br><span class="line">bin=`dirname <span class="string">"$0"</span>`</span><br><span class="line">bin=`cd <span class="string">"$bin"</span>; pwd`</span><br><span class="line"></span><br><span class="line">. <span class="string">"$bin"</span>/config.sh</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> $SERVICE <span class="keyword">in</span></span><br><span class="line">    (taskexecutor)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.taskexecutor.TaskManagerRunner</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (historyserver)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.webmonitor.history.HistoryServer</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (zookeeper)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (standalonesession)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.entrypoint.StandaloneSessionClusterEntrypoint</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (standalonejob)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.container.entrypoint.StandaloneJobClusterEntryPoint</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (*)</span><br><span class="line">        echo <span class="string">"Unknown service '$&#123;SERVICE&#125;'. $USAGE."</span></span><br><span class="line">        exit <span class="number">1</span></span><br><span class="line">    ;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">FLINK_TM_CLASSPATH=`constructFlinkClassPath`</span><br><span class="line"></span><br><span class="line">log_setting=(<span class="string">"-Dlog4j.configuration=file:$&#123;FLINK_CONF_DIR&#125;/log4j-console.properties"</span> <span class="string">"-Dlogback.configurationFile=file:$&#123;FLINK_CONF_DIR&#125;/logback-console.xml"</span>)</span><br><span class="line"></span><br><span class="line">JAVA_VERSION=$($&#123;JAVA_RUN&#125; -version <span class="number">2</span>&gt;&amp;<span class="number">1</span> | sed <span class="string">'s/.*version "\(.*\)\.\(.*\)\..*"/\1\2/; 1q'</span>)</span><br><span class="line"></span><br><span class="line"># Only set JVM <span class="number">8</span> arguments <span class="keyword">if</span> we have correctly extracted the version</span><br><span class="line"><span class="keyword">if</span> [[ $&#123;JAVA_VERSION&#125; =~ $&#123;IS_NUMBER&#125; ]]; then</span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"$JAVA_VERSION"</span> -lt <span class="number">18</span> ]; then</span><br><span class="line">        JVM_ARGS=<span class="string">"$JVM_ARGS -XX:MaxPermSize=256m"</span></span><br><span class="line">    fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo <span class="string">"Starting $SERVICE as a console application on host $HOSTNAME."</span></span><br><span class="line">exec $JAVA_RUN $JVM_ARGS $&#123;FLINK_ENV_JAVA_OPTS&#125; <span class="string">"$&#123;log_setting[@]&#125;"</span> -classpath <span class="string">"`manglePathList "</span>$FLINK_TM_CLASSPATH:$INTERNAL_HADOOP_CLASSPATHS<span class="string">"`"</span> $&#123;CLASS_TO_RUN&#125; <span class="string">"$&#123;ARGS[@]&#125;"</span></span><br></pre></td></tr></table></figure><ul><li>使用flink-console.sh启动的flink使用的logback配置文件是logback-console.xml</li></ul><h3 id="yarn-session-sh"><a href="#yarn-session-sh" class="headerlink" title="yarn-session.sh"></a>yarn-session.sh</h3><p>flink-release-1.7.1/flink-dist/src/main/flink-bin/yarn-bin/yarn-session.sh</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line">################################################################################</span><br><span class="line">#  Licensed to the Apache Software Foundation (ASF) under one</span><br><span class="line">#  or more contributor license agreements.  See the NOTICE file</span><br><span class="line">#  distributed <span class="keyword">with</span> this work for additional information</span><br><span class="line">#  regarding copyright ownership.  The ASF licenses this file</span><br><span class="line">#  to you under the Apache License, Version <span class="number">2.0</span> (the</span><br><span class="line">#  <span class="string">"License"</span>); you may not use this file except <span class="keyword">in</span> compliance</span><br><span class="line">#  <span class="keyword">with</span> the License.  You may obtain a copy <span class="keyword">of</span> the License at</span><br><span class="line">#</span><br><span class="line">#      http:<span class="comment">//www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line">#</span><br><span class="line">#  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">#  distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span><br><span class="line">#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">#  See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line">################################################################################</span><br><span class="line"></span><br><span class="line">bin=`dirname <span class="string">"$0"</span>`</span><br><span class="line">bin=`cd <span class="string">"$bin"</span>; pwd`</span><br><span class="line"></span><br><span class="line"># get Flink config</span><br><span class="line">. <span class="string">"$bin"</span>/config.sh</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"$FLINK_IDENT_STRING"</span> = <span class="string">""</span> ]; then</span><br><span class="line">        FLINK_IDENT_STRING=<span class="string">"$USER"</span></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">JVM_ARGS=<span class="string">"$JVM_ARGS -Xmx512m"</span></span><br><span class="line"></span><br><span class="line">CC_CLASSPATH=`manglePathList $(constructFlinkClassPath):$INTERNAL_HADOOP_CLASSPATHS`</span><br><span class="line"></span><br><span class="line">log=$FLINK_LOG_DIR/flink-$FLINK_IDENT_STRING-yarn-session-$HOSTNAME.log</span><br><span class="line">log_setting=<span class="string">"-Dlog.file="</span>$log<span class="string">" -Dlog4j.configuration=file:"</span>$FLINK_CONF_DIR<span class="string">"/log4j-yarn-session.properties -Dlogback.configurationFile=file:"</span>$FLINK_CONF_DIR<span class="string">"/logback-yarn.xml"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> FLINK_CONF_DIR</span><br><span class="line"></span><br><span class="line">$JAVA_RUN $JVM_ARGS -classpath <span class="string">"$CC_CLASSPATH"</span> $log_setting org.apache.flink.yarn.cli.FlinkYarnSessionCli -j <span class="string">"$FLINK_LIB_DIR"</span>/flink-dist*.jar <span class="string">"$@"</span></span><br></pre></td></tr></table></figure><ul><li>使用yarn-session.sh启动的flink使用的logback配置文件是logback-yarn.xml</li></ul><h2 id="doc"><a href="#doc" class="headerlink" title="doc"></a>doc</h2><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/best_practices.html#using-logback-instead-of-log4j" target="_blank" rel="noopener">Using Logback instead of Log4j</a></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>client端使用logback的话，要在pom文件添加logback-core、logback-classic及log4j-over-slf4j依赖，之后对flink-java、flink-streaming-java_2.11、flink-clients_2.11等配置log4j及slf4j-log4j12的exclusions；最后通过mvn dependency:tree查看是否还有log4j12，以确认下是否都全部排除了</li><li>服务端使用logback的话，要在添加logback-classic.jar、logback-core.jar、log4j-over-slf4j.jar到flink的lib目录下(<code>比如/opt/flink/lib</code>)；移除flink的lib目录下(<code>比如/opt/flink/lib</code>)log4j及slf4j-log4j12的jar(<code>比如log4j-1.2.17.jar及slf4j-log4j12-1.7.15.jar</code>)；如果要自定义logback的配置的话，可以覆盖flink的conf目录下的logback.xml、logback-console.xml或者logback-yarn.xml</li><li>使用flink-daemon.sh启动的flink使用的logback配置文件是logback.xml；使用flink-console.sh启动的flink使用的logback配置文件是logback-console.xml；使用yarn-session.sh启动的flink使用的logback配置文件是logback-yarn.xml</li></ul><h1 id="Logback配置文件详解"><a href="#Logback配置文件详解" class="headerlink" title="Logback配置文件详解"></a>Logback配置文件详解</h1><p>Logback，Java 日志框架。</p><p>Logback 如何加载配置的</p><ol><li>logback 首先会查找 logback.groovy 文件</li><li>当没有找到，继续试着查找 logback-test.xml 文件</li><li>当没有找到时，继续试着查找 logback.xml 文件</li><li>如果仍然没有找到，则使用默认配置（打印到控制台）</li></ol><h2 id="configuration"><a href="#configuration" class="headerlink" title="configuration"></a>configuration</h2><p>configuration 是配置文件的根节点，他包含的属性：</p><ul><li>scan<br>　　当此属性设置为 true 时，配置文件如果发生改变，将会被重新加载，默认值为 true</li><li>scanPeriod<br>　　设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。但 scan 为 true 时，此属性生效，默认的时间间隔为 1 分钟</li><li>debug<br>　　当此属性设置为 true 时，将打印出 logback 内部日志信息，实时查看 logback 运行状态，默认值为 false。</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"60 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span>  </span><br><span class="line">      <span class="comment">&lt;!-- 其他配置省略--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="configuration-的子节点"><a href="#configuration-的子节点" class="headerlink" title="configuration 的子节点"></a>configuration 的子节点</h2><h4 id="设置上下文名称：contextName"><a href="#设置上下文名称：contextName" class="headerlink" title="设置上下文名称：contextName"></a>设置上下文名称：contextName</h4><p>每个 logger 度关联到 logger 上下文，默认上下文名称为 “default”。可以通过设置 contextName 修改上下文名称，用于区分不同应该程序的记录</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"60 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span>  </span><br><span class="line">      <span class="tag">&lt;<span class="name">contextName</span>&gt;</span>myAppName<span class="tag">&lt;/<span class="name">contextName</span>&gt;</span>  </span><br><span class="line">      <span class="comment">&lt;!-- 其他配置省略--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="设置变量：property"><a href="#设置变量：property" class="headerlink" title="设置变量：property"></a>设置变量：property</h4><p>用于定义键值对的变量， property 有两个属性 name 和 value，name 是键，value 是值，通过 property 定义的键值对会保存到logger 上下文的 map 集合内。定义变量后，可以使用 “${}” 来使用变量</p><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"60 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">      <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"APP_Name"</span> <span class="attr">value</span>=<span class="string">"myAppName"</span> /&gt;</span>   </span></span><br><span class="line"><span class="xml">      <span class="tag">&lt;<span class="name">contextName</span>&gt;</span>$</span><span class="template-variable">&#123;APP_Name&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">contextName</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">      <span class="comment">&lt;!-- 其他配置省略--&gt;</span>  </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h4 id="获取时间戳字符串：timestamp"><a href="#获取时间戳字符串：timestamp" class="headerlink" title="获取时间戳字符串：timestamp"></a>获取时间戳字符串：timestamp</h4><p>timestamp 有两个属性，key：标识此 timestamp 的名字；datePattern：时间输出格式，遵循SimpleDateFormat 的格式</p><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"60 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">      <span class="tag">&lt;<span class="name">timestamp</span> <span class="attr">key</span>=<span class="string">"bySecond"</span> <span class="attr">datePattern</span>=<span class="string">"yyyyMMdd'T'HHmmss"</span>/&gt;</span>   </span></span><br><span class="line"><span class="xml">      <span class="tag">&lt;<span class="name">contextName</span>&gt;</span>$</span><span class="template-variable">&#123;bySecond&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">contextName</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">      <span class="comment">&lt;!-- 其他配置省略--&gt;</span>  </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h2 id="logger"><a href="#logger" class="headerlink" title="logger"></a>logger</h2><p>logger 有两种级别，一种是 root，一种是普通的 logger，logger 是用来设置某一个包或者具体的某一个类的日志打印机级别，以及制定的 appender。<br>logger 有三个属性</p><ul><li>name：用来指定此 logger 约束的某一个包或者具体的某一个类</li><li>level：用来设置打印机别，</li><li>addtivity：是否向上级 logger 传递打印信息。默认是 true</li></ul><p>每个 logger 都有对应的父级关系，它通过包名来决定父级关系，root 是最高级的父元素。<br>下面定义了四个 logger，他们的父子关系从小到大为：<br>com.lwc.qg.test.logbackDemo → com.lwc.qg.tes → com.lwc.qg → root</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 根 logger --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">    普通的 logger</span></span><br><span class="line"><span class="comment">    name：类名或包名，标志该 logger 与哪个包或哪个类绑定</span></span><br><span class="line"><span class="comment">    level：该 logger 的日志级别</span></span><br><span class="line"><span class="comment">    additivity：是否将日志信息传递给上一级</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.lwc.qg.test.logbackDemo"</span> <span class="attr">level</span>=<span class="string">"debug"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.lwc.qg.test"</span> <span class="attr">level</span>=<span class="string">"info"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.lwc.qg"</span> <span class="attr">level</span>=<span class="string">"info"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br></pre></td></tr></table></figure><p>　　从该种级别来看，如果此时在最低层的 logger 输出日志信息，以该配置作为基础，它将会向父级的所有 logger 依次传递，所以按理来说一个打印信息将会打印四次</p><p>　　从控制台上看，的确每条日志信息都被打印出了四次，但是细心从配置文件上来看，root 的日志级别配置的为 info，但是却输出<br>debug 级别的日志信息，所以从测试结果可以看出，向上传递的日志信息的日志级别将由最底层的子元素决定（最初传递信息的<br>logger），因为子元素设置的日志级别为 debug，所以也输出了 debug 级别的信息。<br>　　因此，从理论上来说，如果子元素日志级别设置高一点，那么也将会只输出高级别的日志信息。实际上也是如此，如果我们把 com.lwc.qg.test.logbackDemo 对应的 logger 日志级别设为 warn，那么将只会输出 warn 及其以上的信息</p><h2 id="root"><a href="#root" class="headerlink" title="root"></a>root</h2><p>root 也是 logger 元素，但它是根 logger。只有一个 level 属性</p><h2 id="appender"><a href="#appender" class="headerlink" title="appender"></a>appender</h2><p>appender 是负责写日志的组件，常用的组件有：</p><ul><li>ConsoleAppender</li><li>FileAppender</li><li>RollingFileAppender</li></ul><h2 id="ConsoleAppender"><a href="#ConsoleAppender" class="headerlink" title="ConsoleAppender"></a>ConsoleAppender</h2><p>控制台日志组件，该组件将日志信息输出到控制台,该组件有以下节点</p><ul><li>encoder：对日志进行格式化</li><li>target：System.out 或者 System.err，默认是 System.out</li></ul><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">encoder</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-4relative [%thread] %-5level %logger</span><span class="template-variable">&#123;35&#125;</span><span class="xml"> - %msg %n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">target</span>&gt;</span>System.out<span class="tag">&lt;/<span class="name">target</span>&gt;</span> </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h2 id="FileAppender"><a href="#FileAppender" class="headerlink" title="FileAppender"></a>FileAppender</h2><p>文件日志组件，该组件将日志信息输出到日志文件中，该组件有以下节点</p><ul><li>file：被写入的文件名，可以是相对路径，也可以是绝对路径。如果上级目录不存在会自动创建，没有默认值</li><li>append：如果是 true，日志被追加到文件结尾；如果是 false，清空现存文件，默认是 true。</li><li>encoder：格式化</li><li>prudent：如果是 true，日志会被安全的写入文件，即使其他的 FileAppender 也在向此文件做写入操作，效率低，默认是 false。</li></ul><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.FileAppender"</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">file</span>&gt;</span>testFile.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">append</span>&gt;</span>true<span class="tag">&lt;/<span class="name">append</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-4relative [%thread] %-5level %logger</span><span class="template-variable">&#123;35&#125;</span><span class="xml"> - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">prudent</span>&gt;</span>true<span class="tag">&lt;/<span class="name">prudent</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id><a href="#" class="headerlink" title=" "></a> </h3><h2 id="RollingFileAppender"><a href="#RollingFileAppender" class="headerlink" title="RollingFileAppender"></a>RollingFileAppender</h2><p>滚动记录文件日志组件，先将日志记录记录到指定文件，当符合某个条件时，将日志记录到其他文件，该组件有以下节点</p><ul><li>file：文件名</li><li>encoder：格式化</li><li>rollingPolicy：当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名</li><li>triggeringPolicy：告知 RollingFileAppender 合适激活滚动</li><li>prudent：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。</li></ul><p>#### </p><h3 id="rollingPolicy"><a href="#rollingPolicy" class="headerlink" title="rollingPolicy"></a>rollingPolicy</h3><p>滚动策略</p><ol><li>TimeBasedRollingPolicy：最常用的滚动策略，它根据时间来制定滚动策略，即负责滚动也负责触发滚动，包含节点：<ul><li>fileNamePattern：文件名模式</li><li>maxHistoury：控制文件的最大数量，超过数量则删除旧文件</li></ul></li><li>FixedWindowRollingPolicy：根据固定窗口算法重命名文件的滚动策略，包含节点<ul><li>minInedx：窗口索引最小值</li><li>maxIndex：串口索引最大值，当用户指定的窗口过大时，会自动将窗口设置为12</li><li>fileNamePattern：文件名模式，必须包含%i，命名模式为 log%i.log，会产生 log1.log，log2.log 这样的文件</li></ul></li><li>triggeringPolicy：根据文件大小的滚动策略，包含节点<ul><li>maxFileSize：日志文件最大大小</li></ul></li></ol><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>logFile.%d</span><span class="template-variable">&#123;yyyy-MM-dd&#125;</span><span class="xml">.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-4relative [%thread] %-5level %logger</span><span class="template-variable">&#123;35&#125;</span><span class="xml"> - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h2 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h2><h2 id="filter-过滤器"><a href="#filter-过滤器" class="headerlink" title="filter 过滤器"></a>filter 过滤器</h2><p>过滤器是用于日志组件中的，每经过一个过滤器都会返回一个确切的枚举值，分别是</p><ul><li>DENY：返回 DENY，日志将立即被抛弃不再经过其他过滤器</li><li>NEUTRAL：有序列表的下个过滤器接着处理日志</li><li>ACCEPT：日志会被立即处理，不再经过剩余过滤器</li></ul><h3 id="常用过滤器"><a href="#常用过滤器" class="headerlink" title="常用过滤器"></a>常用过滤器</h3><p>常用的过滤器有以下：</p><ul><li>LevelFilter<br>级别过滤器，根据日志级别进行过滤。如果日志级别等于配置级别，过滤器会根据 omMatch 和 omMismatch 接受或拒绝日志。他有以下节点<br>　　level：过滤级别<br>　　onMatch：配置符合过滤条件的操作<br>　　onMismatch：配置不符合过滤条件的操作<br>例：该组件设置一个 INFO 级别的过滤器，那么所有非 INFO 级别的日志都会被过滤掉　　</li></ul><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>INFO<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">encoder</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-4relative [%thread] %-5level %logger</span><span class="template-variable">&#123;35&#125;</span><span class="xml"> - %msg %n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">target</span>&gt;</span>System.out<span class="tag">&lt;/<span class="name">target</span>&gt;</span> </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br></pre></td></tr></table></figure><ul><li>ThresholdFilter<br>临界值过滤器，过滤掉低于指定临界值的日志。当日志级别等于或高于临界值时，过滤器会返回 NEUTRAL；当日志级别低于临界值时，日志会被拒绝<br>例：过滤掉所有低于 INFO 级别的日志</li></ul><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.ThresholdFilter"</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">level</span>&gt;</span>INFO<span class="tag">&lt;/<span class="name">level</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">encoder</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-4relative [%thread] %-5level %logger</span><span class="template-variable">&#123;35&#125;</span><span class="xml"> - %msg %n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span>  </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">target</span>&gt;</span>System.out<span class="tag">&lt;/<span class="name">target</span>&gt;</span> </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br></pre></td></tr></table></figure><ul><li>EvaluatorFilter<br>求值过滤器，评估、鉴别日志是否符合指定条件，包含节点：<br>　　evaluator：鉴别器，通过子标签 expression 配置求值条件<br>　　onMatch：配置符合过滤条件的操作<br>　　onMismatch：配置不符合过滤条件的操作</li></ul>]]></content>
    
    <summary type="html">
    
      本文主要讲述了Flink切换日志框架为Logback的详细步骤，并对Logback框架的配置文件进行了详细的介绍。
    
    </summary>
    
      <category term="日志框架" scheme="https://gjtmaster.github.io/categories/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/"/>
    
    
      <category term="Flink" scheme="https://gjtmaster.github.io/tags/Flink/"/>
    
      <category term="实时计算" scheme="https://gjtmaster.github.io/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Logback" scheme="https://gjtmaster.github.io/tags/Logback/"/>
    
  </entry>
  
  <entry>
    <title>Flink SQL 深度解析</title>
    <link href="https://gjtmaster.github.io/2018/09/18/FlinkSQL%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/"/>
    <id>https://gjtmaster.github.io/2018/09/18/FlinkSQL深度解析/</id>
    <published>2018-09-18T10:19:05.000Z</published>
    <updated>2019-09-08T13:36:12.726Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大数据计算领域对SQL的应用"><a href="#大数据计算领域对SQL的应用" class="headerlink" title="大数据计算领域对SQL的应用"></a>大数据计算领域对SQL的应用</h1><h2 id="离线计算（批计算）"><a href="#离线计算（批计算）" class="headerlink" title="离线计算（批计算）"></a>离线计算（批计算）</h2><p>提及大数据计算领域不得不说MapReduce计算模型，MapReduce最早是由Google公司研究提出的一种面向大规模数据处理的并行计算模型和方法，并发于2004年发表了论文Simplified Data Processing on Large Clusters。论文发表之后Apache 开源社区参考Google MapReduce，基于Java设计开发了一个称为Hadoop的开源MapReduce并行计算框架。很快得到了全球学术界和工业界的普遍关注，并得到推广和普及应用。但利用Hadoop进行MapReduce的开发，需要开发人员精通Java语言，并了解MapReduce的运行原理，这样在一定程度上提高了MapReduce的开发门槛，所以在开源社区又不断涌现了一些为了简化MapReduce开发的开源框架，其中Hive就是典型的代表。HSQL可以让用户以类SQL的方式描述MapReduce计算，比如原本需要几十行，甚至上百行才能完成的wordCount，用户一条SQL语句就能完成了，这样极大的降低了MapReduce的开发门槛，进而也成功的将SQL应用到了大数据计算领域当中来。</p><h2 id="实时计算（流计算）"><a href="#实时计算（流计算）" class="headerlink" title="实时计算（流计算）"></a>实时计算（流计算）</h2><p>SQL不仅仅被成功的应用到了离线计算，SQL的易用性也吸引了流计算产品，目前最热的Spark，Flink也纷纷支持了SQL，尤其是Flink支持的更加彻底，集成了Calcite，完全遵循ANSI-SQL标准。Apache Flink在low-level API上面用DataSet支持批计算，用DataStream支持流计算，但在High-Level API上面利用SQL将流与批进行了统一，使得用户编写一次SQL既可以在流计算中使用，又可以在批计算中使用，为既有流计算业务，又有批计算业务的用户节省了大量开发成本。</p><h1 id="SQL高性能与简洁性"><a href="#SQL高性能与简洁性" class="headerlink" title="SQL高性能与简洁性"></a>SQL高性能与简洁性</h1><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>SQL经过传统数据库领域几十年的不断打磨，查询优化器已经能够极大的优化SQL的查询性能，Apache Flink 应用Calcite进行查询优化，复用了大量数据库查询优化规则，在性能上不断追求极致，能够让用户关心但不用担心性能问题。如下图(Alibaba 对 Apache Flink 进行架构优化后的组件栈)</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvN43HQMdZty0IxMowiaBs1oaPZwyEeVpLvkLakk4V51uz6iaMbz9toslicw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>相对于DataStream而言，SQL会经过Optimization模块透明的为用户进行查询优化，用户专心编写自己的业务逻辑，不用担心性能，却能得到最优的查询性能!</p><h2 id="简洁"><a href="#简洁" class="headerlink" title="简洁"></a>简洁</h2><p>就简洁性而言，SQL与DataSet和DataStream相比具有很大的优越性，我们先用一个WordCount示例来直观的查看用户的代码量：</p><p>DataStream/DataSetAPI</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">... <span class="comment">//省略初始化代码</span></span><br><span class="line"><span class="comment">// 核心逻辑</span></span><br><span class="line"><span class="built_in">text</span>.flatMap(<span class="keyword">new</span> WordCount.Tokenizer()).keyBy(<span class="keyword">new</span> <span class="built_in">int</span>[]&#123;<span class="number">0</span>&#125;).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// flatmap 代码定义</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> class Tokenizer implements FlatMapFunction&lt;<span class="keyword">String</span>, Tuple2&lt;<span class="keyword">String</span>, Integer&gt;&gt; &#123;</span><br><span class="line"><span class="keyword">public</span> Tokenizer() &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> flatMap(<span class="keyword">String</span> value, Collector&lt;Tuple2&lt;<span class="keyword">String</span>, Integer&gt;&gt; out) &#123;</span><br><span class="line"><span class="keyword">String</span>[] tokens = value.toLowerCase().<span class="built_in">split</span>(<span class="string">"\\W+"</span>);</span><br><span class="line"><span class="keyword">String</span>[] var4 = tokens;</span><br><span class="line"><span class="built_in">int</span> var5 = tokens.length;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="built_in">int</span> var6 = <span class="number">0</span>; var6 &lt; var5; ++var6) &#123;</span><br><span class="line"><span class="keyword">String</span> token = var4[var6];</span><br><span class="line"><span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">out.collect(<span class="keyword">new</span> Tuple2(token, <span class="number">1</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>SQL</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">...//省略初始化代码</span><br><span class="line"><span class="keyword">SELECT</span> word, <span class="built_in">COUNT</span>(word) <span class="keyword">FROM</span> tab <span class="keyword">GROUP</span> <span class="keyword">BY</span> word;</span><br></pre></td></tr></table></figure><p>我们直观的体会到相同的统计功能使用SQL的简洁性。</p><h1 id="Flink-SQL-Job的组成"><a href="#Flink-SQL-Job的组成" class="headerlink" title="Flink SQL Job的组成"></a>Flink SQL Job的组成</h1><p>我们做任何数据计算都离不开读取原始数据，计算逻辑和写入计算结果数据三部分，当然基于Apache Flink SQL编写的计算Job也离不开这三个部分，如下所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNmwGyZgbFaPfs2bjXzSGdh9jSTKnxrYlSbLzwMUn95uVLOuHcueGLnw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>如上所示，一个完整的Apache Flink SQL Job 由如下三部分：</p><ul><li>Source Operator - Soruce operator是对外部数据源的抽象, 目前Apache Flink内置了很多常用的数据源实现，比如上图提到的Kafka。</li><li>Query Operators - 查询算子主要完成如图的Query Logic，目前支持了Union，Join，Projection,Difference, Intersection以及window等大多数传统数据库支持的操作。</li><li>Sink Operator - Sink operator 是对外结果表的抽象，目前Apache Flink也内置了很多常用的结果表的抽象，比如上图提到的Kafka。</li></ul><h1 id="Flink-SQL-核心算子"><a href="#Flink-SQL-核心算子" class="headerlink" title="Flink SQL 核心算子"></a>Flink SQL 核心算子</h1><p>目前Flink SQL支持Union，Join，Projection,Difference, Intersection以及Window等大多数传统数据库支持的操作，接下来为大家分别进行简单直观的介绍。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>为了很好的体验和理解Apache Flink SQL算子我们需要先准备一下测试环境，我们选择IDEA，以ITCase测试方式来进行体验。IDEA 安装这里不占篇幅介绍了，相信大家能轻松搞定！我们进行功能体验有两种方式，具体如下：</p><h2 id="源码方式"><a href="#源码方式" class="headerlink" title="源码方式"></a>源码方式</h2><p>对于开源爱好者可能更喜欢源代码方式理解和体验Apache Flink SQL功能，那么我们需要下载源代码并导入到IDEA中：</p><ul><li>下载源码：</li></ul><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 下载源代码</span></span><br><span class="line">git clone https:<span class="comment">//github.com/apache/flink.git study</span></span><br><span class="line"><span class="comment">// 进入源码目录</span></span><br><span class="line">cd study</span><br><span class="line"><span class="comment">// 拉取稳定版release-1.6</span></span><br><span class="line">git fetch origin <span class="built_in">release</span><span class="number">-1.6</span>:<span class="built_in">release</span><span class="number">-1.6</span></span><br><span class="line"><span class="comment">//切换到稳定版</span></span><br><span class="line">git checkout <span class="built_in">release</span><span class="number">-1.6</span></span><br><span class="line"><span class="comment">//将依赖安装到本地mvn仓库，耐心等待需要一段时间</span></span><br><span class="line">mvn clean install -DskipTests</span><br></pre></td></tr></table></figure><ul><li>导入到IDEA<br>将Flink源码导入到IDEA过程这里不再占用篇幅，导入后确保在IDEA中可以运行 <code>org.apache.flink.table.runtime.stream.sql.SqlITCase</code> 并测试全部通过，即证明体验环境已经完成，即证明体验环境已经完成。如下图所示：</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNo09iaFxmhAfdNGPSjCc6qnjDUWyZaCO8UBSkyUJy1EEcicoSv4qa8wzg/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>如上图运行测试后显示测试通过，我们就可以继续下面的Apache Flink SQL功能体验了。</p><h2 id="依赖Flink包方式"><a href="#依赖Flink包方式" class="headerlink" title="依赖Flink包方式"></a>依赖Flink包方式</h2><p>我们还有一种更简单直接的方式，就是新建一个mvn项目，并在pom中添加如下依赖：</p><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"> </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">table.version</span>&gt;</span>1.6-SNAPSHOT<span class="tag">&lt;/<span class="name">table.version</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$</span><span class="template-variable">&#123;table.version&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-scala_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$</span><span class="template-variable">&#123;table.version&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-scala_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$</span><span class="template-variable">&#123;table.version&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$</span><span class="template-variable">&#123;table.version&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>JUnit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>JUnit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span></span><br></pre></td></tr></table></figure><p>完成环境准备后，我们开始准备测试数据和写一个简单的测试类。</p><h2 id="示例数据及测试类"><a href="#示例数据及测试类" class="headerlink" title="示例数据及测试类"></a>示例数据及测试类</h2><h3 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h3><ul><li>customer_tab 表 - 客户表保存客户id，客户姓名和客户描述信息。字段及测试数据如下：</li></ul><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td></tr><tr><td>c_002</td><td>Sunny</td><td>from JinLin</td></tr><tr><td>c_003</td><td>JinCheng</td><td>from HeBei</td></tr></tbody></table><ul><li>order_tab 表 - 订单表保存客户购买的订单信息，包括订单id，订单时间和订单描述信息。 字段节测试数据如下：</li></ul><table><thead><tr><th>o_id</th><th>c_id</th><th>o_time</th><th>o_desc</th></tr></thead><tbody><tr><td>o_oo1</td><td>c_002</td><td>2018-11-05 10:01:01</td><td>iphone</td></tr><tr><td>o_002</td><td>c_001</td><td>2018-11-05 10:01:55</td><td>ipad</td></tr><tr><td>o_003</td><td>c_001</td><td>2018-11-05 10:03:44</td><td>flink book</td></tr></tbody></table><ul><li>Item_tab<br> 商品表, 携带商品id，商品类型，出售时间，价格等信息，具体如下：</li></ul><table><thead><tr><th>itemID</th><th>itemType</th><th>onSellTime</th><th>price</th></tr></thead><tbody><tr><td>ITEM001</td><td>Electronic</td><td>2017-11-11 10:01:00</td><td>20</td></tr><tr><td>ITEM002</td><td>Electronic</td><td>2017-11-11 10:02:00</td><td>50</td></tr><tr><td>ITEM003</td><td>Electronic</td><td><strong>*2017-11-11 10:03:00*</strong></td><td>30</td></tr><tr><td>ITEM004</td><td>Electronic</td><td><strong>*2017-11-11 10:03:00*</strong></td><td>60</td></tr><tr><td>ITEM005</td><td>Electronic</td><td>2017-11-11 10:05:00</td><td>40</td></tr><tr><td>ITEM006</td><td>Electronic</td><td>2017-11-11 10:06:00</td><td>20</td></tr><tr><td>ITEM007</td><td>Electronic</td><td>2017-11-11 10:07:00</td><td>70</td></tr><tr><td>ITEM008</td><td>Clothes</td><td>2017-11-11 10:08:00</td><td>20</td></tr></tbody></table><ul><li>PageAccess_tab<br>页面访问表，包含用户ID，访问时间，用户所在地域信息，具体数据如下：</li></ul><table><thead><tr><th>region</th><th>userId</th><th>accessTime</th></tr></thead><tbody><tr><td>ShangHai</td><td>U0010</td><td>2017-11-11 10:01:00</td></tr><tr><td>BeiJing</td><td>U1001</td><td>2017-11-11 10:01:00</td></tr><tr><td>BeiJing</td><td>U2032</td><td>2017-11-11 10:10:00</td></tr><tr><td>BeiJing</td><td>U1100</td><td>2017-11-11 10:11:00</td></tr><tr><td>ShangHai</td><td>U0011</td><td>2017-11-11 12:10:00</td></tr></tbody></table><ul><li>PageAccessCount_tab<br>页面访问表，访问量，访问时间，用户所在地域信息，具体数据如下：</li></ul><table><thead><tr><th>region</th><th>userCount</th><th>accessTime</th></tr></thead><tbody><tr><td>ShangHai</td><td>100</td><td>2017.11.11 10:01:00</td></tr><tr><td>BeiJing</td><td>86</td><td>2017.11.11 10:01:00</td></tr><tr><td>BeiJing</td><td>210</td><td>2017.11.11 10:06:00</td></tr><tr><td>BeiJing</td><td>33</td><td>2017.11.11 10:10:00</td></tr><tr><td>ShangHai</td><td>129</td><td>2017.11.11 12:10:00</td></tr></tbody></table><ul><li>PageAccessSession_tab<br>页面访问表，访问量，访问时间，用户所在地域信息，具体数据如下：</li></ul><table><thead><tr><th>region</th><th>userId</th><th>accessTime</th></tr></thead><tbody><tr><td>ShangHai</td><td>U0011</td><td>2017-11-11 10:01:00</td></tr><tr><td>ShangHai</td><td>U0012</td><td>2017-11-11 10:02:00</td></tr><tr><td>ShangHai</td><td>U0013</td><td>2017-11-11 10:03:00</td></tr><tr><td>ShangHai</td><td>U0015</td><td>2017-11-11 10:05:00</td></tr><tr><td>ShangHai</td><td>U0011</td><td>2017-11-11 10:10:00</td></tr><tr><td>BeiJing</td><td>U0110</td><td>2017-11-11 10:10:00</td></tr><tr><td>ShangHai</td><td>U2010</td><td>2017-11-11 10:11:00</td></tr><tr><td>ShangHai</td><td>U0410</td><td>2017-11-11 12:16:00</td></tr></tbody></table><h3 id="测试类"><a href="#测试类" class="headerlink" title="测试类"></a>测试类</h3><p>我们创建一个<code>SqlOverviewITCase.scala</code> 用于接下来介绍Flink SQL算子的功能体验。代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.<span class="type">StateBackend</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.memory.<span class="type">MemoryStateBackend</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.<span class="type">TimeCharacteristic</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.<span class="type">RichSinkFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">SourceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.<span class="type">SourceFunction</span>.<span class="type">SourceContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.watermark.<span class="type">Watermark</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.<span class="type">TableEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.<span class="type">Row</span></span><br><span class="line"><span class="keyword">import</span> org.junit.rules.<span class="type">TemporaryFolder</span></span><br><span class="line"><span class="keyword">import</span> org.junit.&#123;<span class="type">Rule</span>, <span class="type">Test</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SqlOverviewITCase</span> </span>&#123;</span><br><span class="line"><span class="keyword">val</span> _tempFolder = <span class="keyword">new</span> <span class="type">TemporaryFolder</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Rule</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tempFolder</span></span>: <span class="type">TemporaryFolder</span> = _tempFolder</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getStateBackend</span></span>: <span class="type">StateBackend</span> = &#123;</span><br><span class="line"><span class="keyword">new</span> <span class="type">MemoryStateBackend</span>()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 客户表数据</span></span><br><span class="line"><span class="keyword">val</span> customer_data = <span class="keyword">new</span> mutable.<span class="type">MutableList</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]</span><br><span class="line">customer_data.+=((<span class="string">"c_001"</span>, <span class="string">"Kevin"</span>, <span class="string">"from JinLin"</span>))</span><br><span class="line">customer_data.+=((<span class="string">"c_002"</span>, <span class="string">"Sunny"</span>, <span class="string">"from JinLin"</span>))</span><br><span class="line">customer_data.+=((<span class="string">"c_003"</span>, <span class="string">"JinCheng"</span>, <span class="string">"from HeBei"</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 订单表数据</span></span><br><span class="line"><span class="keyword">val</span> order_data = <span class="keyword">new</span> mutable.<span class="type">MutableList</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]</span><br><span class="line">order_data.+=((<span class="string">"o_001"</span>, <span class="string">"c_002"</span>, <span class="string">"2018-11-05 10:01:01"</span>, <span class="string">"iphone"</span>))</span><br><span class="line">order_data.+=((<span class="string">"o_002"</span>, <span class="string">"c_001"</span>, <span class="string">"2018-11-05 10:01:55"</span>, <span class="string">"ipad"</span>))</span><br><span class="line">order_data.+=((<span class="string">"o_003"</span>, <span class="string">"c_001"</span>, <span class="string">"2018-11-05 10:03:44"</span>, <span class="string">"flink book"</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 商品销售表数据</span></span><br><span class="line"><span class="keyword">val</span> item_data = <span class="type">Seq</span>(</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365660000</span>L, (<span class="number">1510365660000</span>L, <span class="number">20</span>, <span class="string">"ITEM001"</span>, <span class="string">"Electronic"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365660000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365720000</span>L, (<span class="number">1510365720000</span>L, <span class="number">50</span>, <span class="string">"ITEM002"</span>, <span class="string">"Electronic"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365720000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365780000</span>L, (<span class="number">1510365780000</span>L, <span class="number">30</span>, <span class="string">"ITEM003"</span>, <span class="string">"Electronic"</span>))),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365780000</span>L, (<span class="number">1510365780000</span>L, <span class="number">60</span>, <span class="string">"ITEM004"</span>, <span class="string">"Electronic"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365780000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365900000</span>L, (<span class="number">1510365900000</span>L, <span class="number">40</span>, <span class="string">"ITEM005"</span>, <span class="string">"Electronic"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365900000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365960000</span>L, (<span class="number">1510365960000</span>L, <span class="number">20</span>, <span class="string">"ITEM006"</span>, <span class="string">"Electronic"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365960000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366020000</span>L, (<span class="number">1510366020000</span>L, <span class="number">70</span>, <span class="string">"ITEM007"</span>, <span class="string">"Electronic"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366020000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366080000</span>L, (<span class="number">1510366080000</span>L, <span class="number">20</span>, <span class="string">"ITEM008"</span>, <span class="string">"Clothes"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">151036608000</span>L)))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 页面访问表数据</span></span><br><span class="line"><span class="keyword">val</span> pageAccess_data = <span class="type">Seq</span>(</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365660000</span>L, (<span class="number">1510365660000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0010"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365660000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365660000</span>L, (<span class="number">1510365660000</span>L, <span class="string">"BeiJing"</span>, <span class="string">"U1001"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365660000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366200000</span>L, (<span class="number">1510366200000</span>L, <span class="string">"BeiJing"</span>, <span class="string">"U2032"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366200000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366260000</span>L, (<span class="number">1510366260000</span>L, <span class="string">"BeiJing"</span>, <span class="string">"U1100"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366260000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510373400000</span>L, (<span class="number">1510373400000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0011"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510373400000</span>L)))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 页面访问量表数据2</span></span><br><span class="line"><span class="keyword">val</span> pageAccessCount_data = <span class="type">Seq</span>(</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365660000</span>L, (<span class="number">1510365660000</span>L, <span class="string">"ShangHai"</span>, <span class="number">100</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365660000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365660000</span>L, (<span class="number">1510365660000</span>L, <span class="string">"BeiJing"</span>, <span class="number">86</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365660000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365960000</span>L, (<span class="number">1510365960000</span>L, <span class="string">"BeiJing"</span>, <span class="number">210</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366200000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366200000</span>L, (<span class="number">1510366200000</span>L, <span class="string">"BeiJing"</span>, <span class="number">33</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366200000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510373400000</span>L, (<span class="number">1510373400000</span>L, <span class="string">"ShangHai"</span>, <span class="number">129</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510373400000</span>L)))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 页面访问表数据3</span></span><br><span class="line"><span class="keyword">val</span> pageAccessSession_data = <span class="type">Seq</span>(</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365660000</span>L, (<span class="number">1510365660000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0011"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365660000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365720000</span>L, (<span class="number">1510365720000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0012"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365720000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365720000</span>L, (<span class="number">1510365720000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0013"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365720000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510365900000</span>L, (<span class="number">1510365900000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0015"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510365900000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366200000</span>L, (<span class="number">1510366200000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0011"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366200000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366200000</span>L, (<span class="number">1510366200000</span>L, <span class="string">"BeiJing"</span>, <span class="string">"U2010"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366200000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510366260000</span>L, (<span class="number">1510366260000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0011"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510366260000</span>L)),</span><br><span class="line"><span class="type">Left</span>((<span class="number">1510373760000</span>L, (<span class="number">1510373760000</span>L, <span class="string">"ShangHai"</span>, <span class="string">"U0410"</span>))),</span><br><span class="line"><span class="type">Right</span>((<span class="number">1510373760000</span>L)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">procTimePrint</span></span>(sql: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// Streaming 环境</span></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="keyword">val</span> tEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将order_tab, customer_tab 注册到catalog</span></span><br><span class="line">    <span class="keyword">val</span> customer = env.fromCollection(customer_data).toTable(tEnv).as(<span class="symbol">'c_id</span>, <span class="symbol">'c_name</span>, <span class="symbol">'c_desc</span>)</span><br><span class="line">    <span class="keyword">val</span> order = env.fromCollection(order_data).toTable(tEnv).as(<span class="symbol">'o_id</span>, <span class="symbol">'c_id</span>, <span class="symbol">'o_time</span>, <span class="symbol">'o_desc</span>)</span><br><span class="line"></span><br><span class="line">    tEnv.registerTable(<span class="string">"order_tab"</span>, order)</span><br><span class="line">    tEnv.registerTable(<span class="string">"customer_tab"</span>, customer)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result = tEnv.sqlQuery(sql).toRetractStream[<span class="type">Row</span>]</span><br><span class="line">    <span class="keyword">val</span> sink = <span class="keyword">new</span> <span class="type">RetractingSink</span></span><br><span class="line">    result.addSink(sink)</span><br><span class="line">    env.execute()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rowTimePrint</span></span>(sql: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// Streaming 环境</span></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line">    env.setStateBackend(getStateBackend)</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">val</span> tEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将item_tab, pageAccess_tab 注册到catalog</span></span><br><span class="line">    <span class="keyword">val</span> item =</span><br><span class="line">    env.addSource(<span class="keyword">new</span> <span class="type">EventTimeSourceFunction</span>[(<span class="type">Long</span>, <span class="type">Int</span>, <span class="type">String</span>, <span class="type">String</span>)](item_data))</span><br><span class="line">    .toTable(tEnv, <span class="symbol">'onSellTime</span>, <span class="symbol">'price</span>, <span class="symbol">'itemID</span>, <span class="symbol">'itemType</span>, <span class="symbol">'rowtime</span>.rowtime)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pageAccess =</span><br><span class="line">    env.addSource(<span class="keyword">new</span> <span class="type">EventTimeSourceFunction</span>[(<span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)](pageAccess_data))</span><br><span class="line">    .toTable(tEnv, <span class="symbol">'accessTime</span>, <span class="symbol">'region</span>, <span class="symbol">'userId</span>, <span class="symbol">'rowtime</span>.rowtime)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pageAccessCount =</span><br><span class="line">    env.addSource(<span class="keyword">new</span> <span class="type">EventTimeSourceFunction</span>[(<span class="type">Long</span>, <span class="type">String</span>, <span class="type">Int</span>)](pageAccessCount_data))</span><br><span class="line">    .toTable(tEnv, <span class="symbol">'accessTime</span>, <span class="symbol">'region</span>, <span class="symbol">'accessCount</span>, <span class="symbol">'rowtime</span>.rowtime)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pageAccessSession =</span><br><span class="line">    env.addSource(<span class="keyword">new</span> <span class="type">EventTimeSourceFunction</span>[(<span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)](pageAccessSession_data))</span><br><span class="line">    .toTable(tEnv, <span class="symbol">'accessTime</span>, <span class="symbol">'region</span>, <span class="symbol">'userId</span>, <span class="symbol">'rowtime</span>.rowtime)</span><br><span class="line"></span><br><span class="line">    tEnv.registerTable(<span class="string">"item_tab"</span>, item)</span><br><span class="line">    tEnv.registerTable(<span class="string">"pageAccess_tab"</span>, pageAccess)</span><br><span class="line">    tEnv.registerTable(<span class="string">"pageAccessCount_tab"</span>, pageAccessCount)</span><br><span class="line">    tEnv.registerTable(<span class="string">"pageAccessSession_tab"</span>, pageAccessSession)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result = tEnv.sqlQuery(sql).toRetractStream[<span class="type">Row</span>]</span><br><span class="line">    <span class="keyword">val</span> sink = <span class="keyword">new</span> <span class="type">RetractingSink</span></span><br><span class="line">    result.addSink(sink)</span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testSelect</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sql = <span class="string">"替换想要测试的SQL"</span></span><br><span class="line">    <span class="comment">// 非window 相关用 procTimePrint(sql)</span></span><br><span class="line">    <span class="comment">// Window 相关用 rowTimePrint(sql)</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义Sink</span></span><br><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">RetractingSink</span> <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[(<span class="type">Boolean</span>, <span class="type">Row</span>)] </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> retractedResults: <span class="type">ArrayBuffer</span>[<span class="type">String</span>] = mutable.<span class="type">ArrayBuffer</span>.empty[<span class="type">String</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(v: (<span class="type">Boolean</span>, <span class="type">Row</span>)) &#123;</span><br><span class="line">    retractedResults.synchronized &#123;</span><br><span class="line">    <span class="keyword">val</span> value = v._2.toString</span><br><span class="line">    <span class="keyword">if</span> (v._1) &#123;</span><br><span class="line">    retractedResults += value</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> idx = retractedResults.indexOf(value)</span><br><span class="line">    <span class="keyword">if</span> (idx &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    retractedResults.remove(idx)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RuntimeException</span>(<span class="string">"Tried to retract a value that wasn't added first. "</span> +</span><br><span class="line">    <span class="string">"This is probably an incorrectly implemented test. "</span> +</span><br><span class="line">    <span class="string">"Try to set the parallelism of the sink to 1."</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    retractedResults.sorted.foreach(println(_))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Water mark 生成器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EventTimeSourceFunction</span>[<span class="type">T</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">dataWithTimestampList: <span class="type">Seq</span>[<span class="type">Either</span>[(<span class="type">Long</span>, <span class="type">T</span></span>), <span class="title">Long</span>]]) <span class="keyword">extends</span> <span class="title">SourceFunction</span>[<span class="type">T</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceContext</span>[<span class="type">T</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    dataWithTimestampList.foreach &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Left</span>(t) =&gt; ctx.collectWithTimestamp(t._2, t._1)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Right</span>(w) =&gt; ctx.emitWatermark(<span class="keyword">new</span> <span class="type">Watermark</span>(w))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = ???</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Select"><a href="#Select" class="headerlink" title="Select"></a>Select</h2><p>SELECT 用于从数据集/流中选择数据，语法遵循ANSI-SQL标准，语义是关系代数中的投影(Projection),对关系进行垂直分割，消去某</p><p>些列, 如下图所示:</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNibZ25Mic3yIbEcG8icTWkkJiaMcTr5oq0wTkT7rdZ5EkUpXEp26ZKVTrKw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p><strong>SQL 示例</strong></p><p>从<code>customer_tab</code>选择用户姓名，并用内置的CONCAT函数拼接客户信息，如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c_name, <span class="keyword">CONCAT</span>(c_name, <span class="string">' come '</span>, c_desc) <span class="keyword">as</span> <span class="keyword">desc</span> <span class="keyword">FROM</span> customer_tab;</span><br></pre></td></tr></table></figure><p><strong>结果如下：</strong></p><table><thead><tr><th>c_name</th><th>desc</th></tr></thead><tbody><tr><td>Kevin</td><td>Kevin come from JinLin</td></tr><tr><td>Sunny</td><td>Sunny come from JinLin</td></tr><tr><td>Jincheng</td><td>Jincheng come from HeBei</td></tr></tbody></table><p><strong>特别说明</strong></p><p>大家看到在 <code>SELECT</code> 不仅可以使用普通的字段选择，还可以使用<code>ScalarFunction</code>,当然也包括<code>User-Defined Function</code>，同时还可以进行字段的<code>alias</code>设置。其实<code>SELECT</code>可以结合聚合，在GROUPBY部分会进行介绍,一个比较特殊的使用场景是携带 <code>DISTINCT</code> 关键字，示例如下：</p><p><strong>SQL 示例</strong></p><p>在订单表查询所有的客户id，消除重复客户id, 如下：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> c_id <span class="keyword">FROM</span> order_tab;</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th></tr></thead><tbody><tr><td>c_001</td></tr><tr><td>c_002</td></tr></tbody></table><h2 id="WHERE"><a href="#WHERE" class="headerlink" title="WHERE"></a>WHERE</h2><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WHERE</span> 用于从数据集/流中过滤数据，与<span class="keyword">SELECT</span>一起使用，语法遵循<span class="keyword">ANSI</span>-SQL标准，语义是关系代数的Selection，根据某些条件对关系做水平分割，即选择符合条件的记录，如下所示：</span><br></pre></td></tr></table></figure><p><strong>SQL 示例</strong></p><p>在<code>customer_tab</code>查询客户id为<code>c_001</code>和<code>c_003</code>的客户信息，如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c_id, c_name, c_desc <span class="keyword">FROM</span> customer_tab <span class="keyword">WHERE</span> c_id = <span class="string">'c_001'</span> <span class="keyword">OR</span> c_id = <span class="string">'c_003'</span>;</span><br></pre></td></tr></table></figure><p><strong>Result</strong></p><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td></tr><tr><td>c_003</td><td>JinCheng</td><td>from HeBei</td></tr></tbody></table><p><strong>特别说明</strong></p><p>我们发现<code>WHERE</code>是对满足一定条件的数据进行过滤，<code>WHERE</code>支持=, &lt;, &gt;, &lt;&gt;, &gt;=, &lt;=以及<code>AND</code>， <code>OR</code>等表达式的组合，最终满足过滤条件的数据会被选择出来。并且 <code>WHERE</code> 可以结合<code>IN</code>,<code>NOT IN</code>联合使用，具体如下：</p><p><strong>SQL 示例 (IN 常量)</strong></p><p>使用 <code>IN</code> 在<code>customer_tab</code>查询客户id为<code>c_001</code>和<code>c_003</code>的客户信息，如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c_id, c_name, c_desc <span class="keyword">FROM</span> customer_tab <span class="keyword">WHERE</span> c_id <span class="keyword">IN</span> (<span class="string">'c_001'</span>, <span class="string">'c_003'</span>);</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td></tr><tr><td>c_003</td><td>JinCheng</td><td>from HeBei</td></tr></tbody></table><p><strong>SQL 示例 (IN 子查询)</strong></p><p>使用 <code>IN</code>和 子查询 在<code>customer_tab</code>查询已经下过订单的客户信息，如下：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c_id, c_name, c_desc <span class="keyword">FROM</span> customer_tab <span class="keyword">WHERE</span> c_id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> c_id <span class="keyword">FROM</span> order_tab);</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td></tr><tr><td>c_002</td><td>Sunny</td><td>from JinLin</td></tr></tbody></table><p><strong>IN/NOT IN 与关系代数</strong></p><p>如上介绍IN是关系代数中的Intersection， NOT IN是关系代数的Difference， 如下图示意：</p><ul><li>IN(Intersection</li><li><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NZSOY21trjlOtCxGBVOiblp6icardxtCKeaf7RHrFbN6TVbyqyGOGuSWYY7uY3DJb5ODYsOqvv1mWQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></li><li>NOT IN(Difference）</li><li><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NZSOY21trjlOtCxGBVOiblpcofHeFia7icQorYjiaGmHO9yiclrFaMCk3l6sBuQa2sm5QlrtepLOrdIMA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></li></ul><h2 id="GROUP-BY"><a href="#GROUP-BY" class="headerlink" title="GROUP BY"></a>GROUP BY</h2><p>GROUP BY 是对数据进行分组的操作，比如我需要分别计算一下一个学生表里面女生和男生的人数分别是多少，如下</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NZSOY21trjlOtCxGBVOiblpoeicHXKPbhnpAKEe8cMRzf4WHDQiagwAHRIlH6icqn107hHkiaeJh2CWDQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p><strong>SQL 示例</strong></p><p>将order_tab信息按customer_tab分组统计订单数量，简单示例如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT c_id, count(o_id) as o_count <span class="keyword">FROM</span> order_tab<span class="built_in"> GROUP </span>BY c_id;</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th><th>o_count</th></tr></thead><tbody><tr><td>c_001</td><td>2</td></tr><tr><td>c_002</td><td>1</td></tr></tbody></table><p><strong>特别说明</strong></p><p>在实际的业务场景中，GROUP BY除了按业务字段进行分组外，很多时候用户也可以用时间来进行分组(相当于划分窗口)，比如统计每分钟的订单数量：</p><p><strong>SQL 示例</strong></p><p>按时间进行分组，查询每分钟的订单数量，如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT SUBSTRING(o_time, 1, 16) AS o_time_min, count(o_id) AS o_count <span class="keyword">FROM</span> order_tab<span class="built_in"> GROUP </span>BY SUBSTRING(o_time, 1, 16)</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>o_time_min</th><th>o_count</th></tr></thead><tbody><tr><td>2018-11-05 10:01</td><td>2</td></tr><tr><td>2018-11-05 10:03</td><td>1</td></tr></tbody></table><p>说明：如果我们时间字段是timestamp类型，建议使用内置的 <code>DATE_FORMAT</code> 函数。</p><h2 id="UNION-ALL"><a href="#UNION-ALL" class="headerlink" title="UNION ALL"></a>UNION ALL</h2><p>UNION ALL 将两个表合并起来，要求两个表的字段完全一致，包括字段类型、字段顺序,语义对应关系代数的Union，只是关系代数是Set集合操作，会有去重复操作，UNION ALL 不进行去重，如下所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNpaHuv6VYq4P9Zyke2cuHCIwibTbicJpXicRJWemZsJN6Y1Nq3vKVNzpNg/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p><strong>SQL 示例</strong></p><p>我们简单的将<code>customer_tab</code>查询2次，将查询结果合并起来，如下：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c_id, c_name, c_desc  <span class="keyword">FROM</span> customer_tab </span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> c_id, c_name, c_desc  <span class="keyword">FROM</span> customer_tab</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td></tr><tr><td>c_002</td><td>Sunny</td><td>from JinLin</td></tr><tr><td>c_003</td><td>JinCheng</td><td>from HeBei</td></tr><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td></tr><tr><td>c_002</td><td>Sunny</td><td>from JinLin</td></tr><tr><td>c_003</td><td>JinCheng</td><td>from HeBei</td></tr></tbody></table><p><strong>特别说明</strong></p><p>UNION ALL 对结果数据不进行去重，如果想对结果数据进行去重，传统数据库需要进行UNION操作。</p><h2 id="UNION"><a href="#UNION" class="headerlink" title="UNION"></a>UNION</h2><p>UNION 将两个流给合并起来，要求两个流的字段完全一致，包括字段类型、字段顺序，并其UNION 不同于UNION ALL，UNION会对结果数据去重,与关系代数的Union语义一致，如下：<br><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNALmfI36VBMGEontFaDkRleLsSbErPHtRYvT0dBQ4ic6kwQD3AEJIhfQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p><strong>SQL 示例</strong></p><p>我们简单的将<code>customer_tab</code>查询2次，将查询结果合并起来，如下：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c_id, c_name, c_desc  <span class="keyword">FROM</span> customer_tab </span><br><span class="line"><span class="keyword">UNION</span> </span><br><span class="line"><span class="keyword">SELECT</span> c_id, c_name, c_desc  <span class="keyword">FROM</span> customer_tab</span><br></pre></td></tr></table></figure><p>我们发现完全一样的表数据进行 <code>UNION</code>之后，数据是被去重的，<code>UNION</code>之后的数据并没有增加。</p><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td></tr><tr><td>c_002</td><td>Sunny</td><td>from JinLin</td></tr><tr><td>c_003</td><td>JinCheng</td><td>from HeBei</td></tr></tbody></table><p><strong>特别说明</strong></p><p>UNION 对结果数据进行去重，在实际的实现过程需要对数据进行排序操作，所以非必要去重情况请使用UNION ALL操作。</p><h2 id="JOIN"><a href="#JOIN" class="headerlink" title="JOIN"></a>JOIN</h2><p>JOIN 用于把来自两个表的行联合起来形成一个宽表，Apache Flink支持的JOIN类型：</p><ul><li>JOIN - INNER JOIN</li><li>LEFT JOIN - LEFT OUTER JOIN</li><li>RIGHT JOIN - RIGHT OUTER JOIN</li><li>FULL JOIN - FULL OUTER JOIN</li></ul><p>JOIN与关系代数的Join语义相同，具体如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvN8qxel16siciaMAH8x3aQCcZ6q0ic8QrtZtco3D9frZFjHfZYj4q33hszg/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p><strong>SQL 示例 (JOIN)</strong></p><p><code>INNER JOIN</code>只选择满足<code>ON</code>条件的记录，我们查询<code>customer_tab</code> 和 <code>order_tab</code>表，将有订单的客户和订单信息选择出来，如下：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> customer_tab <span class="keyword">AS</span> c <span class="keyword">JOIN</span> order_tab <span class="keyword">AS</span> o <span class="keyword">ON</span> o.c_id = c.c_id</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th><th>o_id</th><th>c_id</th><th>o_time</th><th>o_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td><td>o_002</td><td>c_001</td><td>2018-11-05 10:01:55</td><td>ipad</td></tr><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td><td>o_003</td><td>c_001</td><td>2018-11-05 10:03:44</td><td>flink book</td></tr><tr><td>c_002</td><td>Sunny</td><td>from JinLin</td><td>o_oo1</td><td>c_002</td><td>2018-11-05 10:01:01</td><td>iphone</td></tr></tbody></table><p><strong>SQL 示例 (LEFT JOIN)</strong></p><p><code>LEFT JOIN</code>与<code>INNER JOIN</code>的区别是当右表没有与左边相JOIN的数据时候，右边对应的字段补<code>NULL</code>输出，语义如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNLcrI9iar3vKlgxMwRceIAMCZm2uNbhUWINhK1yRAllPdkwVJ1PcHhqQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>对应的SQL语句如下(LEFT JOIN)：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT ColA, ColB, <span class="built_in">T2</span>.ColC, ColE FROM TI LEFT <span class="keyword">JOIN </span><span class="built_in">T2</span> ON <span class="built_in">T1</span>.ColC = <span class="built_in">T2</span>.ColC <span class="comment">;</span></span><br></pre></td></tr></table></figure><ul><li>细心的读者可能发现上面T2.ColC是添加了前缀T2了，这里需要说明一下，当两张表有字段名字一样的时候，我需要指定是从那个表里面投影的。</li></ul><p>我们查询<code>customer_tab</code> 和 <code>order_tab</code>表，将客户和订单信息选择出来如下：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> customer_tab <span class="keyword">AS</span> c <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> order_tab <span class="keyword">AS</span> o <span class="keyword">ON</span> o.c_id = c.c_id</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>c_id</th><th>c_name</th><th>c_desc</th><th>o_id</th><th>c_id</th><th>o_time</th><th>o_desc</th></tr></thead><tbody><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td><td>o_002</td><td>c_001</td><td>2018-11-05 10:01:55</td><td>ipad</td></tr><tr><td>c_001</td><td>Kevin</td><td>from JinLin</td><td>o_003</td><td>c_001</td><td>2018-11-05 10:03:44</td><td>flink book</td></tr><tr><td>c_002</td><td>Sunny</td><td>from JinLin</td><td>o_oo1</td><td>c_002</td><td>2018-11-05 10:01:01</td><td>iphone</td></tr><tr><td>c_003</td><td>JinCheng</td><td>from HeBei</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td></tr></tbody></table><p><strong>特别说明</strong></p><p><code>RIGHT JOIN</code> 相当于 <code>LEFT JOIN</code> 左右两个表交互一下位置。<code>FULL JOIN</code>相当于 <code>RIGHT JOIN</code> 和 <code>LEFT JOIN</code> 之后进行<code>UNION ALL</code>操作。</p><h2 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h2><p>在Apache Flink中有2种类型的Window，一种是OverWindow，即传统数据库的标准开窗，每一个元素都对应一个窗口。一种是GroupWindow，目前在SQL中GroupWindow都是基于时间进行窗口划分的。</p><h3 id="Over-Window"><a href="#Over-Window" class="headerlink" title="Over Window"></a>Over Window</h3><p>Apache Flink中对OVER Window的定义遵循标准SQL的定义语法。<br>按ROWS和RANGE分类是传统数据库的标准分类方法，在Apache Flink中还可以根据时间类型(ProcTime/EventTime)和窗口的有限和无限(Bounded/UnBounded)进行分类，共计8种类型。为了避免大家对过细分类造成困扰，我们按照确定当前行的不同方式将OVER Window分成两大类进行介绍，如下:</p><ul><li>ROWS OVER Window - 每一行元素都视为新的计算行，即，每一行都是一个新的窗口。</li><li>RANGE OVER Window - 具有相同时间值的所有元素行视为同一计算行，即，具有相同时间值的所有行都是同一个窗口。</li></ul><h4 id="Bounded-ROWS-OVER-Window"><a href="#Bounded-ROWS-OVER-Window" class="headerlink" title="Bounded ROWS OVER Window"></a>Bounded ROWS OVER Window</h4><p>Bounded ROWS OVER Window 每一行元素都视为新的计算行，即，每一行都是一个新的窗口。</p><p><strong>语义</strong></p><p>我们以3个元素(2 PRECEDING)的窗口为例，如下图:</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvN6yotUibfmTVgbnFd7dvC4tgfFEddh0xJ6PzC9wzLDgiaemZoCCjVNxaw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>上图所示窗口 user 1 的 w5和w6， user 2的 窗口 w2 和 w3，虽然有元素都是同一时刻到达，但是他们仍然是在不同的窗口，这一点有别于RANGE OVER Window。</p><p><strong>语法</strong></p><p>Bounded ROWS OVER Window 语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    agg1(col1) <span class="keyword">OVER</span>(</span><br><span class="line">     [<span class="keyword">PARTITION</span> <span class="keyword">BY</span> (value_expression1,..., value_expressionN)] </span><br><span class="line">     <span class="keyword">ORDER</span> <span class="keyword">BY</span> timeCol</span><br><span class="line">     <span class="keyword">ROWS</span> </span><br><span class="line">     <span class="keyword">BETWEEN</span> (<span class="keyword">UNBOUNDED</span> | rowCount) <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>) <span class="keyword">AS</span> colName, </span><br><span class="line">... </span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br></pre></td></tr></table></figure><ul><li>value_expression - 进行分区的字表达式；</li><li>timeCol - 用于元素排序的时间字段；</li><li>rowCount - 是定义根据当前行开始向前追溯几行元素。</li></ul><p><strong>SQL 示例</strong></p><p>利用<code>item_tab</code>测试数据，我们统计同类商品中当前和当前商品之前2个商品中的最高价格。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    itemID,</span><br><span class="line">    itemType, </span><br><span class="line">    onSellTime, </span><br><span class="line">    price,  </span><br><span class="line">    <span class="keyword">MAX</span>(price) <span class="keyword">OVER</span> (</span><br><span class="line">        <span class="keyword">PARTITION</span> <span class="keyword">BY</span> itemType </span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> onSellTime </span><br><span class="line">        <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> <span class="keyword">preceding</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>) <span class="keyword">AS</span> maxPrice</span><br><span class="line">  <span class="keyword">FROM</span> item_tab</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>itemID</th><th>itemType</th><th>onSellTime</th><th>price</th><th>maxPrice</th></tr></thead><tbody><tr><td>ITEM001</td><td>Electronic</td><td>2017-11-11 10:01:00</td><td>20</td><td>20</td></tr><tr><td>ITEM002</td><td>Electronic</td><td>2017-11-11 10:02:00</td><td>50</td><td>50</td></tr><tr><td>ITEM003</td><td>Electronic</td><td>2017-11-11 10:03:00</td><td>30</td><td>50</td></tr><tr><td>ITEM004</td><td>Electronic</td><td>2017-11-11 10:03:00</td><td>60</td><td>60</td></tr><tr><td>ITEM005</td><td>Electronic</td><td>2017-11-11 10:05:00</td><td>40</td><td>60</td></tr><tr><td>ITEM006</td><td>Electronic</td><td>2017-11-11 10:06:00</td><td>20</td><td>60</td></tr><tr><td>ITEM007</td><td>Electronic</td><td>2017-11-11 10:07:00</td><td>70</td><td>70</td></tr><tr><td>ITEM008</td><td>Clothes</td><td>2017-11-11 10:08:00</td><td>20</td><td>20</td></tr></tbody></table><h4 id="Bounded-RANGE-OVER-Window"><a href="#Bounded-RANGE-OVER-Window" class="headerlink" title="Bounded RANGE OVER Window"></a>Bounded RANGE OVER Window</h4><p>Bounded RANGE OVER Window 具有相同时间值的所有元素行视为同一计算行，即，具有相同时间值的所有行都是同一个窗口。</p><p><strong>语义</strong></p><p>我们以3秒中数据(INTERVAL ‘2’ SECOND)的窗口为例，如下图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNTtvBlDvT0wfxJvTOL8e9CbVJg6YVxAfLMKskjXibicrCeOGgIZxAJxdw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>注意: 上图所示窗口 user 1 的 w6， user 2的 窗口 w3，元素都是同一时刻到达,他们是在同一个窗口，这一点有别于ROWS OVER Window。</p><p><strong>语法</strong></p><p>Bounded RANGE OVER Window的语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    agg1(col1) <span class="keyword">OVER</span>(</span><br><span class="line">     [<span class="keyword">PARTITION</span> <span class="keyword">BY</span> (value_expression1,..., value_expressionN)] </span><br><span class="line">     <span class="keyword">ORDER</span> <span class="keyword">BY</span> timeCol</span><br><span class="line">     <span class="keyword">RANGE</span> </span><br><span class="line">     <span class="keyword">BETWEEN</span> (<span class="keyword">UNBOUNDED</span> | timeInterval) <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>) <span class="keyword">AS</span> colName, </span><br><span class="line">... </span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br></pre></td></tr></table></figure><ul><li>value_expression - 进行分区的字表达式；</li><li>timeCol - 用于元素排序的时间字段；</li><li>timeInterval - 是定义根据当前行开始向前追溯指定时间的元素行；</li></ul><p><strong>SQL 示例</strong></p><p>我们统计同类商品中当前和当前商品之前2分钟商品中的最高价格。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    itemID,</span><br><span class="line">    itemType, </span><br><span class="line">    onSellTime, </span><br><span class="line">    price,  </span><br><span class="line">    <span class="keyword">MAX</span>(price) <span class="keyword">OVER</span> (</span><br><span class="line">        <span class="keyword">PARTITION</span> <span class="keyword">BY</span> itemType </span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> rowtime </span><br><span class="line">        <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="built_in">INTERVAL</span> <span class="string">'2'</span> <span class="keyword">MINUTE</span> <span class="keyword">preceding</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>) <span class="keyword">AS</span> maxPrice</span><br><span class="line">  <span class="keyword">FROM</span> item_tab</span><br></pre></td></tr></table></figure><p><strong>结果如下（Bounded RANGE OVER Windo</strong>w）</p><table><thead><tr><th>itemID</th><th>itemType</th><th>onSellTime</th><th>price</th><th>maxPrice</th></tr></thead><tbody><tr><td>ITEM001</td><td>Electronic</td><td>2017-11-11 10:01:00</td><td>20</td><td>20</td></tr><tr><td>ITEM002</td><td>Electronic</td><td>2017-11-11 10:02:00</td><td>50</td><td>50</td></tr><tr><td>ITEM003</td><td>Electronic</td><td>2017-11-11 10:03:00</td><td>30</td><td>60</td></tr><tr><td>ITEM004</td><td>Electronic</td><td>2017-11-11 10:03:00</td><td>60</td><td>60</td></tr><tr><td>ITEM005</td><td>Electronic</td><td>2017-11-11 10:05:00</td><td>40</td><td>60</td></tr><tr><td>ITEM006</td><td>Electronic</td><td>2017-11-11 10:06:00</td><td>20</td><td>40</td></tr><tr><td>ITEM007</td><td>Electronic</td><td>2017-11-11 10:07:00</td><td>70</td><td>70</td></tr><tr><td>ITEM008</td><td>Clothes</td><td>2017-11-11 10:08:00</td><td>20</td><td>20</td></tr></tbody></table><p><strong>特别说明</strong></p><p>OverWindow最重要是要理解每一行数据都确定一个窗口，同时目前在Apache Flink中只支持按时间字段排序。并且OverWindow开窗与GroupBy方式数据分组最大的不同在于，GroupBy数据分组统计时候，在<code>SELECT</code>中除了GROUP BY的key，不能直接选择其他非key的字段，但是OverWindow没有这个限制，<code>SELECT</code>可以选择任何字段。比如一张表table(a,b,c,d)4个字段，如果按d分组求c的最大值，两种写完如下:</p><ul><li>GROUP BY - <code>SELECT d, MAX(c) FROM table GROUP BY d</code></li><li>OVER Window = <code>SELECT a, b, c, d, MAX(c) OVER(PARTITION BY d, ORDER BY ProcTime())</code><br>如上 OVER Window 虽然PARTITION BY d,但SELECT 中仍然可以选择 a,b,c字段。但在GROUPBY中，SELECT 只能选择 d 字段。</li></ul><h3 id="Group-Window"><a href="#Group-Window" class="headerlink" title="Group Window"></a>Group Window</h3><p>根据窗口数据划分的不同，目前Apache Flink有如下3种Bounded Winodw:</p><ul><li>Tumble - 滚动窗口，窗口数据有固定的大小，窗口数据无叠加；</li><li>Hop - 滑动窗口，窗口数据有固定大小，并且有固定的窗口重建频率，窗口数据有叠加；</li><li>Session - 会话窗口，窗口数据没有固定的大小，根据窗口数据活跃程度划分窗口，窗口数据无叠加。</li></ul><p>说明： Aapche Flink 还支持UnBounded的 Group Window，也就是全局Window，流上所有数据都在一个窗口里面，语义非常简单，这里不做详细介绍了。</p><h4 id="Tumble"><a href="#Tumble" class="headerlink" title="Tumble"></a>Tumble</h4><p><strong>语义</strong></p><p>Tumble 滚动窗口有固定size，窗口数据不重叠,具体语义如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvN9PPeHiaOUQib8BG2xs3YPxpN8EYibnRNkFxgicW1kPrNeicE8vpcUB7tspA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p><strong>语法</strong></p><p>Tumble 滚动窗口对应的语法如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT </span><br><span class="line">    [gk],</span><br><span class="line">    [TUMBLE_START(timeCol, size)], </span><br><span class="line">    [TUMBLE_END(timeCol, size)], </span><br><span class="line">    agg1(col1), </span><br><span class="line">    <span class="built_in">..</span>. </span><br><span class="line">    aggn(colN)</span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br><span class="line">GROUP BY [gk], TUMBLE(timeCol, size)</span><br></pre></td></tr></table></figure><ul><li>[gk] - 决定了流是Keyed还是/Non-Keyed;</li><li>TUMBLE_START - 窗口开始时间;</li><li>TUMBLE_END - 窗口结束时间;</li><li>timeCol - 是流表中表示时间字段；</li><li>size - 表示窗口的大小，如 秒，分钟，小时，天。</li></ul><p><strong>SQL 示例</strong></p><p>利用<code>pageAccess_tab</code>测试数据，我们需要按不同地域统计每2分钟的淘宝首页的访问量(PV)。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    region,</span><br><span class="line">    TUMBLE_START(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'2'</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winStart,  </span><br><span class="line">    TUMBLE_END(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'2'</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winEnd,  </span><br><span class="line">    <span class="keyword">COUNT</span>(region) <span class="keyword">AS</span> pv</span><br><span class="line"><span class="keyword">FROM</span> pageAccess_tab </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> region, TUMBLE(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'2'</span> <span class="keyword">MINUTE</span>)</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>region</th><th>winStart</th><th>winEnd</th><th>pv</th></tr></thead><tbody><tr><td>BeiJing</td><td>2017-11-11 02:00:00.0</td><td>2017-11-11 02:02:00.0</td><td>1</td></tr><tr><td>BeiJing</td><td>2017-11-11 02:10:00.0</td><td>2017-11-11 02:12:00.0</td><td>2</td></tr><tr><td>ShangHai</td><td>2017-11-11 02:00:00.0</td><td>2017-11-11 02:02:00.0</td><td>1</td></tr><tr><td>ShangHai</td><td>2017-11-11 04:10:00.0</td><td>2017-11-11 04:12:00.0</td><td>1</td></tr></tbody></table><h4 id="Hop"><a href="#Hop" class="headerlink" title="Hop"></a>Hop</h4><p>Hop 滑动窗口和滚动窗口类似，窗口有固定的size，与滚动窗口不同的是滑动窗口可以通过slide参数控制滑动窗口的新建频率。因此当slide值小于窗口size的值的时候多个滑动窗口会重叠。</p><p><strong>语义</strong></p><p>Hop 滑动窗口语义如下所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNCwyBicMTKEicSxibebwTfwvImiaA2TlN0FuM0wuG6zAibYyk5JrfBTmrwEA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p><strong>语法</strong></p><p>Hop 滑动窗口对应语法如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT </span><br><span class="line">    [gk], </span><br><span class="line">    [HOP_START(timeCol, slide, size)] ,  </span><br><span class="line">    [HOP_END(timeCol, slide, size)],</span><br><span class="line">    agg1(col1), </span><br><span class="line">    <span class="built_in">..</span>. </span><br><span class="line">    aggN(colN) </span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br><span class="line">GROUP BY [gk], HOP(timeCol, slide, size)</span><br></pre></td></tr></table></figure><ul><li>[gk] 决定了流是Keyed还是/Non-Keyed;</li><li>HOP_START - 窗口开始时间;</li><li>HOP_END - 窗口结束时间;</li><li>timeCol - 是流表中表示时间字段；</li><li>slide - 是滑动步伐的大小；</li><li>size - 是窗口的大小，如 秒，分钟，小时，天；</li></ul><p><strong>SQL 示例</strong></p><p>利用<code>pageAccessCount_tab</code>测试数据，我们需要每5分钟统计近10分钟的页面访问量(PV).</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">  HOP_START(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">MINUTE</span>, <span class="built_in">INTERVAL</span> <span class="string">'10'</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winStart,  </span><br><span class="line">  HOP_END(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">MINUTE</span>, <span class="built_in">INTERVAL</span> <span class="string">'10'</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winEnd,  </span><br><span class="line">  <span class="keyword">SUM</span>(accessCount) <span class="keyword">AS</span> accessCount  </span><br><span class="line"><span class="keyword">FROM</span> pageAccessCount_tab </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> HOP(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">MINUTE</span>, <span class="built_in">INTERVAL</span> <span class="string">'10'</span> <span class="keyword">MINUTE</span>)</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>winStart</th><th>winEnd</th><th>accessCount</th></tr></thead><tbody><tr><td>2017-11-11 01:55:00.0</td><td>2017-11-11 02:05:00.0</td><td>186</td></tr><tr><td>2017-11-11 02:00:00.0</td><td>2017-11-11 02:10:00.0</td><td>396</td></tr><tr><td>2017-11-11 02:05:00.0</td><td>2017-11-11 02:15:00.0</td><td>243</td></tr><tr><td>2017-11-11 02:10:00.0</td><td>2017-11-11 02:20:00.0</td><td>33</td></tr><tr><td>2017-11-11 04:05:00.0</td><td>2017-11-11 04:15:00.0</td><td>129</td></tr><tr><td>2017-11-11 04:10:00.0</td><td>2017-11-11 04:20:00.0</td><td>129</td></tr></tbody></table><h4 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h4><p>Seeeion 会话窗口 是没有固定大小的窗口，通过session的活跃度分组元素。不同于滚动窗口和滑动窗口，会话窗口不重叠,也没有固定的起止时间。一个会话窗口在一段时间内没有接收到元素时，即当出现非活跃间隙时关闭。一个会话窗口 分配器通过配置session gap来指定非活跃周期的时长.</p><p>语义</p><p>Session 会话窗口语义如下所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NJ7vfubd8agGwvHzRBngvNfhx9EQvp4OyBYHue50QEzW3qZfxeRV5DCb8CkcneoGjadj7NqNHq9w/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p><strong>语法</strong></p><p>Seeeion 会话窗口对应语法如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT </span><br><span class="line">    [gk], </span><br><span class="line">    SESSION_START(timeCol, gap) AS winStart,  </span><br><span class="line">    SESSION_END(timeCol, gap) AS winEnd,</span><br><span class="line">    agg1(col1),</span><br><span class="line">     <span class="built_in">..</span>. </span><br><span class="line">    aggn(colN)</span><br><span class="line"><span class="keyword">FROM</span> Tab1</span><br><span class="line">GROUP BY [gk], SESSION(timeCol, gap)</span><br></pre></td></tr></table></figure><ul><li>[gk] 决定了流是Keyed还是/Non-Keyed;</li><li>SESSION_START - 窗口开始时间；</li><li>SESSION_END - 窗口结束时间；</li><li>timeCol - 是流表中表示时间字段；</li><li>gap - 是窗口数据非活跃周期的时长；</li></ul><p><strong>SQL 示例</strong></p><p>利用<code>pageAccessSession_tab</code>测试数据，我们按地域统计连续的两个访问用户之间的访问时间间隔不超过3分钟的的页面访问量(PV).</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  </span><br><span class="line">    region, </span><br><span class="line">    SESSION_START(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'3'</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winStart,  </span><br><span class="line">    SESSION_END(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'3'</span> <span class="keyword">MINUTE</span>) <span class="keyword">AS</span> winEnd, </span><br><span class="line">    <span class="keyword">COUNT</span>(region) <span class="keyword">AS</span> pv  </span><br><span class="line"><span class="keyword">FROM</span> pageAccessSession_tab</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> region, <span class="keyword">SESSION</span>(rowtime, <span class="built_in">INTERVAL</span> <span class="string">'3'</span> <span class="keyword">MINUTE</span>)</span><br></pre></td></tr></table></figure><p><strong>结果如下</strong></p><table><thead><tr><th>region</th><th>winStart</th><th>winEnd</th><th>pv</th></tr></thead><tbody><tr><td>BeiJing</td><td>2017-11-11 02:10:00.0</td><td>2017-11-11 02:13:00.0</td><td>1</td></tr><tr><td>ShangHai</td><td>2017-11-11 02:01:00.0</td><td>2017-11-11 02:08:00.0</td><td>4</td></tr><tr><td>ShangHai</td><td>2017-11-11 02:10:00.0</td><td>2017-11-11 02:14:00.0</td><td>2</td></tr><tr><td>ShangHai</td><td>2017-11-11 04:16:00.0</td><td>2017-11-11 04:19:00.0</td><td>1</td></tr></tbody></table><h2 id="UDX"><a href="#UDX" class="headerlink" title="UDX"></a>UDX</h2><p>Apache Flink 除了提供了大部分ANSI-SQL的核心算子，也为用户提供了自己编写业务代码的机会，那就是User-Defined Function,目前支持如下三种 User-Defined Function：</p><ul><li>UDF - User-Defined Scalar Function</li><li>UDTF - User-Defined Table Function</li><li>UDAF - User-Defined Aggregate Funciton</li></ul><p>UDX都是用户自定义的函数，那么Apache Flink框架为啥将自定义的函数分成三类呢？是根据什么划分的呢？Apache Flink对自定义函数进行分类的依据是根据函数语义的不同，函数的输入和输出不同来分类的，具体如下：</p><table><thead><tr><th>UDX</th><th>INPUT</th><th>OUTPUT</th><th>INPUT:OUTPUT</th></tr></thead><tbody><tr><td>UDF</td><td>单行中的N(N&gt;=0)列</td><td>单行中的1列</td><td>1:1</td></tr><tr><td>UDTF</td><td>单行中的N(N&gt;=0)列</td><td>M(M&gt;=0)行</td><td>1:N(N&gt;=0)</td></tr><tr><td>UDAF</td><td>M(M&gt;=0)行中的每行的N(N&gt;=0)列</td><td>单行中的1列</td><td>M：1(M&gt;=0)</td></tr></tbody></table><h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><ul><li>定义<br>用户想自己编写一个字符串联接的UDF，我们只需要实现<code>ScalarFunction#eval()</code>方法即可，简单实现如下：</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyConnect</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="meta">@varargs</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(args: <span class="type">String</span>*): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sb = <span class="keyword">new</span> <span class="type">StringBuilder</span></span><br><span class="line">    <span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; args.length) &#123;</span><br><span class="line">      <span class="keyword">if</span> (args(i) == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">      &#125;</span><br><span class="line">      sb.append(args(i))</span><br><span class="line">      i += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    sb.toString</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>使用</li></ul><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"> <span class="keyword">val</span> <span class="function"><span class="keyword">fun</span> = MyConnect</span></span><br><span class="line"> tEnv.registerFunction(<span class="string">"myConnect"</span>, <span class="function"><span class="keyword">fun</span>)</span></span><br><span class="line"> <span class="keyword">val</span> sql = <span class="string">"SELECT myConnect(a, b) as str FROM tab"</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="UDTF"><a href="#UDTF" class="headerlink" title="UDTF"></a>UDTF</h3><ul><li>定义<br>用户想自己编写一个字符串切分的UDTF，我们只需要实现<code>TableFunction#eval()</code>方法即可，简单实现如下：</li></ul><p>ScalarFunction#eval()`</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySplit</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>[<span class="type">String</span>] </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(str: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (str.contains(<span class="string">"#"</span>))&#123;</span><br><span class="line">      str.split(<span class="string">"#"</span>).foreach(collect)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(str: <span class="type">String</span>, prefix: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (str.contains(<span class="string">"#"</span>)) &#123;</span><br><span class="line">      str.split(<span class="string">"#"</span>).foreach(s =&gt; collect(prefix + s))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>使用</li></ul><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">val</span> <span class="function"><span class="keyword">fun</span> = new <span class="title">MySplit</span><span class="params">()</span></span></span><br><span class="line">tEnv.registerFunction(<span class="string">"mySplit"</span>, <span class="function"><span class="keyword">fun</span>)</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">"SELECT c, s FROM MyTable, LATERAL TABLE(mySplit(c)) AS T(s)"</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="UDAF"><a href="#UDAF" class="headerlink" title="UDAF"></a>UDAF</h3><ul><li>定义<br>UDAF 要实现的接口比较多，我们以一个简单的CountAGG为例，做简单实现如下：</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** The initial accumulator for count aggregate function */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountAccumulator</span> <span class="keyword">extends</span> <span class="title">JTuple1</span>[<span class="type">Long</span>] </span>&#123;</span><br><span class="line">  f0 = <span class="number">0</span>L <span class="comment">//count</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * User-defined count aggregate function</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCount</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">JLong</span>, <span class="type">CountAccumulator</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// process argument is optimized by Calcite.</span></span><br><span class="line">  <span class="comment">// For instance count(42) or count(*) will be optimized to count().</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    acc.f0 += <span class="number">1</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// process argument is optimized by Calcite.</span></span><br><span class="line">  <span class="comment">// For instance count(42) or count(*) will be optimized to count().</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">retract</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    acc.f0 -= <span class="number">1</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(acc: <span class="type">CountAccumulator</span>, value: <span class="type">Any</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (value != <span class="literal">null</span>) &#123;</span><br><span class="line">      acc.f0 += <span class="number">1</span>L</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">retract</span></span>(acc: <span class="type">CountAccumulator</span>, value: <span class="type">Any</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (value != <span class="literal">null</span>) &#123;</span><br><span class="line">      acc.f0 -= <span class="number">1</span>L</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">JLong</span> = &#123;</span><br><span class="line">    acc.f0</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(acc: <span class="type">CountAccumulator</span>, its: <span class="type">JIterable</span>[<span class="type">CountAccumulator</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> iter = its.iterator()</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">      acc.f0 += iter.next().f0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">CountAccumulator</span> = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">CountAccumulator</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resetAccumulator</span></span>(acc: <span class="type">CountAccumulator</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    acc.f0 = <span class="number">0</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getAccumulatorType</span></span>: <span class="type">TypeInformation</span>[<span class="type">CountAccumulator</span>] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">TupleTypeInfo</span>(classOf[<span class="type">CountAccumulator</span>], <span class="type">BasicTypeInfo</span>.<span class="type">LONG_TYPE_INFO</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResultType</span></span>: <span class="type">TypeInformation</span>[<span class="type">JLong</span>] =</span><br><span class="line">    <span class="type">BasicTypeInfo</span>.<span class="type">LONG_TYPE_INFO</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>使用</li></ul><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">val</span> <span class="function"><span class="keyword">fun</span> = new <span class="title">MyCount</span><span class="params">()</span></span></span><br><span class="line">tEnv.registerFunction(<span class="string">"myCount"</span>, <span class="function"><span class="keyword">fun</span>)</span></span><br><span class="line"><span class="keyword">val</span> sql = <span class="string">"SELECT myCount(c) FROM MyTable GROUP BY  a"</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><h1 id="Source-amp-Sink"><a href="#Source-amp-Sink" class="headerlink" title="Source&amp;Sink"></a>Source&amp;Sink</h1><p>上面我们介绍了Apache Flink SQL核心算子的语法及语义，这部分将选取Bounded EventTime Tumble Window为例为大家编写一个完整的包括Source和Sink定义的Apache Flink SQL Job。假设有一张淘宝页面访问表(PageAccess_tab)，有地域，用户ID和访问时间。我们需要按不同地域统计每2分钟的淘宝首页的访问量(PV). 具体数据如下：</p><table><thead><tr><th>region</th><th>userId</th><th>accessTime</th></tr></thead><tbody><tr><td>ShangHai</td><td>U0010</td><td>2017-11-11 10:01:00</td></tr><tr><td>BeiJing</td><td>U1001</td><td>2017-11-11 10:01:00</td></tr><tr><td>BeiJing</td><td>U2032</td><td>2017-11-11 10:10:00</td></tr><tr><td>BeiJing</td><td>U1100</td><td>2017-11-11 10:11:00</td></tr><tr><td>ShangHai</td><td>U0011</td><td>2017-11-11 12:10:00</td></tr></tbody></table><h2 id="Source-定义"><a href="#Source-定义" class="headerlink" title="Source 定义"></a>Source 定义</h2><p>自定义Apache Flink Stream Source需要实现<code>StreamTableSource</code>, <code>StreamTableSource</code>中通过<code>StreamExecutionEnvironment</code> 的<code>addSource</code>方法获取<code>DataStream</code>, 所以我们需要自定义一个 <code>SourceFunction</code>, 并且要支持产生WaterMark，也就是要实现<code>DefinedRowtimeAttributes</code>接口。</p><h3 id="Source-Function定义"><a href="#Source-Function定义" class="headerlink" title="Source Function定义"></a>Source Function定义</h3><p>支持接收携带EventTime的数据集合，Either的数据结构，Right表示WaterMark和Left表示数据:</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">MySourceFunction</span>[<span class="type">T</span>](<span class="title">dataWithTimestampList</span>: <span class="type">Seq</span>[<span class="type">Either</span>[(<span class="type">Long</span>, <span class="type">T</span>), <span class="type">Long</span>]]) </span></span><br><span class="line"><span class="class">  extends <span class="type">SourceFunction</span>[<span class="type">T</span>] &#123;</span></span><br><span class="line"><span class="class">  override def run(<span class="title">ctx</span>: <span class="type">SourceContext</span>[<span class="type">T</span>]): <span class="type">Unit</span> = &#123;</span></span><br><span class="line"><span class="class">    dataWithTimestampList.foreach &#123;</span></span><br><span class="line"><span class="class">      case <span class="type">Left</span>(<span class="title">t</span>) =&gt; ctx.collectWithTimestamp(<span class="title">t</span>.<span class="title">_2</span>, <span class="title">t</span>.<span class="title">_1</span>)</span></span><br><span class="line"><span class="class">      case <span class="type">Right</span>(<span class="title">w</span>) =&gt; ctx.emitWatermark(<span class="title">new</span> <span class="type">Watermark(w)</span>)</span></span><br><span class="line"><span class="class">    &#125;</span></span><br><span class="line"><span class="class">  &#125;</span></span><br><span class="line"><span class="class">  override def cancel(): <span class="type">Unit</span> = ???</span></span><br><span class="line"><span class="class">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="定义-StreamTableSource"><a href="#定义-StreamTableSource" class="headerlink" title="定义 StreamTableSource"></a>定义 StreamTableSource</h3><p>我们自定义的Source要携带我们测试的数据，以及对应的WaterMark数据，具体如下:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTableSource</span> <span class="keyword">extends</span> <span class="title">StreamTableSource</span>[<span class="type">Row</span>] <span class="keyword">with</span> <span class="title">DefinedRowtimeAttributes</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> fieldNames = <span class="type">Array</span>(<span class="string">"accessTime"</span>, <span class="string">"region"</span>, <span class="string">"userId"</span>)</span><br><span class="line">  <span class="keyword">val</span> schema = <span class="keyword">new</span> <span class="type">TableSchema</span>(fieldNames, <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">SQL_TIMESTAMP</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">STRING</span>))</span><br><span class="line">  <span class="keyword">val</span> rowType = <span class="keyword">new</span> <span class="type">RowTypeInfo</span>(</span><br><span class="line">    <span class="type">Array</span>(<span class="type">Types</span>.<span class="type">LONG</span>, <span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">STRING</span>).asInstanceOf[<span class="type">Array</span>[<span class="type">TypeInformation</span>[_]]],</span><br><span class="line">    fieldNames)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 页面访问表数据 rows with timestamps and watermarks</span></span><br><span class="line">  <span class="keyword">val</span> data = <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Left</span>(<span class="number">1510365660000</span>L, <span class="type">Row</span>.of(<span class="keyword">new</span> <span class="type">JLong</span>(<span class="number">1510365660000</span>L), <span class="string">"ShangHai"</span>, <span class="string">"U0010"</span>)),</span><br><span class="line">    <span class="type">Right</span>(<span class="number">1510365660000</span>L),</span><br><span class="line">    <span class="type">Left</span>(<span class="number">1510365660000</span>L, <span class="type">Row</span>.of(<span class="keyword">new</span> <span class="type">JLong</span>(<span class="number">1510365660000</span>L), <span class="string">"BeiJing"</span>, <span class="string">"U1001"</span>)),</span><br><span class="line">    <span class="type">Right</span>(<span class="number">1510365660000</span>L),</span><br><span class="line">    <span class="type">Left</span>(<span class="number">1510366200000</span>L, <span class="type">Row</span>.of(<span class="keyword">new</span> <span class="type">JLong</span>(<span class="number">1510366200000</span>L), <span class="string">"BeiJing"</span>, <span class="string">"U2032"</span>)),</span><br><span class="line">    <span class="type">Right</span>(<span class="number">1510366200000</span>L),</span><br><span class="line">    <span class="type">Left</span>(<span class="number">1510366260000</span>L, <span class="type">Row</span>.of(<span class="keyword">new</span> <span class="type">JLong</span>(<span class="number">1510366260000</span>L), <span class="string">"BeiJing"</span>, <span class="string">"U1100"</span>)),</span><br><span class="line">    <span class="type">Right</span>(<span class="number">1510366260000</span>L),</span><br><span class="line">    <span class="type">Left</span>(<span class="number">1510373400000</span>L, <span class="type">Row</span>.of(<span class="keyword">new</span> <span class="type">JLong</span>(<span class="number">1510373400000</span>L), <span class="string">"ShangHai"</span>, <span class="string">"U0011"</span>)),</span><br><span class="line">    <span class="type">Right</span>(<span class="number">1510373400000</span>L)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getRowtimeAttributeDescriptors</span></span>: util.<span class="type">List</span>[<span class="type">RowtimeAttributeDescriptor</span>] = &#123;</span><br><span class="line">    <span class="type">Collections</span>.singletonList(<span class="keyword">new</span> <span class="type">RowtimeAttributeDescriptor</span>(</span><br><span class="line">      <span class="string">"accessTime"</span>,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ExistingField</span>(<span class="string">"accessTime"</span>),</span><br><span class="line">      <span class="type">PreserveWatermarks</span>.<span class="type">INSTANCE</span>))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getDataStream</span></span>(execEnv: <span class="type">StreamExecutionEnvironment</span>): <span class="type">DataStream</span>[<span class="type">Row</span>] = &#123;</span><br><span class="line">    execEnv.addSource(<span class="keyword">new</span> <span class="type">MySourceFunction</span>[<span class="type">Row</span>](data)).setParallelism(<span class="number">1</span>).returns(rowType)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getReturnType</span></span>: <span class="type">TypeInformation</span>[<span class="type">Row</span>] = rowType</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getTableSchema</span></span>: <span class="type">TableSchema</span> = schema</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Sink-定义"><a href="#Sink-定义" class="headerlink" title="Sink 定义"></a>Sink 定义</h2><p>我们简单的将计算结果写入到Apache Flink内置支持的CSVSink中，定义Sink如下：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def getCsvTableSink: TableSink[Row] = &#123;</span><br><span class="line">    val tempFile = <span class="built_in">File</span>.createTempFile(<span class="string">"csv_sink_"</span>, <span class="string">"tem"</span>)</span><br><span class="line">    <span class="comment">// 打印sink的文件路径，方便我们查看运行结果</span></span><br><span class="line">    <span class="built_in">println</span>(<span class="string">"Sink path : "</span> + tempFile)</span><br><span class="line">    <span class="built_in">if</span> (tempFile.<span class="built_in">exists</span>()) &#123;</span><br><span class="line">      tempFile.<span class="keyword">delete</span>()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">new</span> CsvTableSink(tempFile.getAbsolutePath).configure(</span><br><span class="line">      Array[<span class="keyword">String</span>](<span class="string">"region"</span>, <span class="string">"winStart"</span>, <span class="string">"winEnd"</span>, <span class="string">"pv"</span>),</span><br><span class="line">      Array[TypeInformation[_]](Types.STRING, Types.SQL_TIMESTAMP, Types.SQL_TIMESTAMP, Types.LONG))</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="构建主程序"><a href="#构建主程序" class="headerlink" title="构建主程序"></a>构建主程序</h2><p>主程序包括执行环境的定义，Source/Sink的注册以及统计查SQL的执行，具体如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// Streaming 环境</span></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    <span class="keyword">val</span> tEnv = <span class="type">TableEnvironment</span>.getTableEnvironment(env)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置EventTime</span></span><br><span class="line">    env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//方便我们查出输出数据</span></span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sourceTableName = <span class="string">"mySource"</span></span><br><span class="line">    <span class="comment">// 创建自定义source数据结构</span></span><br><span class="line">    <span class="keyword">val</span> tableSource = <span class="keyword">new</span> <span class="type">MyTableSource</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sinkTableName = <span class="string">"csvSink"</span></span><br><span class="line">    <span class="comment">// 创建CSV sink 数据结构</span></span><br><span class="line">    <span class="keyword">val</span> tableSink = getCsvTableSink</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注册source</span></span><br><span class="line">    tEnv.registerTableSource(sourceTableName, tableSource)</span><br><span class="line">    <span class="comment">// 注册sink</span></span><br><span class="line">    tEnv.registerTableSink(sinkTableName, tableSink)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sql =</span><br><span class="line">      <span class="string">"SELECT  "</span> +</span><br><span class="line">      <span class="string">"  region, "</span> +</span><br><span class="line">      <span class="string">"  TUMBLE_START(accessTime, INTERVAL '2' MINUTE) AS winStart,"</span> +</span><br><span class="line">      <span class="string">"  TUMBLE_END(accessTime, INTERVAL '2' MINUTE) AS winEnd, COUNT(region) AS pv "</span> +</span><br><span class="line">      <span class="string">" FROM mySource "</span> +</span><br><span class="line">      <span class="string">" GROUP BY TUMBLE(accessTime, INTERVAL '2' MINUTE), region"</span></span><br><span class="line"></span><br><span class="line">    tEnv.sqlQuery(sql).insertInto(sinkTableName);</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="执行并查看运行结果"><a href="#执行并查看运行结果" class="headerlink" title="执行并查看运行结果"></a>执行并查看运行结果</h2><p>执行主程序后我们会在控制台得到Sink的文件路径，如下：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sink <span class="string">path :</span> <span class="regexp">/var/</span>folders<span class="regexp">/88/</span><span class="number">8</span>n406qmx2z73qvrzc_rbtv_r0000gn<span class="regexp">/T/</span>csv_sink_8025014910735142911tem</span><br></pre></td></tr></table></figure><p>Cat 方式查看计算结果，如下：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jinchengsunjcdeMacBook-Pro:FlinkTableApiDemo jincheng.sunjc$ cat /var/folders/<span class="number">88</span>/<span class="number">8</span>n406qmx2z73qvrzc_rbtv_r0000gn/T/csv_sink_8025014910735142911tem</span><br><span class="line">ShangHai,<span class="number">2017-11-11</span> <span class="number">02:00:00.0</span>,<span class="number">2017-11-11</span> <span class="number">02:02:00.0</span>,<span class="number">1</span></span><br><span class="line">BeiJing,<span class="number">2017-11-11</span> <span class="number">02:00:00.0</span>,<span class="number">2017-11-11</span> <span class="number">02:02:00.0</span>,<span class="number">1</span></span><br><span class="line">BeiJing,<span class="number">2017-11-11</span> <span class="number">02:10:00.0</span>,<span class="number">2017-11-11</span> <span class="number">02:12:00.0</span>,<span class="number">2</span></span><br><span class="line">ShangHai,<span class="number">2017-11-11</span> <span class="number">04:10:00.0</span>,<span class="number">2017-11-11</span> <span class="number">04:12:00.0</span>,<span class="number">1</span></span><br></pre></td></tr></table></figure><p>表格化如上结果：</p><table><thead><tr><th>region</th><th>winStart</th><th>winEnd</th><th>pv</th></tr></thead><tbody><tr><td>BeiJing</td><td>2017-11-11 02:00:00.0</td><td>2017-11-11 02:02:00.0</td><td>1</td></tr><tr><td>BeiJing</td><td>2017-11-11 02:10:00.0</td><td>2017-11-11 02:12:00.0</td><td>2</td></tr><tr><td>ShangHai</td><td>2017-11-11 02:00:00.0</td><td>2017-11-11 02:02:00.0</td><td>1</td></tr><tr><td>ShangHai</td><td>2017-11-11 04:10:00.0</td><td>2017-11-11 04:12:00.0</td><td>1</td></tr></tbody></table><p>上面这个端到端的完整示例也可以应用到本篇前面介绍的其他算子示例中，只是大家根据Source和Sink的Schema不同来进行相应的构建即可！</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本篇概要的介绍了Apache Flink SQL 大部分核心功能，并附带了具体的测试数据和测试程序，最后以一个End-to-End的示例展示了如何编写Apache Flink SQL的Job收尾。</p>]]></content>
    
    <summary type="html">
    
      本篇概要的介绍了Apache Flink SQL 大部分核心功能，并附带了具体的测试数据和测试程序，最后以一个End-to-End的示例展示了如何编写Apache Flink SQL的Job。
    
    </summary>
    
      <category term="实时计算框架" scheme="https://gjtmaster.github.io/categories/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
    
      <category term="Flink" scheme="https://gjtmaster.github.io/tags/Flink/"/>
    
      <category term="FlinkSQL" scheme="https://gjtmaster.github.io/tags/FlinkSQL/"/>
    
      <category term="实时计算" scheme="https://gjtmaster.github.io/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>利用ogg实现oracle到kafka的增量数据实时同步</title>
    <link href="https://gjtmaster.github.io/2018/09/13/%E5%88%A9%E7%94%A8ogg%E5%AE%9E%E7%8E%B0oracle%E5%88%B0kafka%E7%9A%84%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/"/>
    <id>https://gjtmaster.github.io/2018/09/13/利用ogg实现oracle到kafka的增量数据实时同步/</id>
    <published>2018-09-13T06:32:58.000Z</published>
    <updated>2019-08-18T05:45:34.748Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Oracle里存储的结构化数据导出到Hadoop体系做离线计算是一种常见数据处置手段。近期有场景需要做Oracle到Kafka的实时导入，这里以此案例进行介绍。</p><p>ogg即Oracle GoldenGate是Oracle的同步工具，本文讲如何配置ogg以实现Oracle数据库增量数据实时同步到kafka中，其中同步消息格式为json。</p><p>下面是我的源端和目标端的一些配置信息：</p><table><thead><tr><th align="center">-</th><th align="center">版本</th><th align="center">OGG版本</th><th align="center">ip</th><th align="center">主机名</th></tr></thead><tbody><tr><td align="center">源端</td><td align="center">OracleRelease 11.2.0.1.0</td><td align="center">Oracle GoldenGate 11.2.1.0.3 for Oracle on Linux x86-64</td><td align="center">192.168.23.167</td><td align="center">cdh01</td></tr><tr><td align="center">目标端</td><td align="center">kafka_2.11-0.11.0.1</td><td align="center">Oracle GoldenGate for Big Data 12.3.0.1.0 on Linux x86-64</td><td align="center">192.168.23.168</td><td align="center">cdh02</td></tr></tbody></table><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>注意：源端和目标端的文件不一样，目标端需要下载Oracle GoldenGate for Big Data,源端需要下载Oracle GoldenGate for Oracle具体下载方法见最后的附录截图。</p><p>目标端在<a href="http://www.oracle.com/technetwork/middleware/goldengate/downloads/index.html" target="_blank" rel="noopener">这里</a>查询下载，源端在<a href="https://edelivery.oracle.com/osdc/faces/SoftwareDelivery" target="_blank" rel="noopener">旧版本</a>查询下载。</p><h2 id="源端（Oracle）配置"><a href="#源端（Oracle）配置" class="headerlink" title="源端（Oracle）配置"></a>源端（Oracle）配置</h2><p>注意：源端是创建了oracle用户且安装了oracle数据库，oracle环境变量之前都配置好了</p><p>（后面只要涉及到源端均在oracle用户下操作）</p><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><p>先建立ogg目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /oracledata/data/ogg</span><br><span class="line">unzip Oracle GoldenGate_11.2.1.0.3.zip</span><br></pre></td></tr></table></figure><p>解压后得到一个tar包，再解压这个tar</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xf fbo_ggs_Linux_x64_ora11g_64bit.tar -C /oracledata/data/ogg</span><br></pre></td></tr></table></figure><h3 id="配置ogg环境变量"><a href="#配置ogg环境变量" class="headerlink" title="配置ogg环境变量"></a>配置ogg环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export OGG_HOME=/oracledata/data/ogg</span><br><span class="line">export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/usr/lib</span><br><span class="line">export PATH=$OGG_HOME:$PATH</span><br></pre></td></tr></table></figure><p>使之生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>测试一下ogg命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $OGG_HOME</span><br><span class="line">ggsci</span><br></pre></td></tr></table></figure><p>如果命令成功即可进行下一步，不成功请检查前面的步骤。</p><h3 id="oracle打开归档模式"><a href="#oracle打开归档模式" class="headerlink" title="oracle打开归档模式"></a>oracle打开归档模式</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 以DBA身份连接数据库</span></span><br><span class="line">sqlplus / as sysdba</span><br></pre></td></tr></table></figure><p>执行下面的命令查看当前是否为归档模式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> archive <span class="built_in">log</span> list</span></span><br></pre></td></tr></table></figure><p>若显示如下，则说明当前未开启归档模式</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Database <span class="built_in">log</span> <span class="built_in">mode</span>       No Archive <span class="built_in">Mode</span></span><br><span class="line">Automatic archival       Disabled</span><br><span class="line">Archive destination       USE_DB_RECOVERY_FILE_DEST</span><br><span class="line">Oldest online <span class="built_in">log</span> sequence     <span class="number">12</span></span><br><span class="line">Current <span class="built_in">log</span> sequence       <span class="number">14</span></span><br></pre></td></tr></table></figure><p>手动打开即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 立即关闭数据库</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> shutdown immediate</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动实例并加载数据库，但不打开</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> startup mount</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更改数据库为归档模式</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter database archivelog;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 打开数据库</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter database open;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启用自动归档</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter system archive <span class="built_in">log</span> start;</span></span><br></pre></td></tr></table></figure><p>再执行一下命令查看当前是否为归档模式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> archive <span class="built_in">log</span> list</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Database log mode       Archive Mode</span><br><span class="line">Automatic archival       Enabled</span><br><span class="line">Archive destination       USE_DB_RECOVERY_FILE_DEST</span><br><span class="line">Oldest online log sequence     12</span><br><span class="line">Next log sequence to archive   14</span><br><span class="line">Current log sequence       14</span><br></pre></td></tr></table></figure><p>可以看到为Enabled，则成功打开归档模式。</p><h3 id="Oracle打开日志相关"><a href="#Oracle打开日志相关" class="headerlink" title="Oracle打开日志相关"></a>Oracle打开日志相关</h3><p>OGG基于辅助日志等进行实时传输，故需要打开相关日志确保可获取事务内容，通过下面的命令查看该状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> select force_logging, supplemental_log_data_min from v<span class="variable">$database</span>;</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">FORCE_</span> <span class="string">SUPPLEMENTAL_LOG</span></span><br><span class="line"><span class="bullet">-</span><span class="bullet">-----</span> <span class="bullet">----------------</span></span><br><span class="line"><span class="literal">NO</span>     <span class="literal">NO</span></span><br></pre></td></tr></table></figure><p>若为NO，则需要通过命令修改</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter database force logging;</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter database add supplemental <span class="built_in">log</span> data;</span></span><br></pre></td></tr></table></figure><p>再查看一下为YES即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> select force_logging, supplemental_log_data_min from v<span class="variable">$database</span>;</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">FORCE_</span> <span class="string">SUPPLEMENTAL_LOG</span></span><br><span class="line"><span class="bullet">-</span><span class="bullet">-----</span> <span class="bullet">----------------</span></span><br><span class="line"><span class="literal">YES</span>    <span class="literal">YES</span></span><br></pre></td></tr></table></figure><p>上述操作只是开启了最小补充日志，如果要抽取全部字段需要开启全列补充日志,否则值为null的字段不会在抽取日志中显示！！！</p><p>补充日志开启命令参考：<a href="https://blog.csdn.net/aaron8219/article/details/16825963" target="_blank" rel="noopener">https://blog.csdn.net/aaron8219/article/details/16825963</a></p><p><strong>注：开启全列补充日志会导致磁盘快速增长，LGWR进程繁忙，不建议使用。大家可根据自己的情况使用。</strong></p><p>查看数据库是否开启了全列补充日志</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; select supplemental<span class="emphasis">_log_</span>data<span class="emphasis">_all from v$database;  </span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">SUPPLE</span></span><br><span class="line"><span class="emphasis">------</span></span><br><span class="line"><span class="emphasis">NO</span></span><br></pre></td></tr></table></figure><p>若未开启可以通过以下命令开启。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; alter database add supplemental log data(all) columns;</span><br><span class="line"></span><br><span class="line">Database altered.</span><br><span class="line"></span><br><span class="line">SQL&gt; select supplemental<span class="emphasis">_log_</span>data<span class="emphasis">_all from v$database;</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">SUPPLE</span></span><br><span class="line"><span class="emphasis">------</span></span><br><span class="line"><span class="emphasis">YES</span></span><br></pre></td></tr></table></figure><h3 id="oracle创建复制用户"><a href="#oracle创建复制用户" class="headerlink" title="oracle创建复制用户"></a>oracle创建复制用户</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="regexp">/oracledata/</span>data<span class="regexp">/tablespace/</span>dbsrv2</span><br></pre></td></tr></table></figure><p>然后执行下面sql</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> create tablespace oggtbs datafile <span class="string">'/oracledata/data/tablespace/dbsrv2/oggtbs01.dbf'</span> size 1000M autoextend on;</span></span><br><span class="line">控制台显示的内容：Tablespace created.</span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash">  create user ogg identified by 123456 default tablespace oggtbs;</span></span><br><span class="line">控制台显示的内容：User created.</span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> grant dba to ogg;</span></span><br><span class="line">控制台显示的内容：Grant succeeded.</span><br></pre></td></tr></table></figure><h3 id="OGG初始化"><a href="#OGG初始化" class="headerlink" title="OGG初始化"></a>OGG初始化</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd $OGG_HOME</span><br><span class="line">ggsci</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建目录</span></span><br><span class="line">GGSCI (cdh01) 1&gt; create subdirs</span><br></pre></td></tr></table></figure><p>控制台显示的内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Creating subdirectories under current directory /oracledata/data/ogg</span><br><span class="line"></span><br><span class="line">Parameter files                /oracledata/data/ogg/dirprm: created</span><br><span class="line">Report files                   /oracledata/data/ogg/dirrpt: created</span><br><span class="line">Checkpoint files               /oracledata/data/ogg/dirchk: created</span><br><span class="line">Process status files           /oracledata/data/ogg/dirpcs: created</span><br><span class="line">SQL script files               /oracledata/data/ogg/dirsql: created</span><br><span class="line">Database definitions files     /oracledata/data/ogg/dirdef: created</span><br><span class="line">Extract data files             /oracledata/data/ogg/dirdat: created</span><br><span class="line">Temporary files                /oracledata/data/ogg/dirtmp: created</span><br><span class="line">Stdout files                   /oracledata/data/ogg/dirout: created</span><br></pre></td></tr></table></figure><h3 id="Oracle创建测试表"><a href="#Oracle创建测试表" class="headerlink" title="Oracle创建测试表"></a>Oracle创建测试表</h3><p>创建一个用户,在该用户下新建测试表，用户名、密码、表名均为 test_ogg。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sqlplus / as sysdba</span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> create user test_ogg identified by test_ogg default tablespace users;</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> grant dba to test_ogg;</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> conn test_ogg/test_ogg;</span></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> create table test_ogg(id int,name varchar(20),sex varchar(4),primary key(id));</span></span><br></pre></td></tr></table></figure><h2 id="目标端（kafka）配置"><a href="#目标端（kafka）配置" class="headerlink" title="目标端（kafka）配置"></a>目标端（kafka）配置</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -<span class="selector-tag">p</span> /data/apps/ogg</span><br><span class="line">unzip OGG_BigData_12.<span class="number">3.0</span>.<span class="number">1.0</span>_Release.zip</span><br><span class="line">tar xf ggs_Adapters_Linux_x64<span class="selector-class">.tar</span>  -C /data/apps/ogg</span><br></pre></td></tr></table></figure><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vim</span> /etc/<span class="keyword">profile</span></span><br></pre></td></tr></table></figure><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=<span class="regexp">/opt/java</span><span class="regexp">/jdk1.8.0_211</span></span><br><span class="line"><span class="regexp">export PATH=$JAVA_HOME/bin</span>:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/<span class="class"><span class="keyword">lib</span>/<span class="title">dt</span>.<span class="title">jar</span>:$<span class="title">JAVA_HOME</span>/<span class="title">lib</span>/<span class="title">tools</span>.<span class="title">jar</span></span></span><br><span class="line"></span><br><span class="line">export OGG_HOME=<span class="regexp">/data/apps</span><span class="regexp">/ogg</span></span><br><span class="line"><span class="regexp">export LD_LIBRARY_PATH=$JAVA_HOME/jre</span><span class="regexp">/lib/amd</span>64:$JAVA_HOME/jre/<span class="class"><span class="keyword">lib</span>/<span class="title">amd64</span>/<span class="title">server</span>:$<span class="title">JAVA_HOME</span>/<span class="title">jre</span>/<span class="title">lib</span>/<span class="title">amd64</span>/<span class="title">libjsig</span>.<span class="title">so</span>:$<span class="title">JAVA_HOME</span>/<span class="title">jre</span>/<span class="title">lib</span>/<span class="title">amd64</span>/<span class="title">server</span>/<span class="title">libjvm</span>.<span class="title">so</span>:$<span class="title">OGG_HOME</span>/<span class="title">lib</span></span></span><br><span class="line">export PATH=$<span class="symbol">OGG_HOME:</span>$PATH</span><br></pre></td></tr></table></figure><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> <span class="regexp">/etc/</span>profile</span><br></pre></td></tr></table></figure><p>同样测试一下ogg命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $OGG_HOME</span><br><span class="line">ggsci</span><br></pre></td></tr></table></figure><h3 id="初始化目录"><a href="#初始化目录" class="headerlink" title="初始化目录"></a>初始化目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create subdirs</span><br></pre></td></tr></table></figure><h2 id="OGG源端配置"><a href="#OGG源端配置" class="headerlink" title="OGG源端配置"></a>OGG源端配置</h2><p>Oracle实时传输到Hadoop集群（HDFS，<a href="http://lib.csdn.net/base/hive" target="_blank" rel="noopener">Hive</a>，Kafka等）的基本原理如图：<br><img src="https://mc.qcloudimg.com/static/img/dd548277beb41f51d0e5914dccda9134/image.png" alt="img"><br>根据如上原理，配置大概分为如下步骤：源端目标端配置ogg管理器（mgr）；源端配置extract进程进行Oracle日志抓取；源端配置pump进程传输抓取内容到目标端；目标端配置replicate进程复制日志到Kafka集群。</p><h3 id="配置OGG的全局变量"><a href="#配置OGG的全局变量" class="headerlink" title="配置OGG的全局变量"></a>配置OGG的全局变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $OGG_HOME</span><br><span class="line">ggsci</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh01) 1&gt; dblogin userid ogg password 123456</span><br><span class="line">控制台显示的内容：Successfully logged into database.</span><br><span class="line"></span><br><span class="line">GGSCI (cdh01) 2&gt; edit param ./globals</span><br></pre></td></tr></table></figure><p>然后和用vim编辑一样添加</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">oggschema ogg</span></span><br></pre></td></tr></table></figure><h3 id="配置管理器mgr"><a href="#配置管理器mgr" class="headerlink" title="配置管理器mgr"></a>配置管理器mgr</h3><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (<span class="name">cdh01</span>) <span class="number">3</span>&gt; edit param mgr</span><br></pre></td></tr></table></figure><p>然后和用vim编辑一样添加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PORT 7809</span><br><span class="line">DYNAMICPORTLIST 7810-7909</span><br><span class="line">AUTORESTART EXTRACT *,RETRIES 5,WAITMINUTES 3</span><br><span class="line">PURGEOLDEXTRACTS ./dirdat/*,usecheckpoints, minkeepdays 3</span><br></pre></td></tr></table></figure><p>说明：PORT即mgr的默认监听端口；</p><p>DYNAMICPORTLIST动态端口列表，当指定的mgr端口不可用时，会在这个端口列表中选择一个，最大指定范围为256个；</p><p>AUTORESTART重启参数设置表示重启所有EXTRACT进程，最多5次，每次间隔3分钟；</p><p>PURGEOLDEXTRACTS即TRAIL文件的定期清理</p><h3 id="添加复制表"><a href="#添加复制表" class="headerlink" title="添加复制表"></a>添加复制表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh01) 4&gt; add trandata test_ogg.test_ogg</span><br><span class="line">控制台显示的内容：Logging of supplemental redo data enabled for table TEST_OGG.TEST_OGG.</span><br><span class="line"></span><br><span class="line">GGSCI (cdh01) 5&gt; info trandata test_ogg.test_ogg</span><br><span class="line">控制台显示的内容：Logging of supplemental redo log data is enabled for table TEST_OGG.TEST_OGG.</span><br><span class="line">控制台显示的内容：Columns supplementally logged for table TEST_OGG.TEST_OGG: ID</span><br></pre></td></tr></table></figure><h3 id="配置extract进程"><a href="#配置extract进程" class="headerlink" title="配置extract进程"></a>配置extract进程</h3><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (<span class="name">cdh01</span>) <span class="number">6</span>&gt; edit param extkafka</span><br></pre></td></tr></table></figure><p>然后和用vim编辑一样添加</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">extract</span> extkafka</span><br><span class="line"><span class="attribute">dynamicresolution</span></span><br><span class="line"><span class="attribute"><span class="nomarkup">SETENV</span></span> (ORACLE_SID = <span class="string">"dbsrv2"</span>)</span><br><span class="line"><span class="attribute"><span class="nomarkup">SETENV</span></span> (NLS_LANG = <span class="string">"american_america.AL32UTF8"</span>)</span><br><span class="line"><span class="attribute">GETUPDATEBEFORES</span></span><br><span class="line"><span class="attribute">NOCOMPRESSDELETES</span></span><br><span class="line"><span class="attribute">NOCOMPRESSUPDATES</span></span><br><span class="line"><span class="attribute">userid</span> ogg,password 123456</span><br><span class="line"><span class="attribute">exttrail</span> /oracledata/data/ogg/dirdat/to</span><br><span class="line"><span class="attribute">table</span> test_ogg.test_ogg;</span><br></pre></td></tr></table></figure><p>说明：</p><p>第一行指定extract进程名称；</p><p>dynamicresolution动态解析；</p><p>SETENV设置环境变量，这里分别设置了Oracle数据库以及字符集；</p><p>userid ogg,password 123456即OGG连接Oracle数据库的帐号密码，这里使用2.5中特意创建的复制帐号；exttrail定义trail文件的保存位置以及文件名，注意这里文件名只能是2个字母，其余部分OGG会补齐；</p><p>table即复制表的表名，支持*通配，必须以;结尾</p><p>添加extract进程：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh01) <span class="number">7</span>&gt; <span class="keyword">add </span><span class="keyword">extract </span><span class="keyword">extkafka,tranlog,begin </span>now</span><br><span class="line">控制台显示的内容：<span class="keyword">EXTRACT </span><span class="keyword">added.</span></span><br></pre></td></tr></table></figure><p>(注：若报错</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ERROR: </span>Could not create checkpoint file /opt/ogg/dirchk/EXTKAFKA.cpe (error 2, No such file or directory).</span><br></pre></td></tr></table></figure><p>执行下面的命令再重新添加即可。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create <span class="keyword">subdirs</span></span><br></pre></td></tr></table></figure><p>)</p><p>添加trail文件的定义与extract进程绑定：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh01) 8&gt; <span class="builtin-name">add</span> exttrail /oracledata/data/ogg/dirdat/<span class="keyword">to</span>,extract extkafka</span><br><span class="line">控制台显示的内容：EXTTRAIL added.</span><br></pre></td></tr></table></figure><h3 id="配置pump进程"><a href="#配置pump进程" class="headerlink" title="配置pump进程"></a>配置pump进程</h3><p>pump进程本质上来说也是一个extract，只不过他的作用仅仅是把trail文件传递到目标端，配置过程和extract进程类似，只是逻辑上称之为pump进程</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (<span class="name">cdh01</span>) <span class="number">9</span>&gt; edit param pukafka</span><br></pre></td></tr></table></figure><p>然后和用vim编辑一样添加</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">extract pukafka</span><br><span class="line">passthru</span><br><span class="line">dynamicresolution</span><br><span class="line">userid ogg,password <span class="number">123456</span></span><br><span class="line">rmthost <span class="number">192.168</span><span class="number">.23</span><span class="number">.168</span> mgrport <span class="number">7809</span></span><br><span class="line">rmttrail /data/apps/ogg/dirdat/to</span><br><span class="line">table test_ogg.test_ogg;</span><br></pre></td></tr></table></figure><p>说明：</p><p>第一行指定extract进程名称；</p><p>passthru即禁止OGG与Oracle交互，我们这里使用pump逻辑传输，故禁止即可；</p><p>dynamicresolution动态解析；</p><p>userid ogg,password ogg即OGG连接Oracle数据库的帐号密码</p><p>rmthost和mgrhost即目标端(kafka)OGG的mgr服务的地址以及监听端口；</p><p>rmttrail即目标端trail文件存储位置以及名称。<strong>(注意，这里很容易犯错！！！注意是目标端的路径！！！)</strong></p><p>分别将本地trail文件和目标端的trail文件绑定到extract进程：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh01) 10&gt; <span class="builtin-name">add</span> extract pukafka,exttrailsource /oracledata/data/ogg/dirdat/<span class="keyword">to</span></span><br><span class="line">控制台显示的内容：EXTRACT added.</span><br><span class="line">GGSCI (cdh01) 11&gt; <span class="builtin-name">add</span> rmttrail /data/apps/ogg/dirdat/<span class="keyword">to</span>,extract pukafka</span><br><span class="line">控制台显示的内容：RMTTRAIL added.</span><br></pre></td></tr></table></figure><h3 id="配置defgen文件"><a href="#配置defgen文件" class="headerlink" title="配置defgen文件"></a>配置defgen文件</h3><p>Oracle与MySQL，Hadoop集群（HDFS，Hive，kafka等）等之间数据传输可以定义为异构数据类型的传输，故需要定义表之间的关系映射，在OGG命令行执行：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (<span class="name">cdh01</span>) <span class="number">12</span>&gt; edit param test_ogg</span><br></pre></td></tr></table></figure><p>然后和用vim编辑一样添加</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">defsfile <span class="meta-keyword">/oracledata/</span>data<span class="meta-keyword">/ogg/</span>dirdef/test_ogg.test_ogg</span><br><span class="line">userid ogg,password <span class="number">123456</span></span><br><span class="line">table test_ogg.test_ogg;</span><br></pre></td></tr></table></figure><p>退出GGSCI</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (<span class="name">cdh01</span>) <span class="number">13</span>&gt; quit</span><br></pre></td></tr></table></figure><p>进行OGG主目录下执行以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $OGG_HOME</span><br><span class="line">./defgen paramfile dirprm/test_ogg.prm</span><br></pre></td></tr></table></figure><p>输出以下内容则执行成功。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">***********************************************************************</span><br><span class="line">        Oracle GoldenGate Table Definition Generator for Oracle</span><br><span class="line"> Version 11.2.1.0.3 14400833 OGGCORE_11.2.1.0.3_PLATFORMS_120823.1258</span><br><span class="line">   Linux, x64, 64bit (optimized), Oracle 11g on Aug 23 2012 16:58:29</span><br><span class="line"> </span><br><span class="line">Copyright (C) 1995, 2012, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                    Starting at 2018-05-23 05:03:04</span><br><span class="line">***********************************************************************</span><br><span class="line"></span><br><span class="line">Operating System Version:</span><br><span class="line">Linux</span><br><span class="line">Version #1 SMP Wed Apr 12 15:04:24 UTC 2017, Release 3.10.0-514.16.1.el7.x86_64</span><br><span class="line">Node: ambari.master.com</span><br><span class="line">Machine: x86_64</span><br><span class="line">                         soft limit   hard limit</span><br><span class="line">Address Space Size   :    unlimited    unlimited</span><br><span class="line">Heap Size            :    unlimited    unlimited</span><br><span class="line">File Size            :    unlimited    unlimited</span><br><span class="line">CPU Time             :    unlimited    unlimited</span><br><span class="line"></span><br><span class="line">Process id: 13126</span><br><span class="line"></span><br><span class="line">***********************************************************************</span><br><span class="line">**            Running with the following parameters                  **</span><br><span class="line">***********************************************************************</span><br><span class="line">defsfile /opt/ogg/dirdef/test_ogg.test_ogg</span><br><span class="line">userid ogg,password ***</span><br><span class="line">table test_ogg.test_ogg;</span><br><span class="line">Retrieving definition for TEST_OGG.TEST_OGG</span><br><span class="line"></span><br><span class="line">Definitions generated for 1 table in /oracledata/data/ogg/dirdef/test_ogg.test_ogg</span><br></pre></td></tr></table></figure><p>将生成的/oracledata/data/ogg/dirdef/test_ogg.test_ogg发送的目标端ogg目录下的dirdef里：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r /oracledata/data/ogg/dirdef/test_ogg.test_ogg root@cdh02:/data/apps/ogg/dirdef/</span><br></pre></td></tr></table></figure><h2 id="OGG目标端配置"><a href="#OGG目标端配置" class="headerlink" title="OGG目标端配置"></a>OGG目标端配置</h2><h3 id="开启kafka服务"><a href="#开启kafka服务" class="headerlink" title="开启kafka服务"></a>开启kafka服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开启Zookeeper</span></span><br><span class="line">/data/apps/apache-zookeeper-3.5.5-bin/bin/zkServer.sh start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开启Kafka</span></span><br><span class="line">/data/apps/kafka_2.11-0.11.0.1/bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure><h3 id="配置管理器mgr-1"><a href="#配置管理器mgr-1" class="headerlink" title="配置管理器mgr"></a>配置管理器mgr</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh02) 1&gt;  edit param mgr</span><br><span class="line">PORT 7809</span><br><span class="line">DYNAMICPORTLIST 7810-7909</span><br><span class="line">AUTORESTART EXTRACT *,RETRIES 5,WAITMINUTES 3</span><br><span class="line">PURGEOLDEXTRACTS ./dirdat/*,usecheckpoints, minkeepdays 3</span><br></pre></td></tr></table></figure><h3 id="配置checkpoint"><a href="#配置checkpoint" class="headerlink" title="配置checkpoint"></a>配置checkpoint</h3><p>checkpoint即复制可追溯的一个偏移量记录，在全局配置里添加checkpoint表即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh02) 2&gt; edit param ./GLOBALS</span><br><span class="line">CHECKPOINTTABLE test_ogg.checkpoint</span><br></pre></td></tr></table></figure><h3 id="配置replicate进程"><a href="#配置replicate进程" class="headerlink" title="配置replicate进程"></a>配置replicate进程</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh02) 3&gt; edit param rekafka</span><br><span class="line">REPLICAT rekafka</span><br><span class="line">sourcedefs /data/apps/ogg/dirdef/test_ogg.test_ogg</span><br><span class="line">TARGETDB LIBFILE libggjava.so SET property=dirprm/kafka.props</span><br><span class="line">REPORTCOUNT EVERY 1 MINUTES, RATE </span><br><span class="line">GROUPTRANSOPS 10000</span><br><span class="line">MAP test_ogg.test_ogg, TARGET test_ogg.test_ogg;</span><br></pre></td></tr></table></figure><p>说明：</p><p>REPLICATE rekafka定义rep进程名称；</p><p>sourcedefs即在4.6中在源服务器上做的表映射文件；</p><p>TARGETDB LIBFILE即定义kafka一些适配性的库文件以及配置文件，配置文件位于OGG主目录下的dirprm/kafka.props；</p><p>REPORTCOUNT即复制任务的报告生成频率；</p><p>GROUPTRANSOPS为以事务传输时，事务合并的单位，减少IO操作；</p><p>MAP即源端与目标端的映射关系</p><h3 id="配置kafka-props"><a href="#配置kafka-props" class="headerlink" title="配置kafka.props"></a>配置kafka.props</h3><p><strong>本环节配置时把注释都去掉，ogg不识别注释，如果不去掉会报错！！！</strong></p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd <span class="meta-keyword">/data/</span>apps<span class="meta-keyword">/ogg/</span>dirprm/</span><br><span class="line">vim kafka.props</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> handler类型</span></span><br><span class="line">gg.handlerlist=kafkahandler</span><br><span class="line">gg.handler.kafkahandler.type=kafka</span><br><span class="line"><span class="meta">#</span><span class="bash"> Kafka生产者配置文件</span></span><br><span class="line">gg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka的topic名称，无需手动创建</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> gg.handler.kafkahandler.topicMappingTemplate=test_ogg（新版topicName属性的设置方式）</span></span><br><span class="line">gg.handler.kafkahandler.topicName=test_ogg</span><br><span class="line"><span class="meta">#</span><span class="bash"> 传输文件的格式，支持json，xml等</span></span><br><span class="line">gg.handler.kafkahandler.format=json</span><br><span class="line">gg.handler.kafkahandler.format.insertOpKey = I  </span><br><span class="line">gg.handler.kafkahandler.format.updateOpKey = U  </span><br><span class="line">gg.handler.kafkahandler.format.deleteOpKey = D</span><br><span class="line">gg.handler.kafkahandler.format.truncateOpKey=T</span><br><span class="line">gg.handler.kafkahandler.format.includePrimaryKeys=true</span><br><span class="line"><span class="meta">#</span><span class="bash"> OGG <span class="keyword">for</span> Big Data中传输模式，即op为一次SQL传输一次，tx为一次事务传输一次</span></span><br><span class="line">gg.handler.kafkahandler.mode=op</span><br><span class="line"><span class="meta">#</span><span class="bash"> 类路径</span></span><br><span class="line">gg.classpath=dirprm/:/data/apps/kafka_2.11-0.11.0.1/libs/*:/data/apps/ogg/:/data/apps/ogg/lib/*</span><br></pre></td></tr></table></figure><p>紧接着创建Kafka生产者配置文件：</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim custom_kafk<span class="built_in">a_producer</span>.properties</span><br></pre></td></tr></table></figure><p>添加以下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kafkabroker的地址</span></span><br><span class="line">bootstrap.servers=cdh01:9092,cdh02:9092,cdh03:9092</span><br><span class="line">acks=1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 压缩类型</span></span><br><span class="line">compression.type=gzip</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重连延时</span></span><br><span class="line">reconnect.backoff.ms=1000</span><br><span class="line">value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer</span><br><span class="line">key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer</span><br><span class="line">batch.size=102400</span><br><span class="line">linger.ms=10000</span><br></pre></td></tr></table></figure><p><strong>配置时把注释都去掉，ogg不识别注释，如果不去掉会报错！！！</strong></p><h3 id="添加trail文件到replicate进程"><a href="#添加trail文件到replicate进程" class="headerlink" title="添加trail文件到replicate进程"></a>添加trail文件到replicate进程</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (cdh02) 1&gt; add replicat rekafka exttrail /data/apps/ogg/dirdat/to,checkpointtable test_ogg.checkpoint</span><br><span class="line">控制台显示的内容：REPLICAT added.</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="启动所有进程"><a href="#启动所有进程" class="headerlink" title="启动所有进程"></a>启动所有进程</h3><p>在源端和目标端的OGG命令行下使用start [进程名]的形式启动所有进程。<br>启动顺序按照源mgr——目标mgr——源extract——源pump——目标replicate来完成。<br>全部需要在ogg目录下执行ggsci目录进入ogg命令行。<br>源端依次是</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">start</span> mgr</span><br><span class="line"><span class="literal">start</span> extkafka</span><br><span class="line"><span class="literal">start</span> pukafka</span><br></pre></td></tr></table></figure><p>目标端</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">start</span> mgr</span><br><span class="line"><span class="literal">start</span> rekafka</span><br></pre></td></tr></table></figure><p>可以通过info all 或者info [进程名] 查看状态，所有的进程都为RUNNING才算成功<br>源端</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (ambari.master.com) 5&gt; <span class="builtin-name">info</span> all</span><br><span class="line"></span><br><span class="line">Program     Status     <span class="built_in"> Group </span>      Lag at Chkpt  Time Since Chkpt</span><br><span class="line"></span><br><span class="line">MANAGER     RUNNING                                           </span><br><span class="line">EXTRACT     RUNNING     EXTKAFKA    04:50:21      00:00:03    </span><br><span class="line">EXTRACT     RUNNING     PUKAFKA     00:00:00      00:00:03</span><br></pre></td></tr></table></figure><p>目标端</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (ambari.slave1.com) 3&gt; <span class="builtin-name">info</span> all</span><br><span class="line"></span><br><span class="line">Program     Status     <span class="built_in"> Group </span>      Lag at Chkpt  Time Since Chkpt</span><br><span class="line"></span><br><span class="line">MANAGER     RUNNING                                           </span><br><span class="line">REPLICAT    RUNNING     REKAFKA     00:00:00      00:00:01</span><br></pre></td></tr></table></figure><h3 id="异常解决"><a href="#异常解决" class="headerlink" title="异常解决"></a>异常解决</h3><p>如果有不是RUNNING可通过查看日志的方法检查解决问题，具体通过下面两种方法</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">vim</span> ggser.<span class="built_in">log</span></span><br></pre></td></tr></table></figure><p>或者ogg命令行,以rekafka进程为例</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GGSCI (<span class="name">cdh02</span>) <span class="number">2</span>&gt; view report rekafka</span><br></pre></td></tr></table></figure><h3 id="测试同步更新效果"><a href="#测试同步更新效果" class="headerlink" title="测试同步更新效果"></a>测试同步更新效果</h3><p>现在源端执行sql语句</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conn test_ogg/test_ogg</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> test_ogg <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">'test'</span>,<span class="literal">null</span>);</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"><span class="keyword">update</span> test_ogg <span class="keyword">set</span> <span class="keyword">name</span>=<span class="string">'zhangsan'</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">3</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"><span class="keyword">delete</span> test_ogg <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">3</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><p>查看源端trail文件状态</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls -l <span class="meta-keyword">/oracledata/</span>data<span class="meta-keyword">/ogg/</span>dirdat/to*</span><br><span class="line">-rw-rw-rw- <span class="number">1</span> oracle oinstall <span class="number">1464</span> May <span class="number">23</span> <span class="number">10</span>:<span class="number">31</span> <span class="meta-keyword">/opt/</span>ogg<span class="meta-keyword">/dirdat/</span>to000000</span><br></pre></td></tr></table></figure><p>查看目标端trail文件状态</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls -l <span class="meta-keyword">/data/</span>apps<span class="meta-keyword">/ogg/</span>dirdat/to*</span><br><span class="line">-rw-r----- <span class="number">1</span> root root <span class="number">1504</span> May <span class="number">23</span> <span class="number">10</span>:<span class="number">31</span> <span class="meta-keyword">/opt/</span>ogg<span class="meta-keyword">/dirdat/</span>to000000</span><br></pre></td></tr></table></figure><p>查看kafka是否自动建立对应的主题</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.<span class="keyword">sh</span> --<span class="keyword">list</span> --zookeeper localhos<span class="variable">t:2181</span></span><br></pre></td></tr></table></figure><p>在列表中显示有test_ogg则表示没问题<br>通过消费者看是否有同步消息</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-<span class="built_in">console</span>-consumer.sh --bootstrap-server <span class="number">192.168</span><span class="number">.44</span><span class="number">.129</span>:<span class="number">9092</span> --topic test_ogg --<span class="keyword">from</span>-beginning</span><br><span class="line">&#123;<span class="string">"table"</span>:<span class="string">"TEST_OGG.TEST_OGG"</span>,<span class="string">"op_type"</span>:<span class="string">"I"</span>,<span class="string">"op_ts"</span>:<span class="string">"2019-08-17 22:04:39.001362"</span>,<span class="string">"current_ts"</span>:<span class="string">"2019-08-17T22:04:44.610000"</span>,<span class="string">"pos"</span>:<span class="string">"00000000010000001246"</span>,<span class="string">"primary_keys"</span>:[<span class="string">"ID"</span>],<span class="string">"after"</span>:&#123;<span class="string">"ID"</span>:<span class="number">3</span>,<span class="string">"NAME"</span>:<span class="string">"test"</span>,<span class="string">"SEX"</span>:<span class="literal">null</span>&#125;&#125;</span><br><span class="line">&#123;<span class="string">"table"</span>:<span class="string">"TEST_OGG.TEST_OGG"</span>,<span class="string">"op_type"</span>:<span class="string">"U"</span>,<span class="string">"op_ts"</span>:<span class="string">"2019-08-17 22:05:44.000411"</span>,<span class="string">"current_ts"</span>:<span class="string">"2019-08-17T22:05:50.764000"</span>,<span class="string">"pos"</span>:<span class="string">"00000000010000001541"</span>,<span class="string">"primary_keys"</span>:[<span class="string">"ID"</span>],<span class="string">"before"</span>:&#123;<span class="string">"ID"</span>:<span class="number">3</span>,<span class="string">"NAME"</span>:<span class="string">"test"</span>,<span class="string">"SEX"</span>:<span class="literal">null</span>&#125;,<span class="string">"after"</span>:&#123;<span class="string">"ID"</span>:<span class="number">3</span>,<span class="string">"NAME"</span>:<span class="string">"zhangsan"</span>,<span class="string">"SEX"</span>:<span class="literal">null</span>&#125;&#125;</span><br><span class="line">&#123;<span class="string">"table"</span>:<span class="string">"TEST_OGG.TEST_OGG"</span>,<span class="string">"op_type"</span>:<span class="string">"D"</span>,<span class="string">"op_ts"</span>:<span class="string">"2019-08-17 22:06:33.000312"</span>,<span class="string">"current_ts"</span>:<span class="string">"2019-08-17T22:06:39.845000"</span>,<span class="string">"pos"</span>:<span class="string">"00000000010000001670"</span>,<span class="string">"primary_keys"</span>:[<span class="string">"ID"</span>],<span class="string">"before"</span>:&#123;<span class="string">"ID"</span>:<span class="number">3</span>,<span class="string">"NAME"</span>:<span class="string">"zhangsan"</span>,<span class="string">"SEX"</span>:<span class="literal">null</span>&#125;&#125;</span><br></pre></td></tr></table></figure><p>before代表操作之前的数据，after代表操作后的数据，现在已经可以从kafka获取到同步的json数据了，后面可以用SparkStreaming和Storm等解析然后存到hadoop等大数据平台里</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果想通配整个库的话，只需要把上面的配置所有表名改为*，如test_ogg<span class="selector-class">.test_ogg</span> 改为 test_ogg.*,但是kafka的topic不能通配，所以需要把所有表的数据放在一个topic，后面再用程序解析表名即可。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">若后期因业务需要导致表结构发生改变，需要重新生成源端表结构的defgen定义文件，再把定义文件通过scp放到目标端。defgen文件的作用是，记录了源端的表结构，然后我们再把这个文件放到目标端，在目标端应用SQL时就能根据defgen文件与目标端表结构，来做一定的转换。</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.cnblogs.com/purpleraintear/p/6071038.html" target="_blank" rel="noopener">基于OGG的Oracle与Hadoop集群准实时同步介绍</a></p><p><a href="https://docs.oracle.com/goldengate/bd1221/gg-bd/GADBD/GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5.htm#GADBD449" target="_blank" rel="noopener">Fusion Middleware Integrating Oracle GoldenGate for Big Data</a></p>]]></content>
    
    <summary type="html">
    
      Oracle里存储的结构化数据导出到Hadoop体系做离线计算是一种常见数据处置手段。近期有场景需要做Oracle到Kafka的实时导入，这里以此案例进行介绍。
    
    </summary>
    
      <category term="数据的导入导出" scheme="https://gjtmaster.github.io/categories/%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"/>
    
    
      <category term="Oracle" scheme="https://gjtmaster.github.io/tags/Oracle/"/>
    
      <category term="Kafka" scheme="https://gjtmaster.github.io/tags/Kafka/"/>
    
      <category term="ogg" scheme="https://gjtmaster.github.io/tags/ogg/"/>
    
  </entry>
  
  <entry>
    <title>kafka生产者和消费者吞吐量测试</title>
    <link href="https://gjtmaster.github.io/2018/09/02/kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85%E5%90%9E%E5%90%90%E9%87%8F%E6%B5%8B%E8%AF%95/"/>
    <id>https://gjtmaster.github.io/2018/09/02/kafka生产者和消费者吞吐量测试/</id>
    <published>2018-09-02T07:11:47.000Z</published>
    <updated>2019-09-18T10:27:41.305Z</updated>
    
    <content type="html"><![CDATA[<h2 id="测试集群配置："><a href="#测试集群配置：" class="headerlink" title="测试集群配置："></a>测试集群配置：</h2><blockquote><p><strong>三台4核cpu/8G内存/50G硬盘的CentOS7机器</strong></p><p><strong>Kafka版本：Kafka_2.11-0.11.0.1</strong></p></blockquote><h2 id="kafka生产者吞吐量测试"><a href="#kafka生产者吞吐量测试" class="headerlink" title="kafka生产者吞吐量测试"></a>kafka生产者吞吐量测试</h2><p><strong>使用kafka-producer-perf-test测试脚本，总共测试50万条数据量</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic test --num-records 500000 --record-size 200 --throughput -1 --producer-props bootstrap.servers=kafka01:9092,kafka02:9092,kafka03:9092 acks=1</span><br></pre></td></tr></table></figure><p><strong>测试结果分析如下：</strong></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">500000</span> records sent ,<span class="number">180701.120347</span> records/sec (<span class="number">34.47</span> MB/sec),<span class="number">315.17</span> ms/avg latency ,<span class="number">982.00</span> ms max latency ,<span class="number">167</span>ms <span class="number">50</span>h ,<span class="number">902</span>ms <span class="number">95</span>th ,<span class="number">969</span> ms <span class="number">99</span>h, <span class="number">981</span>ms <span class="number">99.9</span>th</span><br></pre></td></tr></table></figure><blockquote><p>测试结果显示：</p><p>发送了500000条消息，kafka 的平均吞吐量是34.47 MB/sec ，即占用275Mb/s左右的带宽，平均每秒发送180701条消息。</p><p>平均延时为315 ms，最大延时为982 ms，</p><p>发送50%的消息需要167ms，发送95%的消息需要902ms，发送99%的消息需要969ms，发送99.9%的消息需要981ms。</p></blockquote><h2 id="kafka消费者吞吐量测试"><a href="#kafka消费者吞吐量测试" class="headerlink" title="kafka消费者吞吐量测试"></a>kafka消费者吞吐量测试</h2><p><strong>使用kafka-consumer-perf-test测试脚本，总共测试50万条数据量</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --broker-list kafka01:9092,kafka02:9092,kafka03:9092 --message-size 200 --messages 500000 --topic test</span><br></pre></td></tr></table></figure><p><strong>测试结果分析如下：</strong></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019<span class="selector-tag">-09-18</span> 17<span class="selector-pseudo">:56</span><span class="selector-pseudo">:41</span><span class="selector-pseudo">:388</span>, 2019<span class="selector-tag">-09-18</span> 17<span class="selector-pseudo">:56</span><span class="selector-pseudo">:43</span><span class="selector-pseudo">:906</span>, 95<span class="selector-class">.3674</span>, 37<span class="selector-class">.8743</span>, 500000, 198570<span class="selector-class">.2939</span></span><br></pre></td></tr></table></figure><blockquote><p>看测试结果显示：</p><p>消费了95.3674MB消息，吞吐量为37.8743MB/s,也即303Mb/s，</p><p>消费了500000条消息，吞吐量为198570条/s</p></blockquote>]]></content>
    
    <summary type="html">
    
      本文主要讲述kafka测试集群上生产者和消费者吞吐量测试的整个流程。
    
    </summary>
    
      <category term="消息中间件" scheme="https://gjtmaster.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="Kafka" scheme="https://gjtmaster.github.io/tags/Kafka/"/>
    
      <category term="消息中间件" scheme="https://gjtmaster.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>Kafka0.11版本+Zookeeper-3.4.10集群部署</title>
    <link href="https://gjtmaster.github.io/2018/09/01/Kafka0.11%E7%89%88%E6%9C%AC+Zookeeper-3.4.10%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>https://gjtmaster.github.io/2018/09/01/Kafka0.11版本+Zookeeper-3.4.10集群部署/</id>
    <published>2018-09-01T05:32:44.000Z</published>
    <updated>2019-09-01T05:03:10.556Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://img.shields.io/badge/Author-Joker-green" alt></p><p><img src="https://img.shields.io/badge/Email-gaojintao999%40163.com-blue" alt></p><h2 id="集群环境："><a href="#集群环境：" class="headerlink" title="集群环境："></a>集群环境：</h2><table><thead><tr><th align="center">IP</th><th align="center">hostname</th><th align="center">配置</th></tr></thead><tbody><tr><td align="center">192.168.23.167</td><td align="center">kafka01</td><td align="center">4核cpu/8G内存/50G硬盘</td></tr><tr><td align="center">192.168.23.168</td><td align="center">kafka02</td><td align="center">4核cpu/8G内存/50G硬盘</td></tr><tr><td align="center">192.168.23.169</td><td align="center">kafka03</td><td align="center">4核cpu/8G内存/50G硬盘</td></tr></tbody></table><p><strong>集群安装目录：/data/apps</strong></p><h2 id="部署流程"><a href="#部署流程" class="headerlink" title="部署流程"></a>部署流程</h2><h3 id="root用户配置主机映射"><a href="#root用户配置主机映射" class="headerlink" title="root用户配置主机映射"></a>root用户配置主机映射</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.23.167  kafka01</span><br><span class="line">192.168.23.168  kafka02</span><br><span class="line">192.168.23.169  kafka03</span><br></pre></td></tr></table></figure><h3 id="在root用户下新建kafka用户（kafka-admin）"><a href="#在root用户下新建kafka用户（kafka-admin）" class="headerlink" title="在root用户下新建kafka用户（kafka/admin）"></a>在root用户下新建kafka用户（kafka/admin）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">adduser kafka -g kafka</span><br><span class="line">passwd kafka</span><br></pre></td></tr></table></figure><h3 id="在root用户下将apps目录下的用户及用户组均更改为kafka"><a href="#在root用户下将apps目录下的用户及用户组均更改为kafka" class="headerlink" title="在root用户下将apps目录下的用户及用户组均更改为kafka"></a>在root用户下将apps目录下的用户及用户组均更改为kafka</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown -R kafka:kafka /data/apps/</span><br></pre></td></tr></table></figure><h3 id="切换到kafka用户（之后的操作均在kafka用户下）"><a href="#切换到kafka用户（之后的操作均在kafka用户下）" class="headerlink" title="切换到kafka用户（之后的操作均在kafka用户下）"></a>切换到kafka用户（之后的操作均在kafka用户下）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su kafka</span><br></pre></td></tr></table></figure><h3 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line">ssh-copy-id kafka@kafka01</span><br><span class="line">ssh-copy-id kafka@kafka02</span><br><span class="line">ssh-copy-id kafka@kafka03</span><br></pre></td></tr></table></figure><h3 id="将所有安装资源上传到kafka01节点的kafka用户的家目录下"><a href="#将所有安装资源上传到kafka01节点的kafka用户的家目录下" class="headerlink" title="将所有安装资源上传到kafka01节点的kafka用户的家目录下"></a>将所有安装资源上传到kafka01节点的kafka用户的家目录下</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> zookeeper-3.4.10.tar.gz (官网下载)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka_2.11-0.11.0.1.tar.gz (官网下载)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka-manager-1.3.3.22 (官网下载)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> influxdb-1.7.5.x86_64.rpm (官网下载)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> jmxtrans-270.rpm (官网下载)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> grafana-6.0.2-1.x86_64.rpm (官网下载)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> install-kafka.sh (文件内容见附录)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> install-zookeeper.sh (文件内容见附录)</span></span><br></pre></td></tr></table></figure><h3 id="在kafka01节点上执行zookeeper集群安装脚本"><a href="#在kafka01节点上执行zookeeper集群安装脚本" class="headerlink" title="在kafka01节点上执行zookeeper集群安装脚本"></a>在kafka01节点上执行zookeeper集群安装脚本</h3><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sh</span> ~/install-zookeeper.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure><h3 id="在kafka01节点上执行kafka集群安装脚本"><a href="#在kafka01节点上执行kafka集群安装脚本" class="headerlink" title="在kafka01节点上执行kafka集群安装脚本"></a>在kafka01节点上执行kafka集群安装脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh ~/install-kafka.sh</span><br></pre></td></tr></table></figure><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 内容如下：</span></span><br><span class="line">export ZOOKEEPER_HOME=/data/apps/zookeeper-3.4.10</span><br><span class="line">export KAFKA_HOME=/data/apps/kafka_0.11.0.1</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使环境变量生效</span></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><h3 id="在kafka01、02、03节点上执行命令启动zookeeper集群"><a href="#在kafka01、02、03节点上执行命令启动zookeeper集群" class="headerlink" title="在kafka01、02、03节点上执行命令启动zookeeper集群"></a>在kafka01、02、03节点上执行命令启动zookeeper集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><h3 id="在kafka01、02、03节点上执行命令启动kafka集群"><a href="#在kafka01、02、03节点上执行命令启动kafka集群" class="headerlink" title="在kafka01、02、03节点上执行命令启动kafka集群"></a>在kafka01、02、03节点上执行命令启动kafka集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JMX_PORT=9999 kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties</span><br></pre></td></tr></table></figure><h3 id="Zookeeper常用命令"><a href="#Zookeeper常用命令" class="headerlink" title="Zookeeper常用命令"></a>Zookeeper常用命令</h3><p>查看znode中的内容</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ls</span>  /</span><br></pre></td></tr></table></figure><p>创建普通的节点 </p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">create</span></span><br></pre></td></tr></table></figure><p>获得节点的信息</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">get</span></span><br></pre></td></tr></table></figure><p>创建临时节点  </p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> -<span class="built_in">e</span></span><br></pre></td></tr></table></figure><p>编号节点： </p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">create -s</span></span><br></pre></td></tr></table></figure><p> 删除一个节点 </p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span></span><br></pre></td></tr></table></figure><p>递归删除节点</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">rmr</span></span><br></pre></td></tr></table></figure><p>修改节点内容</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span></span><br></pre></td></tr></table></figure><p>监听节点  </p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">get</span> /test watch</span><br></pre></td></tr></table></figure><p>在其他节点进行修改  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> /<span class="built_in">test</span> 555</span><br></pre></td></tr></table></figure><p>监听节点上收到WatchedEvent state:SyncConnected type:NodeDataChanged path:/test</p><h3 id="Kafka常用命令"><a href="#Kafka常用命令" class="headerlink" title="Kafka常用命令"></a>Kafka常用命令</h3><p>关闭Kafka（关闭Kafka之前禁止关闭Zookeeper）</p><figure class="highlight vbscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-<span class="built_in">server</span>-<span class="keyword">stop</span>.sh</span><br></pre></td></tr></table></figure><p>创建Topic</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper kafka01:2181,kafka02:2181,kafka03:2181 --replication-factor 3 --partitions 3 --topic test</span><br></pre></td></tr></table></figure><p>查看Topic列表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeper kafka01:2181,kafka02:2181,kafka03:2181</span><br></pre></td></tr></table></figure><p>查看Topic详细信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --describe --zookeeper kafka01:2181,kafka02:2181,kafka03:2181 --topic test</span><br></pre></td></tr></table></figure><p>建立发布者console-producer：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list kafka01:9092,kafka02:9092,kafka03:9092 --topic test</span><br></pre></td></tr></table></figure><p>建立订阅者console-consumer：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server kafka01:9092 --topic test --from-beginning</span><br></pre></td></tr></table></figure><p>删除topic(需要server.properties中设置delete.topic.enable=true否则只是标记删除或者直接重启)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --delete --zookeeper kafka01:2181,kafka02:2181,kafka03:2181 --topic test</span><br></pre></td></tr></table></figure><h2 id="使用kafka-manager管理kafka集群"><a href="#使用kafka-manager管理kafka集群" class="headerlink" title="使用kafka-manager管理kafka集群"></a>使用kafka-manager管理kafka集群</h2><p><strong>注：以下均在kafka用户下搭建，仅在kafka01节点上安装kafka-manager</strong></p><h3 id="将kafka-manager的安装包放到-data-apps目录下"><a href="#将kafka-manager的安装包放到-data-apps目录下" class="headerlink" title="将kafka-manager的安装包放到/data/apps目录下"></a>将kafka-manager的安装包放到/data/apps目录下</h3><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv ~/kafka-manager<span class="number">-1.3</span><span class="number">.3</span><span class="number">.22</span> /data/apps</span><br></pre></td></tr></table></figure><h3 id="配置kafka-manager"><a href="#配置kafka-manager" class="headerlink" title="配置kafka-manager"></a>配置kafka-manager</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd conf</span><br><span class="line">vim application.conf</span><br><span class="line">修改kafka-manager.zkhosts="kafka01:2181,kafka02:2181,kafka03:2181"</span><br></pre></td></tr></table></figure><h3 id="启动kafka-manager"><a href="#启动kafka-manager" class="headerlink" title="启动kafka-manager"></a>启动kafka-manager</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=8080 &amp;</span><br></pre></td></tr></table></figure><h3 id="kafka-manager的WebUI"><a href="#kafka-manager的WebUI" class="headerlink" title="kafka-manager的WebUI"></a>kafka-manager的WebUI</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka01:8080</span><br></pre></td></tr></table></figure><h2 id="使用jmxtrans-influxdb-grafana监控JMX指标"><a href="#使用jmxtrans-influxdb-grafana监控JMX指标" class="headerlink" title="使用jmxtrans+influxdb+grafana监控JMX指标"></a>使用jmxtrans+influxdb+grafana监控JMX指标</h2><p><strong>注：以下均在root用户下搭建，除了jmxtrans，其他组件仅在kafka01节点上安装</strong></p><h3 id="开启Kafka-JMX端口"><a href="#开启Kafka-JMX端口" class="headerlink" title="开启Kafka JMX端口"></a>开启Kafka JMX端口</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd bin</span><br><span class="line">vim kafka-run-class.sh</span><br></pre></td></tr></table></figure><p><strong>第一行增加<code>JMX_PORT=9999</code>即可</strong></p><p><strong>修改好后重启kafka，查看Kafka以及JMX端口状态</strong></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ps</span> -ef | <span class="keyword">grep</span> kafka</span><br><span class="line">netstat -anop | <span class="keyword">grep</span> <span class="number">9999</span></span><br></pre></td></tr></table></figure><h3 id="安装InfluxDB"><a href="#安装InfluxDB" class="headerlink" title="安装InfluxDB"></a>安装InfluxDB</h3><p><strong>下载InfluxDB rpm安装包</strong></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http<span class="variable">s:</span>//<span class="keyword">dl</span>.influxdata.<span class="keyword">com</span>/influxdb/releases/influxdb-<span class="number">1.7</span>.<span class="number">5</span>.x86_64.rpm</span><br></pre></td></tr></table></figure><p><strong>安装rpm包</strong></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">rpm</span> <span class="selector-tag">-ivh</span> <span class="selector-tag">influxdb-1</span><span class="selector-class">.7</span><span class="selector-class">.5</span><span class="selector-class">.x86_64</span><span class="selector-class">.rpm</span></span><br></pre></td></tr></table></figure><p><strong>启动InfluxDB</strong></p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service <span class="literal">inf</span>luxdb <span class="literal">start</span>（systemctl <span class="literal">start</span> <span class="literal">inf</span>luxdb）</span><br></pre></td></tr></table></figure><p><strong>查看InfluxDB状态</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep influxdb</span><br><span class="line">service influxdb status（systemctl status influxdb）</span><br></pre></td></tr></table></figure><p><strong>使用InfluxDB客户端</strong></p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">influx</span></span><br></pre></td></tr></table></figure><p><strong>创建用户和数据库</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">"admin"</span> <span class="keyword">WITH</span> <span class="keyword">PASSWORD</span> <span class="string">'admin'</span> <span class="keyword">WITH</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="string">"jmxDB"</span>;</span><br></pre></td></tr></table></figure><p><strong>创建完成InfluxDB的用户和数据库暂时就够用了，其它简单操作如下，后面会用到</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建数据库</span></span><br><span class="line">create database "db_name"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 显示所有的数据库</span></span><br><span class="line">show databases</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除数据库</span></span><br><span class="line">drop database "db_name"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用数据库</span></span><br><span class="line">use db_name</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 显示该数据库中所有的表</span></span><br><span class="line">show measurements</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建表，直接在插入数据的时候指定表名</span></span><br><span class="line">insert test,host=127.0.0.1,monitor_name=test count=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除表</span></span><br><span class="line">drop measurement "measurement_name"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 退出</span></span><br><span class="line">quit</span><br></pre></td></tr></table></figure><h3 id="安装jmxtrans（所有kafka节点均安装）"><a href="#安装jmxtrans（所有kafka节点均安装）" class="headerlink" title="安装jmxtrans（所有kafka节点均安装）"></a>安装jmxtrans（所有kafka节点均安装）</h3><p><strong>下载jmxtrans rpm安装包</strong></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http:<span class="regexp">//</span>central.maven.org<span class="regexp">/maven2/</span>org<span class="regexp">/jmxtrans/</span>jmxtrans<span class="regexp">/270/</span>jmxtrans-<span class="number">270</span>.rpm</span><br></pre></td></tr></table></figure><p><strong>安装rpm包</strong></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">rpm</span> <span class="selector-tag">-ivh</span> <span class="selector-tag">jmxtrans-270</span><span class="selector-class">.rpm</span></span><br></pre></td></tr></table></figure><p><strong>jmxtrans相关路径</strong></p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jmxtrans安装目录：/usr/share/jmxtrans</span><br><span class="line">json文件默认目录：/var/<span class="class"><span class="keyword">lib</span>/<span class="title">jmxtrans</span>/</span></span><br><span class="line">日志路径：/var/log/jmxtrans/jmxtrans.log</span><br></pre></td></tr></table></figure><p><strong>配置json，jmxtrans的github上有一段示例配置</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"servers"</span> : [ &#123;</span><br><span class="line">    <span class="attr">"port"</span> : <span class="string">"9999"</span>,</span><br><span class="line">    <span class="attr">"host"</span> : <span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="attr">"queries"</span> : [ &#123;</span><br><span class="line">      <span class="attr">"obj"</span> : <span class="string">"java.lang:type=Memory"</span>,</span><br><span class="line">      <span class="attr">"attr"</span> : [ <span class="string">"HeapMemoryUsage"</span>, <span class="string">"NonHeapMemoryUsage"</span> ],</span><br><span class="line">      <span class="attr">"resultAlias"</span>:<span class="string">"jvmMemory"</span>,</span><br><span class="line">      <span class="attr">"outputWriters"</span> : [ &#123;</span><br><span class="line">        <span class="attr">"@class"</span> : <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line">        <span class="attr">"url"</span> : <span class="string">"http://127.0.0.1:8086/"</span>,</span><br><span class="line">        <span class="attr">"username"</span> : <span class="string">"admin"</span>,</span><br><span class="line">        <span class="attr">"password"</span> : <span class="string">"admin"</span>,</span><br><span class="line">        <span class="attr">"database"</span> : <span class="string">"jmxDB"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>     : &#123;<span class="attr">"application"</span> : <span class="string">"kafka"</span>&#125;</span><br><span class="line">      &#125; ]</span><br><span class="line">    &#125; ]</span><br><span class="line">  &#125; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>host：监控服务器</li><li>port：jmx端口</li><li>obj：对应jmx的ObjectName，就是我们要监控的指标</li><li>attr：对应ObjectName的属性，可以理解为我们要监控的指标的值</li><li>resultAlias：对应metric 的名称，在InfluxDB里面就是MEASUREMENTS名</li><li>tags：对应InfluxDB的tag功能，对与存储在同一个MEASUREMENTS里面的不同监控指标可以做区分，我们在用Grafana绘图的时候会用到，建议对每个监控指标都打上tags</li></ul><p><strong>附上两段配置的json示例文件（完整的均放在了三台节点的/var/lib/jmxtrans/目录下）</strong></p><p>base_10.164.204.248.json</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"servers"</span>: [&#123;</span><br><span class="line"><span class="attr">"port"</span>: <span class="string">"9999"</span>,</span><br><span class="line"><span class="attr">"host"</span>: <span class="string">"10.164.204.248"</span>,</span><br><span class="line"><span class="attr">"queries"</span>: [&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>, <span class="string">"OneMinuteRate"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"BytesInPerSec"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"BytesInPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>, <span class="string">"OneMinuteRate"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"BytesOutPerSec"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"BytesOutPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>, <span class="string">"OneMinuteRate"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"BytesRejectedPerSec"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"BytesRejectedPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>, <span class="string">"OneMinuteRate"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"MessagesInPerSec"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"MessagesInPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchConsumer"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"RequestsPerSec"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"request"</span>: <span class="string">"FetchConsumer"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchFollower"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"RequestsPerSec"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"request"</span>: <span class="string">"FetchFollower"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.network:type=RequestMetrics,name=RequestsPerSec,request=Produce"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"RequestsPerSec"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"request"</span>: <span class="string">"Produce"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"java.lang:type=Memory"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"HeapMemoryUsage"</span>, <span class="string">"NonHeapMemoryUsage"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"MemoryUsage"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"MemoryUsage"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"java.lang:type=GarbageCollector,name=*"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"CollectionCount"</span>, <span class="string">"CollectionTime"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"GC"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"GC"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"java.lang:type=Threading"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"PeakThreadCount"</span>, <span class="string">"ThreadCount"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"Thread"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"Thread"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Value"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"ReplicaFetcherManager"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"MaxLag"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=ReplicaManager,name=PartitionCount"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Value"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"ReplicaManager"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"PartitionCount"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Value"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"ReplicaManager"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"UnderReplicatedPartitions"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=ReplicaManager,name=LeaderCount"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Value"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"ReplicaManager"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"LeaderCount"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchConsumer"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>, <span class="string">"Max"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"TotalTimeMs"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"FetchConsumer"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchFollower"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>, <span class="string">"Max"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"TotalTimeMs"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"FetchConsumer"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>, <span class="string">"Max"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"TotalTimeMs"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"Produce"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=ReplicaManager,name=IsrShrinksPerSec"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"ReplicaManager"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"IsrShrinksPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>flink_sf_lx_248.json</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"servers"</span>: [&#123;</span><br><span class="line"><span class="attr">"port"</span>: <span class="string">"9999"</span>,</span><br><span class="line"><span class="attr">"host"</span>: <span class="string">"10.164.204.248"</span>,</span><br><span class="line"><span class="attr">"queries"</span>: [&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=FLINK_SF_LX"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"FLINK_SF_LX"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"BytesInPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=FLINK_SF_LX"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"FLINK_SF_LX"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"BytesOutPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=FLINK_SF_LX"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Count"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"FLINK_SF_LX"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"MessagesInPerSec"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"obj"</span>: <span class="string">"kafka.log:type=Log,name=LogEndOffset,topic=FLINK_SF_LX,partition=*"</span>,</span><br><span class="line"><span class="attr">"attr"</span>: [<span class="string">"Value"</span>],</span><br><span class="line"><span class="attr">"resultAlias"</span>: <span class="string">"FLINK_SF_LX"</span>,</span><br><span class="line"><span class="attr">"outputWriters"</span>: [&#123;</span><br><span class="line"><span class="attr">"@class"</span>: <span class="string">"com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory"</span>,</span><br><span class="line"><span class="attr">"url"</span>: <span class="string">"http://10.164.204.248:8086/"</span>,</span><br><span class="line"><span class="attr">"username"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"password"</span>: <span class="string">"admin"</span>,</span><br><span class="line"><span class="attr">"database"</span>: <span class="string">"jmxDB"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"application"</span>: <span class="string">"LogEndOffset"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">]</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>配置说明：</strong></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line">1、全局指标</span><br><span class="line"></span><br><span class="line">每秒输入的流量</span><br><span class="line">"obj" : "kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"BytesInPerSec"</span><br><span class="line">"tags" : &#123;"application" : "BytesInPerSec"&#125;</span><br><span class="line"></span><br><span class="line">每秒输入的流量</span><br><span class="line">"obj" : "kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"BytesOutPerSec"</span><br><span class="line">"tags" : &#123;"application" : "BytesOutPerSec"&#125;</span><br><span class="line"></span><br><span class="line">每秒输入的流量</span><br><span class="line">"obj" : "kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"BytesRejectedPerSec"</span><br><span class="line">"tags" : &#123;"application" : "BytesRejectedPerSec"&#125;</span><br><span class="line"></span><br><span class="line">每秒的消息写入总量</span><br><span class="line"></span><br><span class="line">"obj" : "kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"MessagesInPerSec"</span><br><span class="line">"tags" : &#123;"application" : "MessagesInPerSec"&#125;</span><br><span class="line"></span><br><span class="line">每秒FetchFollower的请求次数</span><br><span class="line"></span><br><span class="line">"obj" : "kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchFollower"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"RequestsPerSec"</span><br><span class="line">"tags" : &#123;"request" : "FetchFollower"&#125;</span><br><span class="line"></span><br><span class="line">每秒FetchConsumer的请求次数</span><br><span class="line"></span><br><span class="line">"obj" : "kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchConsumer"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"RequestsPerSec"</span><br><span class="line">"tags" : &#123;"request" : "FetchConsumer"&#125;</span><br><span class="line"></span><br><span class="line">每秒Produce的请求次数</span><br><span class="line"></span><br><span class="line">"obj" : "kafka.network:type=RequestMetrics,name=RequestsPerSec,request=Produce"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"RequestsPerSec"</span><br><span class="line">"tags" : &#123;"request" : "Produce"&#125;</span><br><span class="line"></span><br><span class="line">内存使用的使用情况</span><br><span class="line">"obj" : "java.lang:type=Memory"</span><br><span class="line">"attr" : [ "HeapMemoryUsage", "NonHeapMemoryUsage" ]</span><br><span class="line">"resultAlias":"MemoryUsage"</span><br><span class="line">"tags" : &#123;"application" : "MemoryUsage"&#125;</span><br><span class="line"></span><br><span class="line">GC的耗时和次数</span><br><span class="line">"obj" : "java.lang:type=GarbageCollector,name=*"</span><br><span class="line">"attr" : [ "CollectionCount","CollectionTime" ]</span><br><span class="line">"resultAlias":"GC"</span><br><span class="line">"tags" : &#123;"application" : "GC"&#125;</span><br><span class="line"></span><br><span class="line">线程的使用情况</span><br><span class="line">"obj" : "java.lang:type=Threading"</span><br><span class="line">"attr" : [ "PeakThreadCount","ThreadCount" ]</span><br><span class="line">"resultAlias":"Thread"</span><br><span class="line">"tags" : &#123;"application" : "Thread"&#125;</span><br><span class="line"></span><br><span class="line">副本落后主分片的最大消息数量</span><br><span class="line">"obj" : "kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica"</span><br><span class="line">"attr" : [ "Value" ]</span><br><span class="line">"resultAlias":"ReplicaFetcherManager"</span><br><span class="line">"tags" : &#123;"application" : "MaxLag"&#125;</span><br><span class="line"></span><br><span class="line">该broker上的partition的数量</span><br><span class="line">"obj" : "kafka.server:type=ReplicaManager,name=PartitionCount"</span><br><span class="line">"attr" : [ "Value" ]</span><br><span class="line">"resultAlias":"ReplicaManager"</span><br><span class="line">"tags" : &#123;"application" : "PartitionCount"&#125;</span><br><span class="line"></span><br><span class="line">正在做复制的partition的数量</span><br><span class="line">"obj" : "kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions"</span><br><span class="line">"attr" : [ "Value" ]</span><br><span class="line">"resultAlias":"ReplicaManager"</span><br><span class="line">"tags" : &#123;"application" : "UnderReplicatedPartitions"&#125;</span><br><span class="line"></span><br><span class="line">Leader的replica的数量</span><br><span class="line">"obj" : "kafka.server:type=ReplicaManager,name=LeaderCount"</span><br><span class="line">"attr" : [ "Value" ]</span><br><span class="line">"resultAlias":"ReplicaManager"</span><br><span class="line">"tags" : &#123;"application" : "LeaderCount"&#125;</span><br><span class="line"></span><br><span class="line">一个请求FetchConsumer耗费的所有时间</span><br><span class="line">"obj" : "kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchConsumer"</span><br><span class="line">"attr" : [ "Count","Max" ]</span><br><span class="line">"resultAlias":"TotalTimeMs"</span><br><span class="line">"tags" : &#123;"application" : "FetchConsumer"&#125;</span><br><span class="line"></span><br><span class="line">一个请求FetchFollower耗费的所有时间</span><br><span class="line">"obj" : "kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchFollower"</span><br><span class="line">"attr" : [ "Count","Max" ]</span><br><span class="line">"resultAlias":"TotalTimeMs"</span><br><span class="line">"tags" : &#123;"application" : "FetchFollower"&#125;</span><br><span class="line"></span><br><span class="line">一个请求Produce耗费的所有时间</span><br><span class="line">"obj" : "kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce"</span><br><span class="line">"attr" : [ "Count","Max" ]</span><br><span class="line">"resultAlias":"TotalTimeMs"</span><br><span class="line">"tags" : &#123;"application" : "Produce"&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2、topic的监控指标</span><br><span class="line"></span><br><span class="line">falcon_monitor_us每秒的写入流量</span><br><span class="line"><span class="string">"kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=falcon_monitor_us"</span></span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"falcon_monitor_us"</span><br><span class="line">"tags" : &#123;"application" : "BytesInPerSec"&#125;</span><br><span class="line"></span><br><span class="line">falcon_monitor_us每秒的输出流量</span><br><span class="line"><span class="string">"kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=falcon_monitor_us"</span></span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"falcon_monitor_us"</span><br><span class="line">"tags" : &#123;"application" : "BytesOutPerSec"&#125;</span><br><span class="line"></span><br><span class="line">falcon_monitor_us每秒写入消息的数量</span><br><span class="line">"obj" : "kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=falcon_monitor_us"</span><br><span class="line">"attr" : [ "Count" ]</span><br><span class="line">"resultAlias":"falcon_monitor_us"</span><br><span class="line">"tags" : &#123;"application" : "MessagesInPerSec"&#125;</span><br><span class="line"></span><br><span class="line">falcon_monitor_us在每个分区最后的Offset</span><br><span class="line">"obj" : "kafka.log:type=Log,name=LogEndOffset,topic=falcon_monitor_us,partition=*"</span><br><span class="line">"attr" : [ "Value" ]</span><br><span class="line">"resultAlias":"falcon_monitor_us"</span><br><span class="line">"tags" : &#123;"application" : "LogEndOffset"&#125;</span><br><span class="line"></span><br><span class="line">PS：</span><br><span class="line">1、参数说明</span><br><span class="line">"obj"对应jmx的ObjectName，就是我们要监控的指标</span><br><span class="line">"attr"对应ObjectName的属性，可以理解为我们要监控的指标的值</span><br><span class="line">"resultAlias"对应metric 的名称，在InfluxDb里面就是MEASUREMENTS名</span><br><span class="line">"tags" 对应InfluxDb的tag功能，对与存储在同一个MEASUREMENTS里面的不同监控指标可以做区分，我们在用Grafana绘图的时候会用到，建议对每个监控指标都打上tags</span><br><span class="line"></span><br><span class="line">2、对于全局监控，每一个监控指标对应一个MEASUREMENTS，所有的kafka节点同一个监控指标数据写同一个MEASUREMENTS ，对于topc监控的监控指标，同一个topic所有kafka节点写到同一个MEASUREMENTS，并且以topic名称命名</span><br></pre></td></tr></table></figure><p><strong>启动jmxtrans</strong></p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service jmxtrans <span class="literal">start</span>(systemctl <span class="literal">start</span> jmxtrans)</span><br></pre></td></tr></table></figure><p><strong>查看日志没有报错即为成功</strong></p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail /<span class="built_in">var</span>/<span class="keyword">log</span>/jmxtrans/jmxtrans.<span class="keyword">log</span></span><br></pre></td></tr></table></figure><h3 id="安装Grafana"><a href="#安装Grafana" class="headerlink" title="安装Grafana"></a>安装Grafana</h3><p><strong>下载jmxtrans rpm安装包</strong></p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://s3-us-west<span class="string">-2</span>.amazonaws.com/grafana-releases/release/grafana<span class="string">-6</span>.0.2<span class="string">-1</span>.x86_64.rpm</span><br></pre></td></tr></table></figure><p><strong>安装rpm包（如果缺少依赖，下载依赖）</strong></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">rpm</span> <span class="selector-tag">-ivh</span> <span class="selector-tag">grafana-6</span><span class="selector-class">.0</span><span class="selector-class">.2-1</span><span class="selector-class">.x86_64</span><span class="selector-class">.rpm</span></span><br></pre></td></tr></table></figure><hr><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yum install --downloadonly --downloaddir=./ fontconfig</span><br><span class="line"></span><br><span class="line">yum localinstall fontconfig-<span class="number">2.13</span>.<span class="number">0</span>-<span class="number">4.3</span><span class="selector-class">.el7</span><span class="selector-class">.x86_64</span><span class="selector-class">.rpm</span></span><br><span class="line"></span><br><span class="line">yum install --downloadonly --downloaddir=./ urw-fonts</span><br><span class="line"></span><br><span class="line">yum localinstall urw-fonts-<span class="number">2.4</span>-<span class="number">11</span><span class="selector-class">.el6</span><span class="selector-class">.noarch</span><span class="selector-class">.rpm</span> </span><br><span class="line"></span><br><span class="line">rpm -ivh grafana-<span class="number">6.0</span>.<span class="number">2</span>-<span class="number">1</span><span class="selector-class">.x86_64</span><span class="selector-class">.rpm</span></span><br></pre></td></tr></table></figure><p><strong>启动Grafana</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service grafana-server <span class="keyword">start</span>（systemctl <span class="keyword">start</span> grafana-<span class="keyword">server</span>）</span><br></pre></td></tr></table></figure><p><strong>打开浏览器</strong></p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">http:</span><span class="comment">//127.0.0.1:3000</span></span><br></pre></td></tr></table></figure><p><strong>先输入默认用户名密码admin/admin</strong></p><p><strong>点击Add data source，选择InfluxDB</strong></p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Url、Database、User、Password需要和jmxtrans采集数据配置文件里面的写一致，然后点击<span class="keyword">Save</span>&amp;<span class="keyword">Test</span>，提示成功就正常了</span><br></pre></td></tr></table></figure><p><strong>通过后点击Back返回</strong></p><p><strong>左侧 + 可以创建或引入仪表盘，创建一个dashboard，然后在这里配置每一个监控指标的图</strong></p><p><strong>主要配置项说明：</strong></p><table><thead><tr><th>配置项</th><th>说明</th></tr></thead><tbody><tr><td>DataSource</td><td>选择Grafana已配置的数据源</td></tr><tr><td>FROM-Default</td><td>默认Schema，保持不变即可</td></tr><tr><td>FROM-measurement</td><td>对应的InfluxDB的表名</td></tr><tr><td>WHERE</td><td>WHERE条件，根据自己需求选择</td></tr><tr><td>SELECT-Field</td><td>对应选的字段，可根据需求增减</td></tr><tr><td>SELECT-mean()</td><td>选择的字段对应的InfluxDB的函数</td></tr><tr><td>GroupBY-time()</td><td>根据时间分组</td></tr><tr><td>GROUPBY-fill()</td><td>当不存在数据时，以null为默认值填充</td></tr></tbody></table><p><strong>要点说明：</strong></p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、对于监控指标为Count的监控项，需要通过Grafana做计算得到我们想要的监控，比如BytesInPerSec这个指标，它的监控值是一个累计值，我们想要取到每秒的流量，肯定需要计算，(本次采集的值-上次采集的值)/<span class="number">60</span> ,jmxtrans是一分钟采集一次数据，具体配置参考下面截图：</span><br><span class="line"></span><br><span class="line">因为我们是一分钟采集一次数据，所以group <span class="keyword">by</span> 和derivative选<span class="number">1</span>分钟；因为我们要每秒的流量，所以math这里除以<span class="number">60</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>、X轴的单位选择，比如流量的单位、时间的单位、每秒消息的个数无单位等等，下面分布举一个例子介绍说明</span><br><span class="line"></span><br><span class="line">设置流量的单位 ，点击需要设置的图，选择<span class="string">"Edit"</span>进入编辑页面，切到Axes这个<span class="literal">tab</span>页，Unit<span class="comment">--》data（Metric）--》bytes</span></span><br><span class="line"></span><br><span class="line">设置时间的单位 ，点击需要设置的图，选择<span class="string">"Edit"</span>进入编辑页面，切到Axes这个<span class="literal">tab</span>页，Unit<span class="comment">--》time--》milliseconds(ms)</span></span><br><span class="line"></span><br><span class="line">设置按原始值展示，无单位 ，点击需要设置的图，选择<span class="string">"Edit"</span>进入编辑页面，切到Axes这个<span class="literal">tab</span>页，Unit<span class="comment">--》none--》none</span></span><br></pre></td></tr></table></figure><h2 id="附录（kafka配置说明）"><a href="#附录（kafka配置说明）" class="headerlink" title="附录（kafka配置说明）"></a>附录（kafka配置说明）</h2><h3 id="server-properties"><a href="#server-properties" class="headerlink" title="server.properties"></a>server.properties</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> this work <span class="keyword">for</span> additional information regarding copyright ownership.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> (the <span class="string">"License"</span>); you may not use this file except <span class="keyword">in</span> compliance with</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> see kafka.server.KafkaConfig <span class="keyword">for</span> additional details and defaults</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Server Basics #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The id of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span> each broker.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 节点的ID，必须与其它节点不同</span></span><br><span class="line">broker.id=0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Switch to <span class="built_in">enable</span> topic deletion or not, default value is <span class="literal">false</span></span></span><br><span class="line">delete.topic.enable=false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Socket Server Settings #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The address the socket server listens on. It will get the value returned from </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> java.net.InetAddress.getCanonicalHostName() <span class="keyword">if</span> not configured.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 套接字服务器监听的地址。如果没有配置，就使用java.net.InetAddress.getCanonicalHostName()的返回值</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   FORMAT:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     listeners = listener_name://host_name:port</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   EXAMPLE:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">     listeners = PLAINTEXT://your.host.name:9092</span></span><br><span class="line"><span class="meta">#</span><span class="bash">listeners=PLAINTEXT://:9092</span></span><br><span class="line">listeners=PLAINTEXT://kafka01:9092</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Hostname and port the broker will advertise to producers and consumers. If not <span class="built_in">set</span>, </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> it uses the value <span class="keyword">for</span> <span class="string">"listeners"</span> <span class="keyword">if</span> configured.  Otherwise, it will use the value</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> returned from java.net.InetAddress.getCanonicalHostName().</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 节点的主机名会通知给生产者和消费者。如果没有设置，如果配置了<span class="string">"listeners"</span>就使用<span class="string">"listeners"</span>的值。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 否则就使用java.net.InetAddress.getCanonicalHostName()的返回值</span></span><br><span class="line"><span class="meta">#</span><span class="bash">advertised.listeners=PLAINTEXT://your.host.name:9092</span></span><br><span class="line">advertised.listeners=PLAINTEXT://kafka01:9092</span><br><span class="line"><span class="meta">#</span><span class="bash"> Maps listener names to security protocols, the default is <span class="keyword">for</span> them to be the same. See the config documentation <span class="keyword">for</span> more details</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将侦听器的名称映射到安全协议，默认情况下它们是相同的。有关详细信息，请参阅配置文档</span></span><br><span class="line"><span class="meta">#</span><span class="bash">listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of threads that the server uses <span class="keyword">for</span> receiving requests from the network and sending responses to the network</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务器用来接受请求或者发送响应的线程数</span></span><br><span class="line">num.network.threads=3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of threads that the server uses <span class="keyword">for</span> processing requests, <span class="built_in">which</span> may include disk I/O</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务器用来处理请求的线程数，可能包括磁盘IO</span></span><br><span class="line">num.io.threads=8</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The send buffer (SO_SNDBUF) used by the socket server</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 套接字服务器使用的发送缓冲区大小</span></span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The receive buffer (SO_RCVBUF) used by the socket server</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 套接字服务器使用的接收缓冲区大小</span></span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The maximum size of a request that the socket server will accept (protection against OOM)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 单个请求最大能接收的数据量</span></span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Log Basics #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> A comma seperated list of directories under <span class="built_in">which</span> to store <span class="built_in">log</span> files</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一个逗号分隔的目录列表，用来存储日志文件</span></span><br><span class="line">log.dirs=/data/apps/kafkaapp/logs</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The default number of <span class="built_in">log</span> partitions per topic. More partitions allow greater</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> parallelism <span class="keyword">for</span> consumption, but this will also result <span class="keyword">in</span> more files across</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the brokers.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 每个主题的日志分区的默认数量。更多的分区允许更大的并行操作，但是它会导致节点产生更多的文件</span></span><br><span class="line">num.partitions=6</span><br><span class="line">default.replication.factor=3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of threads per data directory to be used <span class="keyword">for</span> <span class="built_in">log</span> recovery at startup and flushing at shutdown.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> This value is recommended to be increased <span class="keyword">for</span> installations with data <span class="built_in">dirs</span> located <span class="keyword">in</span> RAID array.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 每个数据目录中的线程数，用于在启动时日志恢复，并在关闭时刷新。</span></span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Internal Topic Settings  #############################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The replication factor <span class="keyword">for</span> the group metadata internal topics <span class="string">"__consumer_offsets"</span> and <span class="string">"__transaction_state"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> For anything other than development testing, a value greater than 1 is recommended <span class="keyword">for</span> to ensure availability such as 3.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 对于除了开发测试之外的其他任何东西，group元数据内部主题的复制因子“__consumer_offsets”和“__transaction_state”，建议值大于1，以确保可用性(如3)。</span></span><br><span class="line">offsets.topic.replication.factor=3</span><br><span class="line">transaction.state.log.replication.factor=3</span><br><span class="line">transaction.state.log.min.isr=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Log Flush Policy #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Messages are immediately written to the filesystem but by default we only fsync() to sync</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the OS cache lazily. The following configurations control the flush of data to disk.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 消息直接被写入文件系统，但是默认情况下我们仅仅调用fsync()以延迟的同步系统缓存</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> There are a few important trade-offs here:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这些有一些重要的权衡</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    1. Durability: Unflushed data may be lost <span class="keyword">if</span> you are not using replication.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1. 持久性:如果不使用复制，未刷新的数据可能会丢失。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 延迟:非常大的刷新间隔可能会在刷新时导致延迟，因为将会有大量数据刷新。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. 吞吐量:刷新通常是最昂贵的操作，而一个小的刷新间隔可能会导致过多的搜索。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The settings below allow one to configure the flush policy to flush data after a period of time or</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> every N messages (or both). This can be <span class="keyword">done</span> globally and overridden on a per-topic basis.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面的设置允许你去配置刷新策略，每隔一段时间刷新或者一次N个消息（或者两个都配置）。这可以在全局范围内完成，并在每个主题的基础上重写。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of messages to accept before forcing a flush of data to disk</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在强制刷新数据到磁盘之前允许接收消息的数量</span></span><br><span class="line"><span class="meta">#</span><span class="bash">log.flush.interval.messages=10000</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The maximum amount of time a message can sit <span class="keyword">in</span> a <span class="built_in">log</span> before we force a flush</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在强制刷新之前，消息可以在日志中停留的最长时间</span></span><br><span class="line"><span class="meta">#</span><span class="bash">log.flush.interval.ms=1000</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Log Retention Policy #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The following configurations control the disposal of <span class="built_in">log</span> segments. The policy can</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> be <span class="built_in">set</span> to delete segments after a period of time, or after a given size has accumulated.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 以下的配置控制了日志段的处理。策略可以配置为每隔一段时间删除片段或者到达一定大小之后。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> from the end of the <span class="built_in">log</span>.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当满足这些条件时，将会删除一个片段。删除总是发生在日志的末尾。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The minimum age of a <span class="built_in">log</span> file to be eligible <span class="keyword">for</span> deletion due to age</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一个日志的最小存活时间，可以被删除</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> A size-based retention policy <span class="keyword">for</span> logs. Segments are pruned from the <span class="built_in">log</span> as long as the remaining</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> segments don<span class="string">'t drop below log.retention.bytes. Functions independently of log.retention.hours.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一个基于大小的日志保留策略。段将被从日志中删除只要剩下的部分段不低于log.retention.bytes。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">log.retention.bytes=1073741824</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The maximum size of a <span class="built_in">log</span> segment file. When this size is reached a new <span class="built_in">log</span> segment will be created.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 每一个日志段大小的最大值。当到达这个大小时，会生成一个新的片段。</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The interval at <span class="built_in">which</span> <span class="built_in">log</span> segments are checked to see <span class="keyword">if</span> they can be deleted according</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> to the retention policies</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 检查日志段的时间间隔，看是否可以根据保留策略删除它们</span></span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Zookeeper #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper connection string (see zookeeper docs <span class="keyword">for</span> details).</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper连接字符串（具体见Zookeeper文档）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is a comma separated host:port pairs, each corresponding to a zk</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这是一个以逗号为分割的部分，每一个都匹配一个Zookeeper</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> server. e.g. <span class="string">"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"</span>.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You can also append an optional chroot string to the urls to specify the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 您还可以将一个可选的chroot字符串附加到url，以指定所有kafka znode的根目录。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> root directory <span class="keyword">for</span> all kafka znodes.</span></span><br><span class="line">zookeeper.connect=kafka01:2181,kafka02:2181,kafka03:2181</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Timeout <span class="keyword">in</span> ms <span class="keyword">for</span> connecting to zookeeper</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 连接到Zookeeper的超时时间</span></span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Group Coordinator Settings #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The following configuration specifies the time, <span class="keyword">in</span> milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The default value <span class="keyword">for</span> this is 3 seconds.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> We override this to 0 here as it makes <span class="keyword">for</span> a better out-of-the-box experience <span class="keyword">for</span> development and testing.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> However, <span class="keyword">in</span> production environments the default value of 3 seconds is more suitable as this will <span class="built_in">help</span> to avoid unnecessary, and potentially expensive, rebalances during application startup.</span></span><br><span class="line">group.initial.rebalance.delay.ms=0</span><br></pre></td></tr></table></figure><h3 id="producer-properties"><a href="#producer-properties" class="headerlink" title="producer.properties"></a>producer.properties</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> this work <span class="keyword">for</span> additional information regarding copyright ownership.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> (the <span class="string">"License"</span>); you may not use this file except <span class="keyword">in</span> compliance with</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> limitations under the License.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> see kafka.producer.ProducerConfig <span class="keyword">for</span> more details</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Producer Basics #############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> list of brokers used <span class="keyword">for</span> bootstrapping knowledge about the rest of the cluster</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> format: host1:port1,host2:port2 ...</span></span><br><span class="line">bootstrap.servers=kafka01:9092,kafka02:9092,kafka03:9092</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> specify the compression codec <span class="keyword">for</span> all data generated: none, gzip, snappy, lz4</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩。压缩后消息中会有头来指明消息压缩类型，故在消费者端消息解压是透明的无需指定。</span></span><br><span class="line">compression.type=none</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> name of the partitioner class <span class="keyword">for</span> partitioning events; default partition spreads data randomly</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定分区处理类。默认kafka.producer.DefaultPartitioner，表通过key哈希到对应分区</span></span><br><span class="line">partitioner.class=kafka.producer.DefaultPartitioner</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> the maximum amount of time the client will <span class="built_in">wait</span> <span class="keyword">for</span> the response of a request</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在向producer发送ack之前,broker允许等待的最大时间 ，如果超时,broker将会向producer发送一个error ACK.意味着上一次消息因为某种原因未能成功(比如follower未能同步成功)</span></span><br><span class="line">request.timeout.ms=10000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> how long `KafkaProducer.send` and `KafkaProducer.partitionsFor` will block <span class="keyword">for</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">max.block.ms=</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> the producer will <span class="built_in">wait</span> <span class="keyword">for</span> up to the given delay to allow other records to be sent so that the sends can be batched together</span></span><br><span class="line"><span class="meta">#</span><span class="bash">linger.ms=</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> the maximum size of a request <span class="keyword">in</span> bytes</span></span><br><span class="line"><span class="meta">#</span><span class="bash">max.request.size=</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> the default batch size <span class="keyword">in</span> bytes when batching multiple records sent to a partition</span></span><br><span class="line"><span class="meta">#</span><span class="bash">batch.size=</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> the total bytes of memory the producer can use to buffer records waiting to be sent to the server</span></span><br><span class="line"><span class="meta">#</span><span class="bash">buffer.memory=</span></span><br></pre></td></tr></table></figure><h3 id="consumer-properties"><a href="#consumer-properties" class="headerlink" title="consumer.properties"></a>consumer.properties</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> this work <span class="keyword">for</span> additional information regarding copyright ownership.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> (the <span class="string">"License"</span>); you may not use this file except <span class="keyword">in</span> compliance with</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> limitations under the License.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> see kafka.consumer.ConsumerConfig <span class="keyword">for</span> more details</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper connection string</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> comma separated host:port pairs, each corresponding to a zk</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> server. e.g. <span class="string">"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"</span></span></span><br><span class="line">zookeeper.connect=kafka01:2181,kafka02:2181,kafka03:2181</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> timeout <span class="keyword">in</span> ms <span class="keyword">for</span> connecting to zookeeper</span></span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">consumer group id</span></span><br><span class="line">group.id=test-consumer-group</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">consumer timeout</span></span><br><span class="line"><span class="meta">#</span><span class="bash">consumer.timeout.ms=500</span></span><br></pre></td></tr></table></figure><h3 id="install-kafka-sh"><a href="#install-kafka-sh" class="headerlink" title="install-kafka.sh"></a>install-kafka.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Author gaojintao999@163.com</span></span><br><span class="line">echo "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"</span><br><span class="line">echo "~~~ 运行后续操作前请仔细阅读以下内容！ Author gaojintao999@163.com ~~~"</span><br><span class="line">echo "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"</span><br><span class="line">echo "(1)已配置主机映射！"</span><br><span class="line">echo "(2)已永久关闭防火墙！"</span><br><span class="line">echo "(3)已配置免密登录！"</span><br><span class="line">echo "(4)当前执行脚本和相关的安装包资源在同一路径下！"</span><br><span class="line">read -p "上述条件是否都满足？(y or n)" yesorno</span><br><span class="line"></span><br><span class="line">if [[ $yesorno = "y" || $yesorno = "Y" ]]; then</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置KAFKA的安装目录</span></span><br><span class="line">currentTime=$(date '+%Y-%m-%d %H:%M:%S')</span><br><span class="line">echo -e "请输入kafka的安装目录,不存在脚本自动创建,最后一个/不要写,如 /data/apps"</span><br><span class="line">read kafkainstallpath</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kafka安装的目录</span></span><br><span class="line">if [ ! -d $kafkainstallpath ]; then</span><br><span class="line">   mkdir -p $kafkainstallpath</span><br><span class="line">fi </span><br><span class="line">if [ ! -d $kafkainstallpath ]; then</span><br><span class="line">  echo "创建目录$kafkainstallpath失败！请检查目录是否有权限"</span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压tar包</span></span><br><span class="line">currentdir=$(cd $(dirname $0); pwd)</span><br><span class="line">ls | grep 'kafka.*[gz]$'</span><br><span class="line">if [ $? -ne 0 ]; then</span><br><span class="line">   # 当前目录没有kafka的压缩包</span><br><span class="line">   echo "在$currentdir下没有发现kafka*.tar.gz,请自行上传!"</span><br><span class="line">   exit</span><br><span class="line">else</span><br><span class="line">   # 解压</span><br><span class="line">   tar -zxvf $currentdir/$(ls | grep 'kafka.*[gz]$') -C $kafkainstallpath</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka版本全称</span></span><br><span class="line">kafkaversion=`ls $kafkainstallpath| grep 'kafka_2.*'`</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka配置文件存储路径</span></span><br><span class="line">confpath=$kafkainstallpath/$kafkaversion/config</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改配置文件</span></span><br><span class="line">echo -e "请输入当前kafka节点的broker.id：唯一值 例如 0"</span><br><span class="line">read brokerid</span><br><span class="line">sed -i "s/^broker.id=0/broker.id=$&#123;brokerid&#125;/g" $confpath/server.properties</span><br><span class="line"></span><br><span class="line">echo -e "请输入当前kafka节点的hostname: 例如kafka01"</span><br><span class="line">read hostname</span><br><span class="line">sed -i "s/^#listeners=PLAINTEXT:\/\/:9092/listeners=PLAINTEXT:\/\/$hostname:9092/g" $confpath/server.properties</span><br><span class="line"> </span><br><span class="line">echo -e "请输入kafka消息存储目录：例如 /data/apps/kafkaapp/log"</span><br><span class="line">read kafkalogspath</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">创建KAFKA日志存储目录</span></span><br><span class="line">if [ ! -d $kafkalogspath ]; then</span><br><span class="line">   mkdir -p $kafkalogspath</span><br><span class="line">fi </span><br><span class="line">if [ ! -d $kafkalogspath ]; then</span><br><span class="line">  echo "创建目录$kafkalogspath失败！请检查目录是否有权限"</span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">bak_dir='log.dirs=/tmp/kafka-logs'</span><br><span class="line">new_dir='log.dirs='$kafkalogspath</span><br><span class="line">sed -i "s!$&#123;bak_dir&#125;!$&#123;new_dir&#125;!g" $confpath/server.properties</span><br><span class="line"> </span><br><span class="line">echo -e '请输入zookeeper集群的所有节点：（严格按照示例格式） 例如kafka01:2181,kafka02:2181,kafka03:2181'</span><br><span class="line">read allhosts</span><br><span class="line">sed -i "s/^zookeeper.connect=localhost:2181/zookeeper.connect=$allhosts/g" $confpath/server.properties</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭删除topic的权限</span></span><br><span class="line">sed -i 's/^#delete.topic.enable=true/delete.topic.enable=false/g' $confpath/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置topic的默认分区数量为6</span></span><br><span class="line">sed -i 's/^num.partitions=1/num.partitions=6/g' $confpath/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 一个基于大小的日志保留策略。段将被从日志中删除只要剩下的部分段不低于log.retention.bytes。</span></span><br><span class="line">sed -i 's/^#log.retention.bytes=1073741824/log.retention.bytes=1073741824/g' $confpath/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在强制刷新数据到磁盘之前允许接收消息的数量</span></span><br><span class="line">sed -i 's/^#log.flush.interval.messages=10000/log.flush.interval.messages=10000/g' $confpath/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在强制刷新之前，消息可以在日志中停留的最长时间</span></span><br><span class="line">sed -i 's/^#log.flush.interval.ms=1000/log.flush.interval.ms=1000/g' $confpath/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置偏移量topic的复制因子为3</span></span><br><span class="line">sed -i 's/^offsets.topic.replication.factor=1/offsets.topic.replication.factor=3/g' $confpath/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置事务topic的复制因子为3</span></span><br><span class="line">sed -i 's/^transaction.state.log.replication.factor=1/transaction.state.log.replication.factor=3/g' $confpath/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认副本因子为3</span></span><br><span class="line">echo ""&gt;&gt;$confpath/server.properties</span><br><span class="line">echo "default.replication.factor=3" &gt;&gt;$confpath/server.properties</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> <span class="string">""</span>&gt;&gt;<span class="variable">$confpath</span>/server.properties</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> <span class="string">"log.cleanup.policy=delete"</span> &gt;&gt;<span class="variable">$confpath</span>/server.properties</span></span><br><span class="line"><span class="meta">#</span><span class="bash">kafka参数优化</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sed -i <span class="string">'s/^log.retention.hours=16/log.retention.hours=72/g'</span> <span class="variable">$confpath</span>/server.properties</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> param=`cat /proc/cpuinfo | grep <span class="string">"cpu cores"</span>| uniq`</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> bak_count=<span class="string">"num.network.threads=3"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> new_count=<span class="string">"num.network.threads="</span>$((<span class="variable">$&#123;param:0-1:1&#125;</span>+1))</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sed -i <span class="string">"s!<span class="variable">$&#123;bak_count&#125;</span>!<span class="variable">$&#123;new_count&#125;</span>!g"</span> <span class="variable">$confpath</span>/server.properties</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> bak_io=<span class="string">"num.network.threads=3"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> new_io=<span class="string">"num.network.threads="</span>$((<span class="variable">$&#123;param:0-1:1&#125;</span>+<span class="variable">$&#123;param:0-1:1&#125;</span>))</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sed -i <span class="string">"s!<span class="variable">$&#123;bak_io&#125;</span>!<span class="variable">$&#123;new_io&#125;</span>!g"</span> <span class="variable">$confpath</span>/server.properties</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">PATH设置</span></span><br><span class="line"><span class="meta">#</span><span class="bash">末行插入</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">""</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">"#KAFKA <span class="variable">$currentTime</span>"</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">"export KAFKA_HOME=<span class="variable">$kafkainstallpath</span>/<span class="variable">$kafkaversion</span>"</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">'export PATH=$PATH:$KAFKA_HOME/bin'</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">source</span> ~/.bash_profile</span></span><br><span class="line"> </span><br><span class="line">echo -e "是否远程复制 请输入y/n"</span><br><span class="line">read flag</span><br><span class="line">if [[ $flag == "y" ]]; then</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">修改并分发安装文件</span></span><br><span class="line">kafkapath=$kafkainstallpath/$kafkaversion</span><br><span class="line">kafkapathtemp=$kafkainstallpath/$kafkaversion-temp</span><br><span class="line">cp -r $kafkapath $kafkapathtemp</span><br><span class="line"> </span><br><span class="line">echo "以下输入的节点必须做免密登录"</span><br><span class="line">echo -e '请输入除当前节点之外的节点(当前节点$&#123;hostname&#125;),严格符合以下格式hostname:brokerid,空格隔开， 如kafka02:1 kafka03:2'</span><br><span class="line">read allnodes</span><br><span class="line">user=`whoami`</span><br><span class="line">array2=($&#123;allnodes// / &#125;)</span><br><span class="line">for allnode in $&#123;array2[@]&#125;</span><br><span class="line">do</span><br><span class="line"> array3=($&#123;allnode//:/ &#125;)</span><br><span class="line"> kafkahostname=$&#123;array3[0]&#125;</span><br><span class="line"> kafkabrokerid=$&#123;array3[1]&#125;</span><br><span class="line"> echo ======= $kafkahostname  =======</span><br><span class="line"> </span><br><span class="line"><span class="meta"> #</span><span class="bash">修改文件</span></span><br><span class="line"> ssh $kafkahostname "rm -rf $kafkapath $kafkalogspath"</span><br><span class="line"> ssh $kafkahostname "mkdir -p $kafkapath $kafkalogspath"</span><br><span class="line"> </span><br><span class="line"><span class="meta"> #</span><span class="bash">修改broker.id</span></span><br><span class="line"> old_brokerid="broker.id=$brokerid"</span><br><span class="line"> new_brokerid="broker.id=$kafkabrokerid"</span><br><span class="line"> sed -i "s!$&#123;old_brokerid&#125;!$&#123;new_brokerid&#125;!g" $kafkapathtemp/config/server.properties</span><br><span class="line"><span class="meta"> #</span><span class="bash">修改listeners</span></span><br><span class="line"> old_listeners="listeners=PLAINTEXT:\/\/$&#123;hostname&#125;:9092"</span><br><span class="line"> new_listeners="listeners=PLAINTEXT:\/\/$&#123;kafkahostname&#125;:9092"</span><br><span class="line"> sed -i "s!$&#123;old_listeners&#125;!$&#123;new_listeners&#125;!g" $kafkapathtemp/config/server.properties</span><br><span class="line"> </span><br><span class="line"> scp -r $kafkapathtemp/* $&#123;user&#125;@$kafkahostname:$kafkapath/</span><br><span class="line"> </span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$kafkahostname</span> <span class="string">"echo ''&gt;&gt;~/.bash_profile"</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$kafkahostname</span> <span class="string">"echo '#KAFKA <span class="variable">$currentTime</span>'&gt;&gt;~/.bash_profile"</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$kafkahostname</span> <span class="string">"echo 'export KAFKA_HOME=<span class="variable">$kafkainstallpath</span>/<span class="variable">$kafkaversion</span>'&gt;&gt;~/.bash_profile"</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$kafkahostname</span> <span class="string">'echo "export PATH=\$PATH:\$KAFKA_HOME/bin"&gt;&gt;~/.bash_profile'</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$kafkahostname</span> <span class="string">"source ~/.bash_profile"</span></span></span><br><span class="line"> </span><br><span class="line"><span class="meta"> #</span><span class="bash">再次修改回来 防止修改错误</span></span><br><span class="line"> new_brokerid="broker.id=$brokerid"</span><br><span class="line"> old_brokerid="broker.id=$kafkabrokerid"</span><br><span class="line"> sed -i "s!$&#123;old_brokerid&#125;!$&#123;new_brokerid&#125;!g" $kafkapathtemp/config/server.properties</span><br><span class="line"> new_listeners="listeners=PLAINTEXT:\/\/$hostname:9092"</span><br><span class="line"> old_listeners="listeners=PLAINTEXT:\/\/$kafkahostname:9092"</span><br><span class="line"> sed -i "s!$&#123;old_listeners&#125;!$&#123;new_listeners&#125;!g" $kafkapathtemp/config/server.properties</span><br><span class="line"> </span><br><span class="line"> echo ======= $kafkahostname 远程复制完成  =======</span><br><span class="line">done</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">删除临时文件</span></span><br><span class="line">rm -rf $kafkapathtemp</span><br><span class="line"> </span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line">echo "退出当前程序！"</span><br><span class="line">exit</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="install-zookeeper-sh"><a href="#install-zookeeper-sh" class="headerlink" title="install-zookeeper.sh"></a>install-zookeeper.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Author gaojintao999@163.com</span></span><br><span class="line">echo "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"</span><br><span class="line">echo "~~~ 运行后续操作前请仔细阅读以下内容！ Author gaojintao999@163.com ~~~"</span><br><span class="line">echo "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"</span><br><span class="line">echo "(1)已配置主机映射！"</span><br><span class="line">echo "(2)已永久关闭防火墙！"</span><br><span class="line">echo "(3)已配置免密登录！"</span><br><span class="line">echo "(4)当前执行脚本和相关的安装包资源在同一路径下！"</span><br><span class="line">read -p "上述条件是否都满足？(y or n)" yesorno</span><br><span class="line"></span><br><span class="line">if [[ $yesorno = "y" || $yesorno = "Y" ]]; then</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">配置zk的安装目录</span></span><br><span class="line">currentTime=$(date '+%Y-%m-%d %H:%M:%S')</span><br><span class="line">echo -e "请输入zk的安装目录,不存在脚本自动创建,最后一个/不要写 如/data/apps"</span><br><span class="line">read zkinstallpath</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">创建zk安装的目录</span></span><br><span class="line">if [ ! -d $zkinstallpath ]; then</span><br><span class="line">   mkdir -p $zkinstallpath</span><br><span class="line">fi </span><br><span class="line">if [ ! -d $zkinstallpath ]; then</span><br><span class="line">  echo "创建目录$zkinstallpath失败！请检查目录是否有权限"</span><br><span class="line">  exit:</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">解压tar包</span></span><br><span class="line">currentdir=$(cd $(dirname $0); pwd)</span><br><span class="line">ls | grep 'zookeeper-.*[gz]$'</span><br><span class="line">if [ $? -ne 0 ]; then</span><br><span class="line">   #当前目录没有zk的压缩包</span><br><span class="line">   echo "在$currentdir下没有发现zookeeper的gz压缩包,请自行上传!"</span><br><span class="line">   exit</span><br><span class="line">else</span><br><span class="line">   #解压</span><br><span class="line">   tar -zxvf $currentdir/$(ls | grep 'zookeeper-.*[gz]$') -C $zkinstallpath</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">zkversion=`ls $zkinstallpath| grep 'zookeeper-.*'`</span><br><span class="line"></span><br><span class="line">confpath=$zkinstallpath/$zkversion/conf</span><br><span class="line"></span><br><span class="line">cp $confpath/zoo_sample.cfg  $confpath/zoo.cfg</span><br><span class="line"></span><br><span class="line">echo -e "请输入zk数据存储目录：例如 /data/apps/zookeeperapp"</span><br><span class="line">read zkdatapath</span><br><span class="line"><span class="meta">#</span><span class="bash">创建zk数据的目录</span></span><br><span class="line">if [ ! -d $zkdatapath ]; then</span><br><span class="line">   mkdir -p $zkdatapath</span><br><span class="line">fi</span><br><span class="line">if [ ! -d $zkdatapath ]; then</span><br><span class="line">  echo "创建目录$zkdatapath失败！请检查目录是否有权限"</span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">bak_dir='dataDir=/tmp/zookeeper'</span><br><span class="line">new_dir='dataDir='$zkdatapath</span><br><span class="line">sed -i "s!$&#123;bak_dir&#125;!$&#123;new_dir&#125;!g" $confpath/zoo.cfg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo  "请输入所有的zk集群节点：（按照空格分割） 例如 zk01 zk02 zk03"</span><br><span class="line">read zkNodes</span><br><span class="line">array=(`echo $zkNodes | tr ' ' ' '` )</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">末行插入</span></span><br><span class="line">echo ""&gt;&gt;$confpath/zoo.cfg</span><br><span class="line">for i in `seq 0 $(($&#123;#array[@]&#125;-1))`</span><br><span class="line">do</span><br><span class="line"> echo "server.$(($&#123;i&#125;+1))=$&#123;array[$&#123;i&#125;]&#125;:2888:3888" &gt;&gt;$confpath/zoo.cfg</span><br><span class="line">done </span><br><span class="line"></span><br><span class="line">echo  "请输入zk的myid,不能重复,唯一值 例如 1" </span><br><span class="line">read myid</span><br><span class="line">echo $myid &gt; $zkdatapath/myid</span><br><span class="line"></span><br><span class="line">binpath=$zkinstallpath/$zkversion/bin</span><br><span class="line"></span><br><span class="line">sed -i 's/ZOO_LOG_DIR=\".\"/ZOO_LOG_DIR=\"$&#123;ZOOKEEPER_PREFIX&#125;\/logs\"/g' $binpath/zkEnv.sh</span><br><span class="line"></span><br><span class="line">echo "ZOO_LOG_DIR修改成功"</span><br><span class="line"></span><br><span class="line">sed -i 's/ZOO_LOG4J_PROP=\"INFO,CONSOLE\"/ZOO_LOG4J_PROP=\"INFO,ROLLINGFILE\"/g' $binpath/zkEnv.sh</span><br><span class="line">echo "ZOO_LOG4J_PROP修改成功"</span><br><span class="line"></span><br><span class="line">sed -i 's/_ZOO_DAEMON_OUT=\"$ZOO_LOG_DIR\/zookeeper.out\"/_ZOO_DAEMON_OUT=\"$ZOO_LOG_DIR\/zookeeper.log\"/g' $binpath/zkServer.sh</span><br><span class="line">echo "_ZOO_DAEMON_OUT修改成功"</span><br><span class="line"></span><br><span class="line">sed -i 's/zookeeper.root.logger=INFO, CONSOLE/zookeeper.root.logger=INFO, ROLLINGFILE/g' $confpath/log4j.properties</span><br><span class="line">echo "zookeeper.root.logger修改成功"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">PATH设置</span></span><br><span class="line"><span class="meta">#</span><span class="bash">末行插入</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">""</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">"#zookeeper <span class="variable">$currentTime</span>"</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">"export ZK_HOME=<span class="variable">$zkinstallpath</span>/<span class="variable">$zkversion</span>"</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">'export PATH=$PATH:$ZK_HOME/bin'</span>&gt;&gt;~/.bash_profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">source</span> ~/.bash_profile</span></span><br><span class="line"></span><br><span class="line">echo -e "是否远程复制 请输入y/n"</span><br><span class="line">read flag</span><br><span class="line">if [[ $flag == "y" ]]; then</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改并分发安装文件</span></span><br><span class="line">zkpath=$zkinstallpath/$zkversion</span><br><span class="line">zkpathtemp=$zkinstallpath/$zkversion-temp</span><br><span class="line">cp -r $zkpath $zkpathtemp</span><br><span class="line"></span><br><span class="line">echo "以下输入的节点必须做免密登录"</span><br><span class="line">currentnode=`hostname`</span><br><span class="line">echo -e '请输入除当前节点之外的节点(当前节点$currentnode),严格符合以下格式hostname:zkID,空格隔开， 如zk02:2 zk03:3 zk04:4 zk05:5 zk06:6'</span><br><span class="line">read allnodes</span><br><span class="line">user=`whoami`</span><br><span class="line">array2=($&#123;allnodes// / &#125;)</span><br><span class="line">for allnode in $&#123;array2[@]&#125;</span><br><span class="line">do</span><br><span class="line"> array3=($&#123;allnode//:/ &#125;)</span><br><span class="line"> hostname=$&#123;array3[0]&#125;</span><br><span class="line"> zkid=$&#123;array3[1]&#125;</span><br><span class="line"> echo ======= $hostname  =======</span><br><span class="line"> </span><br><span class="line"><span class="meta"> #</span><span class="bash">修改文件</span></span><br><span class="line"> ssh $hostname "mkdir -p $zkpath"</span><br><span class="line"> ssh $hostname "mkdir -p $zkdatapath"</span><br><span class="line"></span><br><span class="line"><span class="meta"> #</span><span class="bash">修改zk的myid唯一值</span></span><br><span class="line"> ssh $hostname "echo $zkid &gt; $zkdatapath/myid"</span><br><span class="line"></span><br><span class="line"> scp -r $zkpathtemp/* $&#123;user&#125;@$hostname:$zkpath/</span><br><span class="line"></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$hostname</span> <span class="string">"echo ''&gt;&gt;~/.bash_profile"</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$hostname</span> <span class="string">"echo '#zk <span class="variable">$currentTime</span>'&gt;&gt;~/.bash_profile"</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$hostname</span> <span class="string">"echo 'export ZK_HOME=<span class="variable">$zkinstallpath</span>/<span class="variable">$zkversion</span>'&gt;&gt;~/.bash_profile"</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$hostname</span> <span class="string">'echo "export PATH=\$PATH:\$ZK_HOME/bin"&gt;&gt;~/.bash_profile'</span></span></span><br><span class="line"><span class="meta"> #</span><span class="bash">ssh <span class="variable">$hostname</span> <span class="string">"source ~/.bash_profile"</span></span></span><br><span class="line"></span><br><span class="line"> echo ======= $hostname 远程复制完成  =======</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删除临时文件</span></span><br><span class="line">rm -rf $zkpathtemp</span><br><span class="line"></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line">echo "退出当前程序！"</span><br><span class="line">exit</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      本文主要讲述kafka_2.11-0.11.0.1和Zookeeper-3.4.10整合搭建Kafka集群以及监控平台的全套流程。
    
    </summary>
    
      <category term="消息中间件" scheme="https://gjtmaster.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="Kafka" scheme="https://gjtmaster.github.io/tags/Kafka/"/>
    
      <category term="消息中间件" scheme="https://gjtmaster.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>JsonSchema全套解决方案</title>
    <link href="https://gjtmaster.github.io/2018/08/17/JsonSchema%E5%85%A8%E5%A5%97%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://gjtmaster.github.io/2018/08/17/JsonSchema全套解决方案/</id>
    <published>2018-08-17T03:34:28.000Z</published>
    <updated>2019-07-26T15:36:32.110Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h1 id="Json-Schema说明"><a href="#Json-Schema说明" class="headerlink" title="Json Schema说明"></a>Json Schema说明</h1><ol><li>json schema 本身也是一个json串；</li><li>每个schema可以描述一个json实例，并且该json实例里每一个节点都可以用一个schema来描述，因此schema与json一样，本身也是一个层级结构，一个schema中可能嵌套着另外若干层schema；</li><li>json schema 定义的检查规则以数据格式验证为主（字段存在性、字段类型），并可以支持一些简单的数据正确性验证（例如数值范围、字符串的模式等），但不能进行复杂的逻辑校验（例如进价必须小于售价等）；</li></ol><h1 id="Json-Schema-格式"><a href="#Json-Schema-格式" class="headerlink" title="Json Schema 格式"></a>Json Schema 格式</h1><p>Json schema 本身遵循Json规范，本身就是一个Json字符串，先来看一个例子</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"$schema"</span>: <span class="string">"http://json-schema.org/draft-04/schema#"</span>,</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"Product"</span>,</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"A product from Acme's catalog"</span>,</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"The unique identifier for a product"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"integer"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"name"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name of the product"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"price"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"number"</span>,</span><br><span class="line">            <span class="attr">"minimum"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="attr">"exclusiveMinimum"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"required"</span>: [<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"price"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们来看一下json schema 最外层包含以下几个字段</p><table><thead><tr><th>$schema</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>$schema</td><td>$schema 关键字状态，表示这个模式与 v4 规范草案书写一致。</td><td></td></tr><tr><td>title</td><td>标题，用来描述结构</td><td></td></tr><tr><td>description</td><td>描述</td><td></td></tr><tr><td>type</td><td>类型</td><td>.</td></tr><tr><td>properties</td><td>定义属性</td><td></td></tr><tr><td>required</td><td>必需属性</td><td></td></tr></tbody></table><p>上面只是一个简单的例子，从上面可以看出Json schema 本身是一个JSON字符串，由通过key-value的形式进行标示。<br>type 和 properties 用来定义json 属性的类型。required 是对Object字段的必段性进行约束。事实上,json Schema定义了json所支持的类型，每种类型都有0-N种约束方式。下一节我们来，细致介绍一下。</p><hr><h1 id="Json-Schema-类型"><a href="#Json-Schema-类型" class="headerlink" title="Json Schema 类型"></a>Json Schema 类型</h1><h2 id="Object"><a href="#Object" class="headerlink" title="Object"></a>Object</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"$schema"</span>: <span class="string">"http://json-schema.org/draft-04/schema#"</span>,</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"Product"</span>,</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"A product from Acme's catalog"</span>,</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"The unique identifier for a product"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"integer"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"name"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name of the product"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"price"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"number"</span>,</span><br><span class="line">            <span class="attr">"minimum"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="attr">"exclusiveMinimum"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"required"</span>: [<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"price"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>object类型有三个关键字:type（限定类型）,properties(定义object的各个字段),required（限定必需字段）,如下：</p><table><thead><tr><th>关键字</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>type</td><td>类型</td><td>.</td></tr><tr><td>properties</td><td>定义属性</td><td></td></tr><tr><td>required</td><td>必需属性</td><td></td></tr><tr><td>maxProperties</td><td>最大属性个数</td><td></td></tr><tr><td>minProperties</td><td>最小属性个数</td><td></td></tr><tr><td>additionalProperties</td><td>true or false or object</td><td><a href="https://link.jianshu.com/?t=https://spacetelescope.github.io/understanding-json-schema/reference/object.html" target="_blank" rel="noopener">参考</a></td></tr></tbody></table><p>properties 定义每个属性的名字和类型，方式如上例。</p><h2 id="array"><a href="#array" class="headerlink" title="array"></a>array</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"$schema"</span>: <span class="string">"http://json-schema.org/draft-04/schema#"</span>,</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"Product"</span>,</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"A product from Acme's catalog"</span>,</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"array"</span>,</span><br><span class="line">    <span class="attr">"items"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">     &#125;,</span><br><span class="line">     <span class="attr">"minItems"</span>: <span class="number">1</span>,</span><br><span class="line">     <span class="attr">"uniqueItems"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>array有三个单独的属性:items,minItems,uniqueItems:</p><table><thead><tr><th>关键字</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>items</td><td>array 每个元素的类型</td><td>.</td></tr><tr><td>minItems</td><td>约束属性，数组最小的元素个数</td><td></td></tr><tr><td>maxItems</td><td>约束属性，数组最大的元素个数</td><td></td></tr><tr><td>uniqueItems</td><td>约束属性，每个元素都不相同</td><td></td></tr><tr><td>additionalProperties</td><td>约束items的类型，不建议使用</td><td><a href="https://link.jianshu.com/?t=https://spacetelescope.github.io/understanding-json-schema/reference/array.html" target="_blank" rel="noopener">示例</a></td></tr><tr><td>Dependencies</td><td>属性依赖</td><td><a href="https://link.jianshu.com/?t=https://spacetelescope.github.io/understanding-json-schema/reference/object.html?highlight=additionalproperties" target="_blank" rel="noopener">用法</a></td></tr><tr><td>patternProperties</td><td></td><td><a href="https://link.jianshu.com/?t=https://spacetelescope.github.io/understanding-json-schema/reference/object.html?highlight=patternproperties" target="_blank" rel="noopener">用法</a></td></tr></tbody></table><h2 id="string"><a href="#string" class="headerlink" title="string"></a>string</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">"$schema"</span>: <span class="string">"http://json-schema.org/draft-04/schema#"</span>,</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"Product"</span>,</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"A product from Acme's catalog"</span>,</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"ip"</span>: &#123;</span><br><span class="line">            <span class="attr">"mail"</span>: <span class="string">"string"</span>,</span><br><span class="line">            <span class="attr">"pattern"</span>:<span class="string">"w+([-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"host"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"phoneNumber"</span>,</span><br><span class="line">            <span class="attr">"pattern"</span>:<span class="string">"((d&#123;3,4&#125;)|d&#123;3,4&#125;-)?d&#123;7,8&#125;(-d&#123;3&#125;)*"</span></span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"required"</span>: [<span class="string">"ip"</span>, <span class="string">"host"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th>关键字</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>maxLength</td><td>定义字符串的最大长度，&gt;=0</td><td>.</td></tr><tr><td>minLength</td><td>定义字符串的最小长度，&gt;=0</td><td></td></tr><tr><td>pattern</td><td>用正则表达式约束字符串</td><td></td></tr></tbody></table><h2 id="integer"><a href="#integer" class="headerlink" title="integer"></a>integer</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"$schema"</span>: <span class="string">"http://json-schema.org/draft-04/schema#"</span>,</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"Product"</span>,</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"A product from Acme's catalog"</span>,</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"name"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name of the product"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"price"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"integer"</span>,</span><br><span class="line">            <span class="attr">"minimum"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="attr">"exclusiveMinimum"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"required"</span>: [<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"price"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th>关键字</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>minimum</td><td>最小值</td><td>.</td></tr><tr><td>exclusiveMinimum</td><td>如果存在 “exclusiveMinimum” 并且具有布尔值 true，如果它严格意义上大于 “minimum” 的值则实例有效。</td><td></td></tr><tr><td>maximum</td><td>约束属性，最大值</td><td></td></tr><tr><td>exclusiveMaximum</td><td>如果存在 “exclusiveMinimum” 并且具有布尔值 true，如果它严格意义上小于 “maximum” 的值则实例有效。</td><td></td></tr><tr><td>multipleOf</td><td>是某数的倍数，必须大于0的整数</td><td></td></tr></tbody></table><h2 id="number"><a href="#number" class="headerlink" title="number"></a>number</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"$schema"</span>: <span class="string">"http://json-schema.org/draft-04/schema#"</span>,</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"Product"</span>,</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"A product from Acme's catalog"</span>,</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"name"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name of the product"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"price"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"number"</span>,</span><br><span class="line">            <span class="attr">"minimum"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="attr">"exclusiveMinimum"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"required"</span>: [<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"price"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>number 关键字可以描述任意长度，任意小数点的数字。number类型的约束有以下几个：</p><table><thead><tr><th>关键字</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>minimum</td><td>最小值</td><td>.</td></tr><tr><td>exclusiveMinimum</td><td>如果存在 “exclusiveMinimum” 并且具有布尔值 true，如果它严格意义上大于 “minimum” 的值则实例有效。</td><td></td></tr><tr><td>maximum</td><td>约束属性，最大值</td><td></td></tr><tr><td>exclusiveMaximum</td><td>如果存在 “exclusiveMinimum” 并且具有布尔值 true，如果它严格意义上小于 “maximum” 的值则实例有效。</td><td></td></tr></tbody></table><h2 id="boolean"><a href="#boolean" class="headerlink" title="boolean"></a>boolean</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">  <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    <span class="attr">"number"</span>:      &#123; <span class="attr">"type"</span>: <span class="string">"boolean"</span> &#125;,</span><br><span class="line">    <span class="attr">"street_name"</span>: &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125;,</span><br><span class="line">    <span class="attr">"street_type"</span>: &#123; <span class="attr">"type"</span>: <span class="string">"string"</span>,</span><br><span class="line">                     <span class="attr">"enum"</span>: [<span class="string">"Street"</span>, <span class="string">"Avenue"</span>, <span class="string">"Boulevard"</span>]</span><br><span class="line">                   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>true or false</p><h2 id="enum"><a href="#enum" class="headerlink" title="enum"></a>enum</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">  <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    <span class="attr">"number"</span>:      &#123; <span class="attr">"type"</span>: <span class="string">"number"</span> &#125;,</span><br><span class="line">    <span class="attr">"street_name"</span>: &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125;,</span><br><span class="line">    <span class="attr">"street_type"</span>: &#123; <span class="attr">"type"</span>: <span class="string">"string"</span>,</span><br><span class="line">                     <span class="attr">"enum"</span>: [<span class="string">"Street"</span>, <span class="string">"Avenue"</span>, <span class="string">"Boulevard"</span>]</span><br><span class="line">                   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以这么做</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">  <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    <span class="attr">"number"</span>:      &#123; <span class="attr">"type"</span>: <span class="string">"number"</span> &#125;,</span><br><span class="line">    <span class="attr">"street_name"</span>: &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125;,</span><br><span class="line">    <span class="attr">"street_type"</span>: [<span class="string">"Street"</span>, <span class="string">"Avenue"</span>, <span class="string">"Boulevard"</span>]                   </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="null"><a href="#null" class="headerlink" title="null"></a>null</h2><h1 id="Json-Schema进阶"><a href="#Json-Schema进阶" class="headerlink" title="Json Schema进阶"></a>Json Schema进阶</h1><p>了解了上面的各个类型的定义及约定条件，就可以满足大部分情况了。但为了写出更好的json schema,我们再学习几个关键字</p><h2 id="ref"><a href="#ref" class="headerlink" title="$ref"></a>$ref</h2><p>$ref 用来引用其它schema,<br>示例如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"$schema"</span>: <span class="string">"http://json-schema.org/draft-04/schema#"</span>,</span><br><span class="line">    <span class="attr">"title"</span>: <span class="string">"Product set"</span>,</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"array"</span>,</span><br><span class="line">    <span class="attr">"items"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Product"</span>,</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">            <span class="attr">"id"</span>: &#123;</span><br><span class="line">                <span class="attr">"description"</span>: <span class="string">"The unique identifier for a product"</span>,</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"number"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"name"</span>: &#123;</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"price"</span>: &#123;</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"number"</span>,</span><br><span class="line">                <span class="attr">"minimum"</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="attr">"exclusiveMinimum"</span>: <span class="literal">true</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"tags"</span>: &#123;</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"array"</span>,</span><br><span class="line">                <span class="attr">"items"</span>: &#123;</span><br><span class="line">                    <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"minItems"</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="attr">"uniqueItems"</span>: <span class="literal">true</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"dimensions"</span>: &#123;</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">                <span class="attr">"properties"</span>: &#123;</span><br><span class="line">                    <span class="attr">"length"</span>: &#123;<span class="attr">"type"</span>: <span class="string">"number"</span>&#125;,</span><br><span class="line">                    <span class="attr">"width"</span>: &#123;<span class="attr">"type"</span>: <span class="string">"number"</span>&#125;,</span><br><span class="line">                    <span class="attr">"height"</span>: &#123;<span class="attr">"type"</span>: <span class="string">"number"</span>&#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"required"</span>: [<span class="string">"length"</span>, <span class="string">"width"</span>, <span class="string">"height"</span>]</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"warehouseLocation"</span>: &#123;</span><br><span class="line">                <span class="attr">"description"</span>: <span class="string">"Coordinates of the warehouse with the product"</span>,</span><br><span class="line">                <span class="attr">"$ref"</span>: <span class="string">"http://json-schema.org/geo"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"required"</span>: [<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"price"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="definitions"><a href="#definitions" class="headerlink" title="definitions"></a>definitions</h2><p>当一个schema写的很大的时候，可能需要创建内部结构体，再使用$ref进行引用，示列如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"array"</span>,</span><br><span class="line">    <span class="attr">"items"</span>: &#123; <span class="attr">"$ref"</span>: <span class="string">"#/definitions/positiveInteger"</span> &#125;,</span><br><span class="line">    <span class="attr">"definitions"</span>: &#123;</span><br><span class="line">        <span class="attr">"positiveInteger"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"integer"</span>,</span><br><span class="line">            <span class="attr">"minimum"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="attr">"exclusiveMinimum"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="allOf"><a href="#allOf" class="headerlink" title="allOf"></a>allOf</h2><p>意思是展示全部属性，建议用requires替代</p><p>不建议使用，示例如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"definitions"</span>: &#123;</span><br><span class="line">    <span class="attr">"address"</span>: &#123;</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">      <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"street_address"</span>: &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125;,</span><br><span class="line">        <span class="attr">"city"</span>:           &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125;,</span><br><span class="line">        <span class="attr">"state"</span>:          &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"required"</span>: [<span class="string">"street_address"</span>, <span class="string">"city"</span>, <span class="string">"state"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"allOf"</span>: [</span><br><span class="line">    &#123; <span class="attr">"$ref"</span>: <span class="string">"#/definitions/address"</span> &#125;,</span><br><span class="line">    &#123; <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: &#123; <span class="attr">"enum"</span>: [ <span class="string">"residential"</span>, <span class="string">"business"</span> ] &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="anyOf"><a href="#anyOf" class="headerlink" title="anyOf"></a>anyOf</h2><p>意思是展示任意属性，建议用requires替代和minProperties替代，示例如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"anyOf"</span>: [</span><br><span class="line">    &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125;,</span><br><span class="line">    &#123; <span class="attr">"type"</span>: <span class="string">"number"</span> &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="oneOf"><a href="#oneOf" class="headerlink" title="oneOf"></a>oneOf</h2><p>其中之一</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"oneOf"</span>: [</span><br><span class="line">    &#123; <span class="attr">"type"</span>: <span class="string">"number"</span>, <span class="attr">"multipleOf"</span>: <span class="number">5</span> &#125;,</span><br><span class="line">    &#123; <span class="attr">"type"</span>: <span class="string">"number"</span>, <span class="attr">"multipleOf"</span>: <span class="number">3</span> &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="not"><a href="#not" class="headerlink" title="not"></a>not</h2><p>非 * 类型<br>示例</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; <span class="attr">"not"</span>: &#123; <span class="attr">"type"</span>: <span class="string">"string"</span> &#125; &#125;</span><br></pre></td></tr></table></figure><h1 id="Java-Json-Schema库"><a href="#Java-Json-Schema库" class="headerlink" title="Java Json Schema库"></a>Java Json Schema库</h1><p>表中给出了两种java中使用的JSON Schema库</p><table><thead><tr><th>库名称</th><th>地址</th><th>支持草案</th></tr></thead><tbody><tr><td>fge</td><td><a href="https://github.com/daveclayton/json-schema-validator" target="_blank" rel="noopener">https://github.com/daveclayton/json-schema-validator</a></td><td>draft-04 draft-03</td></tr><tr><td>everit</td><td><a href="https://github.com/everit-org/json-schema" target="_blank" rel="noopener">https://github.com/everit-org/json-schema</a></td><td>draft-04</td></tr></tbody></table><p>建议：</p><ol><li><p>如果在项目中使用了jackson json，那么使用fge是一个好的选择，因为fge就是使用的jackson json。</p></li><li><p>如果项目中使用的是org.json API，那么使用everit会更好。</p></li><li><p>如果是使用以上两个库以外的库，那么就使用everit，因为everit会比fge的性能好上两倍。</p></li></ol><h2 id="fge的使用："><a href="#fge的使用：" class="headerlink" title="fge的使用："></a>fge的使用：</h2><p>maven配置</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;2.3.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;2.3.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;2.3.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;com.github.fge&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;json-schema-validator&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;2.2.6&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>测试代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testJsonSchema1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  JsonNode schema = readJsonFile(<span class="string">"src/main/resources/Schema.json"</span>);</span><br><span class="line">  JsonNode data = readJsonFile(<span class="string">"src/main/resources/failure.json"</span>);</span><br><span class="line">  ProcessingReport report = JsonSchemaFactory.byDefault().getValidator().validateUnchecked(schema, data);</span><br><span class="line">  Assert.assertTrue(report.isSuccess());</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> JsonNode <span class="title">readJsonFile</span><span class="params">(String filePath)</span> </span>&#123;</span><br><span class="line">  JsonNode instance = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">instance = <span class="keyword">new</span> JsonNodeReader().fromReader(<span class="keyword">new</span> FileReader(filePath));</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>真正的调用只有一行代码，需要传入验证规则和数据。分别有validate和validateUnchecked两种方法，区别在于validateUnchecked方法不会抛出ProcessingException异常。</p><p>还可以从字符串中读取json，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testJsonSchema2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  String failure = <span class="keyword">new</span> String(<span class="string">"&#123;\"foo\":1234&#125;"</span>);</span><br><span class="line">  String Schema = <span class="string">"&#123;\"type\": \"object\", \"properties\" : &#123;\"foo\" : &#123;\"type\" : \"string\"&#125;&#125;&#125;"</span>;</span><br><span class="line">  ProcessingReport report = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">JsonNode data = JsonLoader.fromString(failure);</span><br><span class="line">JsonNode schema = JsonLoader.fromString(Schema);</span><br><span class="line">report = JsonSchemaFactory.byDefault().getValidator().validateUnchecked(schema, data);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//Assert.assertTrue(report.isSuccess());</span></span><br><span class="line">  Iterator&lt;ProcessingMessage&gt; it = report.iterator();</span><br><span class="line">  <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">System.out.println(it.next());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中ProcessingReport对象中维护了一共迭代器，如果执行失败（执行成功时没有信息），其提供了一些高级故障信息。每个错误可能包含以下属性：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">level: 错误级别（应该就是error）</span><br><span class="line">schema：引起故障的模式的所在位置的 URI</span><br><span class="line">instance：错误对象</span><br><span class="line">domain：验证域</span><br><span class="line">keyword：引起错误的约束key</span><br><span class="line">found：现在类型</span><br><span class="line">expected：期望类型</span><br></pre></td></tr></table></figure><p>以上代码的json信息为：</p><p>failure.json ：  </p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"foo"</span> : <span class="number">1234</span>&#125;</span><br></pre></td></tr></table></figure><p>Schema.json ：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"type"</span>: <span class="string">"object"</span>,</span><br><span class="line">  <span class="string">"properties"</span> : &#123;</span><br><span class="line">    <span class="string">"foo"</span> : &#123;</span><br><span class="line">      <span class="string">"type"</span> : <span class="string">"string"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行错误信息为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">error: <span class="function">instance <span class="title">type</span> <span class="params">(integer)</span> does not match any allowed primitive <span class="title">type</span> <span class="params">(allowed: [<span class="string">"string"</span>])</span></span></span><br><span class="line"><span class="function">level: "error"</span></span><br><span class="line"><span class="function">schema: </span>&#123;<span class="string">"loadingURI"</span>:<span class="string">"#"</span>,<span class="string">"pointer"</span>:<span class="string">"/properties/foo"</span>&#125;</span><br><span class="line">instance: &#123;<span class="string">"pointer"</span>:<span class="string">"/foo"</span>&#125;</span><br><span class="line">domain: <span class="string">"validation"</span></span><br><span class="line">keyword: <span class="string">"type"</span></span><br><span class="line">found: <span class="string">"integer"</span></span><br><span class="line">expected: [<span class="string">"string"</span>]</span><br></pre></td></tr></table></figure><h2 id="everit的使用："><a href="#everit的使用：" class="headerlink" title="everit的使用："></a>everit的使用：</h2><p>maven配置</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.everit.json&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;org.everit.json.schema&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.3.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>测试代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testJsonSchema3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  InputStream inputStream = getClass().getResourceAsStream(<span class="string">"/Schema.json"</span>);</span><br><span class="line">  JSONObject Schema = <span class="keyword">new</span> JSONObject(<span class="keyword">new</span> JSONTokener(inputStream));</span><br><span class="line">  JSONObject data = <span class="keyword">new</span> JSONObject(<span class="string">"&#123;\"foo\" : 1234&#125;"</span>);</span><br><span class="line">  Schema schema = SchemaLoader.load(Schema);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">schema.validate(data);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (ValidationException e) &#123;</span><br><span class="line">System.out.println(e.getMessage());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果验证失败会抛出一个ValidationException异常，然后在catch块中打印出错误信息。everit中的错误信息想比fge来说比较简单，相同的json测试文件，打印的信息如下：</p><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#/foo: expected <span class="keyword">type</span>: <span class="built_in">String</span>, found: <span class="built_in">Integer</span></span><br></pre></td></tr></table></figure><p>此外everit提供了一个format关键字，可以自定义validator来校验json中一些复杂数据，比如IP地址，电话号码等。具体请参考官方文档。</p><h2 id="性能测试："><a href="#性能测试：" class="headerlink" title="性能测试："></a>性能测试：</h2><p>1、一共执行1000次，成功和失败分开执行，每种情况执行250次。然后记录下每次的执行时间，执行10次，取平均值。</p><p>fge每1000次的执行时间(ms)：1158, 1122, 1120, 1042, 1180, 1254, 1198，1126，1177，1192<br>everit每1000次的执行时间(ms)：33, 49, 54, 57, 51, 47, 48, 52, 53, 44</p><p>2、一共执行10000次，成功和失败分开执行，每种情况执行2500次。</p><table><thead><tr><th>方法/场景</th><th>每次执行时间(ms)</th></tr></thead><tbody><tr><td>fge/场景1</td><td>1.1569</td></tr><tr><td>fge/场景2</td><td>0.3407</td></tr><tr><td>everit/场景1</td><td>0.0488</td></tr><tr><td>everit/场景2</td><td>0.0206</td></tr></tbody></table><p><strong>使用对比：</strong></p><p>​    从性能上来说everit完全是碾压fge，官方说的至少两倍，实际测试过程中，差不多有20倍的差距。虽然fge使用的是jackson json，相对来说学习成本可能较低，但是使用下来发现everit的使用也并不复杂，需要注意的是包需要导入正确（org.json）。fge唯一的优势在于错误信息比较详细。还有一点区别在于，everit验证失败是抛出异常，而fge是判断返回一个boolean类型的值。</p>]]></content>
    
    <summary type="html">
    
      JSON schema是一个帮助你定义、校验甚至是修复json数据格式的解决方案。它定义了一整套规则，允许我们通过定义一个schema(本身也是JSON)来描述一个JSON串的数据格式。
    
    </summary>
    
      <category term="数据存储格式" scheme="https://gjtmaster.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/"/>
    
    
      <category term="Json" scheme="https://gjtmaster.github.io/tags/Json/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7 命令行静默安装部署oracle11g数据库</title>
    <link href="https://gjtmaster.github.io/2017/12/10/CentOS%207%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%9D%99%E9%BB%98%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2oracle11g%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <id>https://gjtmaster.github.io/2017/12/10/CentOS 7 命令行静默安装部署oracle11g数据库/</id>
    <published>2017-12-10T02:45:58.000Z</published>
    <updated>2019-08-18T03:53:12.043Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备Oracle-11g安装包"><a href="#准备Oracle-11g安装包" class="headerlink" title="准备Oracle 11g安装包"></a>准备Oracle 11g安装包</h2><p><a href="https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html" target="_blank" rel="noopener">官方下载地址</a></p><h2 id="检查硬件需求"><a href="#检查硬件需求" class="headerlink" title="检查硬件需求"></a>检查硬件需求</h2><ol><li>查看系统物理内存,以下输出可以看出，有8G的内存，内存最低要求256M。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep MemTotal /proc/meminfo</span><br></pre></td></tr></table></figure><ol start="2"><li>查看交换空间大小,以下输出可以看出，有5G的交换空间，交换空间的最优设置与你物理内存大小相关，详细说明请参考安装文档</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep SwapTotal /proc/meminfo</span><br></pre></td></tr></table></figure><h2 id="本来的交换空间大小为0，所以重新设置，有以下步骤："><a href="#本来的交换空间大小为0，所以重新设置，有以下步骤：" class="headerlink" title="本来的交换空间大小为0，所以重新设置，有以下步骤："></a>本来的交换空间大小为0，所以重新设置，有以下步骤：</h2><p>关闭swap：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo swapoff -a</span><br></pre></td></tr></table></figure><p>设置swap的大小：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudd dd if=/dev/zero of=/swapfile bs=1M count=5120</span><br></pre></td></tr></table></figure><p>bs指的是Block Size，就是每一块的大小。这里的例子是1M，意思就是count的数字，是以1M为单位的。<br>count是告诉程序，新的swapfile要多少个block。这里是1024，就是说，新的swap文件是5G大小。<br>注意：有些公司的权限需要重新输入密码，而我们就是这样，输入后会看见卡在那里没动，请耐心等待，机器不一样，等待时间也不一样。</p><p>把增大后的文件变为swap文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkswap /swapfile</span><br></pre></td></tr></table></figure><p>重新打开swap：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo swapon  /swapfile</span><br></pre></td></tr></table></figure><p>让swap在启动的时候，自动生效。打开/etc/fstab文件，加上以下命令。然后保存。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /etc</span><br><span class="line">sudo vim fstab</span><br></pre></td></tr></table></figure><p>因为我的权限不是root权限，所以输入命令前必须加sudo才可以修改资料</p><p>附Linux编辑文件命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vi打开一个文件时，进入的是阅读模式，只有输入相关命令才会进入编辑模式：</span><br><span class="line">i :在当前位置插入</span><br><span class="line">a:在当前位置后追加</span><br><span class="line">o:在当前位置的后面插入一行</span><br><span class="line">I :在行头插入</span><br><span class="line">A:在行尾追加</span><br><span class="line">O:在当前位置的前面插入一行</span><br><span class="line">'ESC'键从编辑模式转换到阅读模式</span><br><span class="line">阅读模式（或叫命令模式）下：</span><br><span class="line">:w 保存文件</span><br><span class="line">:w filename 保存成filename文件</span><br><span class="line">:q 退出</span><br><span class="line">:q! 强行退出</span><br><span class="line">:w! 强行写</span><br><span class="line">:wq 保存退出</span><br><span class="line">:x 同wq</span><br></pre></td></tr></table></figure><p>在fstab文件加入这行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/swapfile swap swap default 0 0</span><br></pre></td></tr></table></figure><p>保存退出，再次查swap大小,就发现变成5g了</p><h2 id="查当前发行版本检查并安装依赖包："><a href="#查当前发行版本检查并安装依赖包：" class="headerlink" title="查当前发行版本检查并安装依赖包："></a>查当前发行版本检查并安装依赖包：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/redhat-release</span><br></pre></td></tr></table></figure><p>发现是7.2的，需要安装包如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> binutils-2.23.52.0.1-12.el7.x86_64</span><br><span class="line"><span class="meta">#</span> compat-libcap1-1.10-3.el7.x86_64</span><br><span class="line"><span class="meta">#</span> gcc-4.8.2-3.el7.x86_64</span><br><span class="line"><span class="meta">#</span> gcc-c++-4.8.2-3.el7.x86_64</span><br><span class="line"><span class="meta">#</span> glibc-2.17-36.el7.i686</span><br><span class="line"><span class="meta">#</span> glibc-2.17-36.el7.x86_64</span><br><span class="line"><span class="meta">#</span> glibc-devel-2.17-36.el7.i686</span><br><span class="line"><span class="meta">#</span> glibc-devel-2.17-36.el7.x86_64</span><br><span class="line"><span class="meta">#</span> ksh</span><br><span class="line"><span class="meta">#</span> libaio-0.3.109-9.el7.i686</span><br><span class="line"><span class="meta">#</span> libaio-0.3.109-9.el7.x86_64</span><br><span class="line"><span class="meta">#</span> libaio-devel-0.3.109-9.el7.i686</span><br><span class="line"><span class="meta">#</span> libaio-devel-0.3.109-9.el7.x86_64</span><br><span class="line"><span class="meta">#</span> libgcc-4.8.2-3.el7.i686</span><br><span class="line"><span class="meta">#</span> libgcc-4.8.2-3.el7.x86_64</span><br><span class="line"><span class="meta">#</span> libstdc++-4.8.2-3.el7.i686</span><br><span class="line"><span class="meta">#</span> libstdc++-4.8.2-3.el7.x86_64</span><br><span class="line"><span class="meta">#</span> libstdc++-devel-4.8.2-3.el7.i686</span><br><span class="line"><span class="meta">#</span> libstdc++-devel-4.8.2-3.el7.x86_64</span><br><span class="line"><span class="meta">#</span> libXi-1.7.2-1.el7.i686</span><br><span class="line"><span class="meta">#</span> libXi-1.7.2-1.el7.x86_64 libXtst-1.2.2-1.el7.i686</span><br><span class="line"><span class="meta">#</span> libXtst-1.2.2-1.el7.x86_64</span><br><span class="line"><span class="meta">#</span> make-3.82-19.el7.x86_64</span><br><span class="line"><span class="meta">#</span> sysstat-10.1.5-1.el7.x86_64</span><br></pre></td></tr></table></figure><p>我安装的版本是有安装包的，所以版本不一样</p><p>检查安装oracle11g所需要的安装包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -q install binutils compat-libcap1  gcc gcc-c++ glibc glibc glibc-devel glibc-devel ksh libaio libaio libaio-devel libaio-devel libgcc libstdc++ libstdc++ libstdc++-devel libstdc++-devel libXi libXi libXtst libXtst sysstat</span><br></pre></td></tr></table></figure><p>或：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -q binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ glibc glibc-devel ksh libaio libaio-devel libgcc libstdc++ libstdc++-devel libXi libXtst  make sysstat  unixODBC unixODBC-devel</span><br></pre></td></tr></table></figure><p>单独检查：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -q 包名</span><br></pre></td></tr></table></figure><p>单独安装： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y 包名</span><br></pre></td></tr></table></figure><p>注意：安装 elfutils-libelf-devel 时候，因为存在互相依存关系，需要2个同时安装（这个我也是参考别人的，我也没试过怎么 搞，所以我也直接用下面的几条安装命令，安装比较多的包，再安装剩下单独）。</p><p>多包安装：</p><p><strong>命令(强烈推荐使用yum安装)：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y binutils compat-libcap1 gcc gcc-c++ glibc glibc glibc-devel glibc-devel ksh libaio libaio libaio-devel libaio-devel libgcc libstdc++ libstdc++ libstdc++-devel libstdc++-devel libXi libXi libXtst libXtst sysstat</span><br></pre></td></tr></table></figure><p>或：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -q binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ glibc glibc-devel ksh libaio libaio-devel libgcc libstdc++ libstdc++-devel libXi libXtst  make sysstat  unixODBC unixODBC-devel</span><br></pre></td></tr></table></figure><p>发现下图最后ksh没安装就可以使用单独安装命令，以上命令没有权限时加 sudo 或者登录root权限安装，因地而异。</p><p>发现找不到ksh这个包，报以下错误：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile No package ksh available.</span><br></pre></td></tr></table></figure><p>只好查百度了，找了很久有很多方法，我这边用的是下载的方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirror.centos.org/centos/7/os/x86_64/Packages/ksh-20120801-137.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><p>附上下载jar包地址的：</p><p><a href="https://altlinux.pkgs.org/sisyphus/classic-x86_64/pdksh-5.2.14-alt5.x86_64.rpm.html" target="_blank" rel="noopener">https://altlinux.pkgs.org/sisyphus/classic-x86_64/pdksh-5.2.14-alt5.x86_64.rpm.html</a><br>接着是安装这个包，进入这个有这个包的目录，wget命令默认下载的文件放在当前目录,附上Linux命令大全地址：</p><p><a href="http://man.linuxde.net/wget" target="_blank" rel="noopener">http://man.linuxde.net/wget</a><br>接着安装这个包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install ksh-20120801-137.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="安装完检查后，有这些包后接着是创建安装oracle和放解压包的文件夹："><a href="#安装完检查后，有这些包后接着是创建安装oracle和放解压包的文件夹：" class="headerlink" title="安装完检查后，有这些包后接着是创建安装oracle和放解压包的文件夹："></a>安装完检查后，有这些包后接着是创建安装oracle和放解压包的文件夹：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> oracle数据库安装目录</span><br><span class="line">sudo mkdir -p /oracledata/data/oracle</span><br><span class="line"><span class="meta">#</span> 数据库配置文件目录</span><br><span class="line">sudo mkdir -p /oracledata/data/oraInventory</span><br><span class="line"><span class="meta">#</span> oracle数据库软件包解压目录</span><br><span class="line">sudo mkdir -p /oracledata/data/database</span><br></pre></td></tr></table></figure><p>检查文件夹是否创建，进入data目录：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll /oracledata/data</span><br></pre></td></tr></table></figure><h2 id="接着是创建oracle用户组和用户："><a href="#接着是创建oracle用户组和用户：" class="headerlink" title="接着是创建oracle用户组和用户："></a>接着是创建oracle用户组和用户：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 创建用户组 oraclesysdba</span><br><span class="line">sudo groupadd oraclesysdba</span><br><span class="line"><span class="meta">#</span> 创建用户组 oraclesysoinstall </span><br><span class="line">sudo groupadd oraclesysoinstall</span><br><span class="line"><span class="meta">#</span> 创建用户组 oraclesysoper</span><br><span class="line">sudo groupadd oraclesysoper</span><br><span class="line"><span class="meta">#</span> 创建oracle用户，并加入到oraclesysoinstall用户组</span><br><span class="line">sudo useradd -g oraclesysoinstall -G oraclesysdba,oraclesysoper oracle</span><br><span class="line"><span class="meta">#</span> 设置oracle用户的登陆密码，需要确认一次，注意两次密码要一样(注意：此处的密码是linux端oracle用户登录密码)</span><br><span class="line">sudo passwd oracle</span><br><span class="line"><span class="meta">#</span> 查看创建的用户：</span><br><span class="line">id oracle</span><br></pre></td></tr></table></figure><p>为啥要创建三个用户组呢？参考：<a href="http://www.oracle.com/technetwork/cn/articles/hunter-rac11gr2-iscsi-2-092412-zhs.html#13" target="_blank" rel="noopener">http://www.oracle.com/technetwork/cn/articles/hunter-rac11gr2-iscsi-2-092412-zhs.html#13</a></p><p>a.oracle 清单组（一般为oinstall):<br> OINSTALL 组的成员被视为 Oracle 软件的“所有者”，拥有对 Oracle 中央清单 (oraInventory) 的写入权限。在一个 Linux 系统上首次安装 Oracle 软件时，OUI 会创建 /etc/oraInst.loc 文件。该文件指定 Oracle 清单组的名称（默认为 oinstall）以及 Oracle 中央清单目录的路径。<br>b.数据库管理员（OSDBA，一般为 dba）:<br> OSDBA 组的成员可通过操作系统身份验证使用 SQL 以 SYSDBA 身份连接到一个 Oracle 实例。该组的成员可执行关键的数据库管理任务，如创建数据库、启动和关闭实例。该组的默认名称为dba。SYSDBA 系统权限甚至在数据库未打开时也允许访问数据库实例。对此权限的控制完全超出了数据库本身的范围。不要混淆 SYSDBA 系统权限与数据库角色 DBA。DBA 角色不包括 SYSDBA 或 SYSOPER 系统权限。<br>c.数据库操作员组（OSOPER，一般为 oper）:<br> OSOPER 组的成员可通过操作系统身份验证使用 SQL 以 SYSOPER 身份连接到一个 Oracle 实例。这个可选组的成员拥有一组有限的数据库管理权限，如管理和运行备份。该组的默认名称为oper。SYSOPER 系统权限甚至在数据库未打开时也允许访问数据库实例。对此权限的控制完全超出了数据库本身的范围。</p><h2 id="设置目录所有者为oraclesysoinstall-用户组的oracle用户"><a href="#设置目录所有者为oraclesysoinstall-用户组的oracle用户" class="headerlink" title="设置目录所有者为oraclesysoinstall 用户组的oracle用户"></a>设置目录所有者为oraclesysoinstall 用户组的oracle用户</h2><p>进入到data的目录，敲以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo chown -R oracle:oraclesysoinstall /oracledata/data/oracle　</span><br><span class="line">sudo chown -R oracle:oraclesysoinstall /oracledata/data/oraInventory</span><br><span class="line">sudo chown -R oracle:oraclesysoinstall /oracledata/data/database</span><br></pre></td></tr></table></figure><h2 id="修改内核参数，以便支持oracle"><a href="#修改内核参数，以便支持oracle" class="headerlink" title="修改内核参数，以便支持oracle"></a>修改内核参数，以便支持oracle</h2><p>进入/etc/sysctl.conf：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /etc</span><br><span class="line">sudo vim sysctl.conf</span><br></pre></td></tr></table></figure><p>在最后增加上以下参数：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kernel<span class="selector-class">.shmall</span> = <span class="number">2097152</span></span><br><span class="line">kernel<span class="selector-class">.shmmax</span> = <span class="number">2147483648</span></span><br><span class="line">kernel<span class="selector-class">.shmmni</span> = <span class="number">4096</span></span><br><span class="line">kernel<span class="selector-class">.sem</span> = <span class="number">250</span> <span class="number">32000</span> <span class="number">100</span> <span class="number">128</span></span><br><span class="line">fs<span class="selector-class">.file-max</span> = <span class="number">65536</span></span><br><span class="line">net<span class="selector-class">.ipv4</span><span class="selector-class">.ip_local_port_range</span> = <span class="number">1024</span> <span class="number">65000</span></span><br><span class="line">net<span class="selector-class">.core</span><span class="selector-class">.rmem_default</span>=<span class="number">262144</span></span><br><span class="line">net<span class="selector-class">.core</span><span class="selector-class">.rmem_max</span>=<span class="number">262144</span></span><br><span class="line">net<span class="selector-class">.core</span><span class="selector-class">.wmem_default</span>=<span class="number">262144</span></span><br><span class="line">net<span class="selector-class">.core</span><span class="selector-class">.wmem_max</span>=<span class="number">262144</span></span><br></pre></td></tr></table></figure><p>执行如下命令使更改的内核生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /sbin/sysctl -p</span><br></pre></td></tr></table></figure><h2 id="修改用户的限制："><a href="#修改用户的限制：" class="headerlink" title="修改用户的限制："></a>修改用户的限制：</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="keyword">vim</span> /etc/security/limits.<span class="keyword">conf</span></span><br></pre></td></tr></table></figure><p>在limits.conf文件中， 使用vim进行编辑，在最后增加上以下参数：</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">oracle soft nproc <span class="number">2047</span>  </span><br><span class="line">oracle hard nproc <span class="number">16384</span>  </span><br><span class="line">oracle soft nofile <span class="number">1024</span>  </span><br><span class="line">oracle hard nofile <span class="number">65536</span>  </span><br><span class="line">oracle soft stack <span class="number">10240</span></span><br></pre></td></tr></table></figure><p>接着在文件/etc/pam.d/login中修改，</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/pam.d/login</span><br></pre></td></tr></table></figure><p>在最后添加以下内容:</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session required /<span class="class"><span class="keyword">lib</span>/<span class="title">security</span>/<span class="title">pam_limits</span>.<span class="title">so</span></span></span><br><span class="line">session required pam_limits.so</span><br></pre></td></tr></table></figure><p>最后在etc/profile添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">$USER</span> = “oracle” ];<span class="keyword">then</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$SHELL</span> = “/bin/ksh”];<span class="keyword">then</span></span><br><span class="line"><span class="built_in">ulimit</span> -p 16384</span><br><span class="line"><span class="built_in">ulimit</span> -n 65536</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">ulimit</span> -u 16384 -n 65536</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>生效命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h2 id="设置环境变量："><a href="#设置环境变量：" class="headerlink" title="设置环境变量："></a>设置环境变量：</h2><p>切记，一定要切换到oracle用户(切换用户一定要是 su-)，然后执行以下命令</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~<span class="string">/.bash_profile</span></span><br></pre></td></tr></table></figure><p>增加以下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> oracle数据库安装目录</span></span><br><span class="line">export ORACLE_BASE=/oracledata/data/oracle</span><br><span class="line">export ORACLE_SID=dbsrv2</span><br></pre></td></tr></table></figure><p>然后使之生效：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><h2 id="接着是解压安装包"><a href="#接着是解压安装包" class="headerlink" title="接着是解压安装包"></a>接着是解压安装包</h2><p>安装zip和unzip组件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y unzip zip</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirror.centos.org/centos/7/os/x86_64/Packages/zip-3.0-11.el7.x86_64.rpm  //zip</span><br><span class="line">wget http://downloads.naulinux.ru/pub/SLCE/7x/x86_64/CyrEd/RPMS//unzip-6.0-15.1.el7.x86_64.rpm </span><br><span class="line">sudo yum install zip-3.0-11.el7.x86_64.rpm</span><br><span class="line">sudo yum install unzip-6.0-15.1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><p>unzip 压缩文件 -c 指定目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unzip p13390677_112040_Linux-x86-64_1of7.zip  -d  /oracledata/data/oraInventory</span><br><span class="line">unzip p13390677_112040_Linux-x86-64_2of7.zip  -d  /oracledata/data/oraInventory</span><br></pre></td></tr></table></figure><p>看到Complete就完成了，然后切换到oracle用户，cd进入解压目录，解压oracle安装包：</p><h2 id="接着是关闭防火墙和selinux"><a href="#接着是关闭防火墙和selinux" class="headerlink" title="接着是关闭防火墙和selinux"></a>接着是关闭防火墙和selinux</h2><p>关闭防火墙是为了其他客户端能够访问到oracle</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看防火墙状态</span></span><br><span class="line">systemctl status firewalld.service</span><br></pre></td></tr></table></figure><p>接着是关闭selinux，查看selinux状态：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usr<span class="regexp">/sbin/</span>sestatus -v</span><br></pre></td></tr></table></figure><p>已经是关闭状态，如果是enforcing ，输入以下命令：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/selinux/<span class="built_in">config</span></span><br></pre></td></tr></table></figure><p>然后进行修改：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELINUX=disabled  //将SELINUX=enforcing 此处修改为SELINUX=disabled</span><br></pre></td></tr></table></figure><p>需重启系统生效</p><h2 id="修改响应文件模板"><a href="#修改响应文件模板" class="headerlink" title="修改响应文件模板"></a>修改响应文件模板</h2><p>1、复制响应文件模板</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /home/oracle/etc</span><br><span class="line">cp /oracledata/data/oraInventory/database/response/* /home/oracle/etc</span><br></pre></td></tr></table></figure><p>2、设置响应文件权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 700 /home/oracle/etc/*.rsp</span><br></pre></td></tr></table></figure><h2 id="修改安装Oracle软件的响应文件-oracledata-data-database-etc-db-install-rsp"><a href="#修改安装Oracle软件的响应文件-oracledata-data-database-etc-db-install-rsp" class="headerlink" title="修改安装Oracle软件的响应文件/oracledata/data/database/etc/db_install.rsp"></a>修改安装Oracle软件的响应文件/oracledata/data/database/etc/db_install.rsp</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="regexp">/home/</span>oracle<span class="regexp">/etc/</span>db_install.rsp</span><br></pre></td></tr></table></figure><p>按照下面修改</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装类型</span></span><br><span class="line">oracle.install.option=INSTALL_DB_SWONLY</span><br><span class="line"><span class="meta">#</span><span class="bash"> 主机名称（hostname查询）</span></span><br><span class="line">ORACLE_HOSTNAME=cdh01</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装组</span></span><br><span class="line">UNIX_GROUP_NAME=oraclesysoinstall</span><br><span class="line"><span class="meta">#</span><span class="bash"> INVENTORY中央库存目录（不填就是默认值）</span></span><br><span class="line">INVENTORY_LOCATION=/home/oracle/oraInventory</span><br><span class="line"><span class="meta">#</span><span class="bash"> 选择语言</span></span><br><span class="line">SELECTED_LANGUAGES=en,zh_CN,zh_TW</span><br><span class="line"><span class="meta">#</span><span class="bash"> oracle_home</span></span><br><span class="line">ORACLE_HOME=/oracledata/data/oracle/product/11.2.0.1</span><br><span class="line"><span class="meta">#</span><span class="bash"> oracle_base</span></span><br><span class="line">ORACLE_BASE=/oracledata/data/oracle</span><br><span class="line"><span class="meta">#</span><span class="bash"> oracle版本</span></span><br><span class="line">oracle.install.db.InstallEdition=EE</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自定义安装，否，使用默认组件</span></span><br><span class="line">oracle.install.db.isCustomInstall=false</span><br><span class="line"><span class="meta">#</span><span class="bash"> dba用户组</span></span><br><span class="line">oracle.install.db.DBA_GROUP= oraclesysdba</span><br><span class="line"><span class="meta">#</span><span class="bash"> oper用户组</span></span><br><span class="line">oracle.install.db.OPER_GROUP=oraclesysoper</span><br><span class="line"><span class="meta">#</span><span class="bash"> 数据库类型</span></span><br><span class="line">oracle.install.db.config.starterdb.type=GENERAL_PURPOSE</span><br><span class="line"><span class="meta">#</span><span class="bash"> globalDBName</span></span><br><span class="line">oracle.install.db.config.starterdb.globalDBName=orcl</span><br><span class="line"><span class="meta">#</span><span class="bash"> SID</span></span><br><span class="line">oracle.install.db.config.starterdb.SID=dbsrv2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自动管理内存的内存(M)</span></span><br><span class="line">oracle.install.db.config.starterdb.memoryLimit=81920</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设定所有数据库用户使用同一个密码</span></span><br><span class="line">oracle.install.db.config.starterdb.password.ALL=123456</span><br><span class="line"><span class="meta">#</span><span class="bash">（手动写了<span class="literal">false</span>）</span></span><br><span class="line">SECURITY_UPDATES_VIA_MYORACLESUPPORT=false</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置安全更新（貌似是有bug，这个一定要选<span class="literal">true</span>，否则会无限提醒邮件地址有问题，终止安装。）</span></span><br><span class="line">DECLINE_SECURITY_UPDATES=true</span><br></pre></td></tr></table></figure><h2 id="开始安装："><a href="#开始安装：" class="headerlink" title="开始安装："></a>开始安装：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 重启系统，保证所有配置完成</span></span><br><span class="line">sudo reboot</span><br><span class="line"><span class="meta">#</span><span class="bash"> 接着登录到oracle用户，进入解压后的data目录</span></span><br><span class="line">cd /oracledata/data/oraInventory/database</span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行安装</span></span><br><span class="line">./runInstaller -silent -force -ignorePrereq -responseFile /home/oracle/etc/db_install.rsp</span><br><span class="line"><span class="meta">#</span><span class="bash"> 接下来需要等一会儿，时间略长，出现提示信息后安装成功，告知要新开会话用root用户执行脚本</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 新开会话切换用户root或者其他用户可以用sudo的，我的就是用sudo的，根据提示输入两个脚本：</span></span><br><span class="line">sudo /home/oracle/oraInventory/orainstRoot.sh</span><br><span class="line">sudo /oracledata/data/oracle/product/11.2.0.1/root.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 然后切回原会话按Enter即可</span></span><br></pre></td></tr></table></figure><p>接下来是增加或者修改环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br></pre></td></tr></table></figure><p>内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> oracle数据库安装目录</span></span><br><span class="line">export ORACLE_BASE=/oracledata/data/oracle</span><br><span class="line"><span class="meta">#</span><span class="bash"> oracle数据库路径</span></span><br><span class="line">export ORACLE_HOME=/oracledata/data/oracle/product/11.2.0.1</span><br><span class="line"><span class="meta">#</span><span class="bash"> oracle启动数据库实例名</span></span><br><span class="line">export ORACLE_SID=dbsrv2</span><br><span class="line">export ROACLE_PID=ora11g</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加系统环境变量</span></span><br><span class="line">export PATH=$PATH:$ORACLE_HOME/bin</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加系统环境变量</span></span><br><span class="line">export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib</span><br><span class="line"><span class="meta">#</span><span class="bash"> 防止安装过程出现乱码</span></span><br><span class="line">export LANG=C</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置Oracle客户端字符集，必须与Oracle安装时设置的字符集保持一致</span></span><br><span class="line">export NLS_LANG= "AL32UTF8"</span><br><span class="line">export NLS_DATE_FORMAT='yyyy-mm-dd hh24:mi:ss'</span><br></pre></td></tr></table></figure><p>保存退出,使其生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><h2 id="配置监听程序"><a href="#配置监听程序" class="headerlink" title="配置监听程序"></a>配置监听程序</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netca /silent /responsefile /home/oracle/etc/netca.rsp</span><br></pre></td></tr></table></figure><h2 id="启动监控程序"><a href="#启动监控程序" class="headerlink" title="启动监控程序"></a>启动监控程序</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsnrctl start</span><br></pre></td></tr></table></figure><p>发现监听已经启动好了</p><h2 id="静默dbca建库"><a href="#静默dbca建库" class="headerlink" title="静默dbca建库"></a>静默dbca建库</h2><p>编辑应答文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/oracle/etc/dbca.rsp</span><br></pre></td></tr></table></figure><p>内容如下</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">RESPONSEFILE_VERSION</span> = <span class="string">"11.2.0"</span></span><br><span class="line"><span class="attr">OPERATION_TYPE</span> = <span class="string">"createDatabase"</span></span><br><span class="line"><span class="attr">GDBNAME</span> = <span class="string">"dbsrv2"</span></span><br><span class="line"><span class="attr">SID</span> = <span class="string">"dbsrv2"</span></span><br><span class="line"><span class="attr">TEMPLATENAME</span> = <span class="string">"General_Purpose.dbc"</span></span><br></pre></td></tr></table></figure><p>建库：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> dbca -silent -responseFile /home/oracle/etc/dbca.rsp （此命令无效以下命令代替）</span></span><br><span class="line">dbca -silent -createDatabase -templateName General_Purpose.dbc -gdbName dbsrv2 -sysPassword 123456 -systemPassword 123456</span><br></pre></td></tr></table></figure><p>完成后查看输出日记：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /oracledata/data/oracle/cfgtoollogs/dbca/dbsrv2/dbsrv2.log</span><br></pre></td></tr></table></figure><p> 至此完成数据库实例的创建。</p><p>查看监听状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsnrctl status</span><br></pre></td></tr></table></figure><p>输入命令连接数据库</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlplus / as sysdba</span><br></pre></td></tr></table></figure><p>在sqlplus终端输入sql命令启动数据库</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">startup</span><br></pre></td></tr></table></figure><p>发现已经启动实例</p><p>如何退出sqlpuls</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quit 或 exit</span><br></pre></td></tr></table></figure><p>如何删除实例（清楚自己做什么的情况下再执行此命令）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dbca -silent -deleteDatabase -sourcedb dbsrv2</span><br></pre></td></tr></table></figure><h2 id="创建可以外部访问的数据库"><a href="#创建可以外部访问的数据库" class="headerlink" title="创建可以外部访问的数据库"></a>创建可以外部访问的数据库</h2><p>输入：sqlplus “/as sysdba” (此处是用dba身份登录数据库，系统的超级用户)</p><p>1、创建临时表空间：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mkdir /oracledata/data/oracle/tablespace</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">temporary</span> <span class="keyword">tablespace</span> dp_test tempfile <span class="string">'/oracledata/data/oracle/tablespace/dp_test.dbf'</span> 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">size</span> <span class="number">1024</span>m 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">autoextend</span> <span class="keyword">on</span> 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">next</span> <span class="number">100</span>m <span class="keyword">maxsize</span> <span class="number">10240</span>m 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">extent</span> <span class="keyword">management</span> <span class="keyword">local</span>; 点击Enter</span><br></pre></td></tr></table></figure><p>说明：</p><p>1) dp_test是临时表空间的名字</p><p>2) /oracledata/data/oracle/tablespace/dp_test.dbf是在/oracledata/data/oracle/tablespace下建一个名为dp_test.dbf的表(注意：单引号为英文状态下的输入)，</p><p>3) 1024m是表空间初始大小，</p><p>4) 100m是表空间自动增长大小，</p><p>5) 10240m是表空间最大的大小。</p><p>2、创建数据表空间</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">tablespace</span> dp <span class="keyword">logging</span> <span class="keyword">datafile</span> <span class="string">'/oracledata/data/oracle/tablespace/dp.dbf'</span> 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">size</span> <span class="number">1024</span>m 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">autoextend</span> <span class="keyword">on</span> 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">next</span> <span class="number">100</span>m <span class="keyword">maxsize</span> <span class="number">10240</span>m 点击Enter</span><br><span class="line"></span><br><span class="line"><span class="keyword">extent</span> <span class="keyword">management</span> <span class="keyword">local</span>; 点击Enter</span><br></pre></td></tr></table></figure><p>3、创建用户并指定表空间</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create<span class="built_in"> user </span>dp identified by dp123<span class="built_in"> default </span>tablespace dp temporary tablespace dp_test;</span><br></pre></td></tr></table></figure><p>其中dp为用户名，dp123为用户密码，dp_test是临时表空间的名字。</p><p>4、给用户授予权限</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">grant</span> dba <span class="keyword">to</span> dp;</span><br></pre></td></tr></table></figure><p>至此，oracle在centos7下的安装和配置也就完成了，别人已经可以访问你的数据库了</p><h2 id="修改oracle字符集将字符编码WE8MSWIN1252修改为AL32UTF8"><a href="#修改oracle字符集将字符编码WE8MSWIN1252修改为AL32UTF8" class="headerlink" title="修改oracle字符集将字符编码WE8MSWIN1252修改为AL32UTF8"></a>修改oracle字符集将字符编码WE8MSWIN1252修改为AL32UTF8</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">采用的是操作系统默认字符集：WE8MSWIN1252，将字符集修改为：AL32UTF8。</span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> select userenv(<span class="string">'language'</span>) from dual;</span></span><br><span class="line"></span><br><span class="line">SIMPLIFIED CHINESE_CHINA.WE8MSWIN1252</span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> select * from nls_database_parameters <span class="built_in">where</span> parameter <span class="keyword">in</span> (<span class="string">'NLS_CHARCTERSET'</span>,<span class="string">'NLS_NCHAR_CHARACTERSET'</span>);</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> select* from v<span class="variable">$nls_parameters</span> <span class="built_in">where</span> parameter=<span class="string">'NLS_CHARACTERSET'</span>;</span></span><br><span class="line"></span><br><span class="line">操作过程如下：</span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> shutdown immediate</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> startup</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter session <span class="built_in">set</span> sql_trace=<span class="literal">true</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter system <span class="built_in">enable</span> restricted session;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> show parameter job_queue_processes;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter system <span class="built_in">set</span> job_queue_processes=0;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter system <span class="built_in">set</span> aq_tm_processes=0;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter database open;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> alter database character <span class="built_in">set</span> INTERNAL_USE AL32UTF8;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash"> update props$ <span class="built_in">set</span> VALUE$=<span class="string">'UTF8'</span> <span class="built_in">where</span> NAME=<span class="string">'NLS_NCHAR_CHARACTERSET'</span>;</span></span><br><span class="line"></span><br><span class="line">维护完以后需要</span><br><span class="line"></span><br><span class="line"><span class="meta">SQL&gt;</span><span class="bash">ALTER SYSTEM DISABLE RESTRICTED SESSION;</span></span><br><span class="line"></span><br><span class="line">改变字符集后，原来已有的数据不会改变，只是之后新增的数据会是新的字符集。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      本文主要讲述了CentOS 7 命令行模式下静默安装部署oracle11g数据库的全套流程。
    
    </summary>
    
      <category term="数据库" scheme="https://gjtmaster.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Oracle" scheme="https://gjtmaster.github.io/tags/Oracle/"/>
    
  </entry>
  
  <entry>
    <title>深入理解JVM</title>
    <link href="https://gjtmaster.github.io/2017/11/03/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM/"/>
    <id>https://gjtmaster.github.io/2017/11/03/深入理解JVM/</id>
    <published>2017-11-03T05:20:02.000Z</published>
    <updated>2019-08-03T05:51:17.132Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Java运行时数据区："><a href="#Java运行时数据区：" class="headerlink" title="Java运行时数据区："></a>Java运行时数据区：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Java虚拟机在执行Java程序的过程中会将其管理的内存划分为若干个不同的数据区域，这些区域有各自的用途、创建和销毁的时间，有些区域随虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束来建立和销毁。Java虚拟机所管理的内存包括以下几个运行时数据区域，如图：</span><br></pre></td></tr></table></figure><img src="/2017/11/03/深入理解JVM/1.png"><p>1、程序计数器：指向当前线程正在执行的字节码指令。线程私有的。<br>2、虚拟机栈：虚拟机栈是Java执行方法的内存模型。每个方法被执行的时候，都会创建一个栈帧，把栈帧压人栈，当方法正常返回或者抛出未捕获的异常时，栈帧就会出栈。<br>（1）栈帧：栈帧存储方法的相关信息，包含局部变量数表、返回值、操作数栈、动态链接<br>a、局部变量表：包含了方法执行过程中的所有变量。局部变量数组所需要的空间在编译期间完成分配，在方法运行期间不会改变局部变量数组的大小。<br>b、返回值：如果有返回值的话，压入调用者栈帧中的操作数栈中，并且把PC的值指向 方法调用指令 后面的一条指令地址。<br>c、操作数栈：操作变量的内存模型。操作数栈的最大深度在编译的时候已经确定（写入方法区code属性的max_stacks项中）。操作数栈的的元素可以是任意Java类型，包括long和double，32位数据占用栈空间为1，64位数据占用2。方法刚开始执行的时候，栈是空的，当方法执行过程中，各种字节码指令往栈中存取数据。<br>d、动态链接：每个栈帧都持有在运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接。<br>（2）线程私有<br>3、本地方法栈：<br>（1）调用本地native的内存模型<br>（2）线程独享。<br>4、方法区：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据<br>（1）线程共享的<br>（2）运行时常量池：</p><figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A、是方法区的一部分</span><br><span class="line">B、存放编译期生成的各种字面量和符号引用</span><br><span class="line">C、<span class="class"><span class="keyword">Class</span>文件中除了存有类的版本、字段、方法、接口等描述信息，还有一项是常量池，存有这个类的 编译期生成的各种字面量和符号引用，这部分内容将在类加载后，存放到方法区的运行时常量池中。</span></span><br></pre></td></tr></table></figure><p>5、堆（Heap）：Java对象存储的地方<br>（1）Java堆是虚拟机管理的内存中最大的一块<br>（2）Java堆是所有线程共享的区域<br>（3）在虚拟机启动时创建<br>（4）此内存区域的唯一目的就是存放对象实例，几乎所有对象实例都在这里分配内存。存放new生成的对象和数组<br>（5）Java堆是垃圾收集器管理的内存区域，因此很多时候称为“GC堆”</p><h2 id="JMM-Java内存模型："><a href="#JMM-Java内存模型：" class="headerlink" title="JMM Java内存模型："></a>JMM Java内存模型：</h2><p>1、 Java的并发采用“共享内存”模型，线程之间通过读写内存的公共状态进行通讯。多个线程之间是不能通过直接传递数据交互的，它们之间交互只能通过共享变量实现。<br>2、 主要目的是定义程序中各个变量的访问规则。<br>3、 Java内存模型规定所有变量都存储在主内存中，每个线程还有自己的工作内存。<br>（1） 线程的工作内存中保存了被该线程使用到的变量的拷贝（从主内存中拷贝过来），线程对变量的所有操作都必须在工作内存中执行，而不能直接访问主内存中的变量。<br>（2） 不同线程之间无法直接访问对方工作内存的变量，线程间变量值的传递都要通过主内存来完成。<br>（3） 主内存主要对应Java堆中实例数据部分。工作内存对应于虚拟机栈中部分区域。</p><img src="/2017/11/03/深入理解JVM/2.png"><p>4、Java线程之间的通信由内存模型JMM（Java Memory Model）控制。<br>（1）JMM决定一个线程对变量的写入何时对另一个线程可见。<br>（2）线程之间共享变量存储在主内存中<br>（3）每个线程有一个私有的本地内存，里面存储了读/写共享变量的副本。<br>（4）JMM通过控制每个线程的本地内存之间的交互，来为程序员提供内存可见性保证。<br>5、可见性、有序性：<br>（1）当一个共享变量在多个本地内存中有副本时，如果一个本地内存修改了该变量的副本，其他变量应该能够看到修改后的值，此为可见性。<br>（2）保证线程的有序执行，这个为有序性。（保证线程安全）<br>6、内存间交互操作：<br>（1）lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。<br>（2）unlock（解锁）：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。<br>（3）read（读取）：作用于主内存变量，把主内存的一个变量读取到工作内存中。<br>（4）load（载入）：作用于工作内存，把read操作读取到工作内存的变量载入到工作内存的变量副本中<br>（5）use（使用）：作用于工作内存的变量，把工作内存中的变量值传递给一个执行引擎。<br>（6）assign（赋值）：作用于工作内存的变量。把执行引擎接收到的值赋值给工作内存的变量。<br>（7）store（存储）：把工作内存的变量的值传递给主内存<br>（8）write（写入）：把store操作的值入到主内存的变量中<br>6.1、注意：<br>（1）不允许read、load、store、write操作之一单独出现<br>（2）不允许一个线程丢弃assgin操作<br>（3）不允许一个线程不经过assgin操作，就把工作内存中的值同步到主内存中<br>（4）一个新的变量只能在主内存中生成<br>（5）一个变量同一时刻只允许一条线程对其进行lock操作。但lock操作可以被同一条线程执行多次，只有执行相同次数的unlock操作，变量才会解锁<br>（6）如果对一个变量进行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或者assgin操作初始化变量的值。<br>（7）如果一个变量没有被锁定，不允许对其执行unlock操作，也不允许unlock一个被其他线程锁定的变量<br>（8）对一个变量执行unlock操作之前，需要将该变量同步回主内存中</p><h2 id="堆的内存划分："><a href="#堆的内存划分：" class="headerlink" title="堆的内存划分："></a>堆的内存划分：</h2><img src="/2017/11/03/深入理解JVM/3.png"><p>Java堆的内存划分如图所示，分别为年轻代、Old Memory（老年代）、Perm（永久代）。其中在Jdk1.8中，永久代被移除，使用MetaSpace代替。<br>1、新生代：<br>（1）使用复制清除算法（Copinng算法），原因是年轻代每次GC都要回收大部分对象。新生代里面分成一份较大的Eden空间和两份较小的Survivor空间。每次只使用Eden和其中一块Survivor空间，然后垃圾回收的时候，把存活对象放到未使用的Survivor（划分出from、to）空间中，清空Eden和刚才使用过的Survivor空间。<br>（2）分为Eden、Survivor From、Survivor To，比例默认为8：1：1<br>（3）内存不足时发生Minor GC<br>2、老年代：<br>（1）采用标记-整理算法（mark-compact），原因是老年代每次GC只会回收少部分对象。<br>3、Perm：用来存储类的元数据，也就是方法区。<br>（1）Perm的废除：在jdk1.8中，Perm被替换成MetaSpace，MetaSpace存放在本地内存中。原因是永久代进场内存不够用，或者发生内存泄漏。<br>（2）MetaSpace（元空间）：元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。<br>4、堆内存的划分在JVM里面的示意图：</p><img src="/2017/11/03/深入理解JVM/4.png"><h2 id="GC垃圾回收："><a href="#GC垃圾回收：" class="headerlink" title="GC垃圾回收："></a>GC垃圾回收：</h2><p>一、 判断对象是否要回收的方法：可达性分析法<br>1、 可达性分析法：通过一系列“GC Roots”对象作为起点进行搜索，如果在“GC Roots”和一个对象之间没有可达路径，则称该对象是不可达的。不可达对象不一定会成为可回收对象。进入DEAD状态的线程还可以恢复，GC不会回收它的内存。（把一些对象当做root对象，JVM认为root对象是不可回收的，并且root对象引用的对象也是不可回收的）<br>2、 以下对象会被认为是root对象：<br>（1） 虚拟机栈（栈帧中本地变量表）中引用的对象<br>（2） 方法区中静态属性引用的对象<br>（3） 方法区中常量引用的对象<br>（4） 本地方法栈中Native方法引用的对象<br>3、 对象被判定可被回收，需要经历两个阶段：<br>（1） 第一个阶段是可达性分析，分析该对象是否可达<br>（2） 第二个阶段是当对象没有重写finalize()方法或者finalize()方法已经被调用过，虚拟机认为该对象不可以被救活，因此回收该对象。（finalize()方法在垃圾回收中的作用是，给该对象一次救活的机会）<br>4、 方法区中的垃圾回收：<br>（1） 常量池中一些常量、符号引用没有被引用，则会被清理出常量池<br>（2） 无用的类：被判定为无用的类，会被清理出方法区。判定方法如下：<br>A、 该类的所有实例被回收<br>B、 加载该类的ClassLoader被回收<br>C、 该类的Class对象没有被引用<br>5、 finalize():<br>（1） GC垃圾回收要回收一个对象的时候，调用该对象的finalize()方法。然后在下一次垃圾回收的时候，才去回收这个对象的内存。<br>（2） 可以在该方法里面，指定一些对象在释放前必须执行的操作。</p><p>二、 发现虚拟机频繁full GC时应该怎么办：<br>（full GC指的是清理整个堆空间，包括年轻代和永久代）<br>（1） 首先用命令查看触发GC的原因是什么 jstat –gccause 进程id<br>（2） 如果是System.gc()，则看下代码哪里调用了这个方法<br>（3） 如果是heap inspection(内存检查)，可能是哪里执行jmap –histo[:live]命令<br>（4） 如果是GC locker，可能是程序依赖的JNI库的原因</p><p>三、常见的垃圾回收算法：<br>1、Mark-Sweep（标记-清除算法）：<br>（1）思想：标记清除算法分为两个阶段，标记阶段和清除阶段。标记阶段任务是标记出所有需要回收的对象，清除阶段就是清除被标记对象的空间。<br>（2）优缺点：实现简单，容易产生内存碎片<br>2、Copying（复制清除算法）：<br>（1）思想：将可用内存划分为大小相等的两块，每次只使用其中的一块。当进行垃圾回收的时候了，把其中存活对象全部复制到另外一块中，然后把已使用的内存空间一次清空掉。<br>（2）优缺点：不容易产生内存碎片；可用内存空间少；存活对象多的话，效率低下。<br>3、Mark-Compact（标记-整理算法）：<br>（1）思想：先标记存活对象，然后把存活对象向一边移动，然后清理掉端边界以外的内存。<br>（2）优缺点：不容易产生内存碎片；内存利用率高；存活对象多并且分散的时候，移动次数多，效率低下</p><p>4、分代收集算法：（目前大部分JVM的垃圾收集器所采用的算法）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">思想：把堆分成新生代和老年代。（永久代指的是方法区）</span><br></pre></td></tr></table></figure><p>（1） 因为新生代每次垃圾回收都要回收大部分对象，所以新生代采用Copying算法。新生代里面分成一份较大的Eden空间和两份较小的Survivor空间。每次只使用Eden和其中一块Survivor空间，然后垃圾回收的时候，把存活对象放到未使用的Survivor（划分出from、to）空间中，清空Eden和刚才使用过的Survivor空间。<br>（2） 由于老年代每次只回收少量的对象，因此采用mark-compact算法。<br>（3） 在堆区外有一个永久代。对永久代的回收主要是无效的类和常量<br>5、GC使用时对程序的影响？<br>垃圾回收会影响程序的性能，Java虚拟机必须要追踪运行程序中的有用对象，然后释放没用对象，这个过程消耗处理器时间<br>6、几种不同的垃圾回收类型：<br>（1）Minor GC：从年轻代（包括Eden、Survivor区）回收内存。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A、当<span class="keyword">JVM无法为一个新的对象分配内存的时候，越容易触发Minor </span>GC。所以分配率越高，内存越来越少，越频繁执行Minor GC</span><br><span class="line"><span class="keyword">B、执行Minor </span>GC操作的时候，不会影响到永久代（Tenured）。从永久代到年轻代的引用，被当成GC Roots，从年轻代到老年代的引用在标记阶段直接被忽略掉。</span><br></pre></td></tr></table></figure><p>（2）Major GC：清理整个老年代，当eden区内存不足时触发。<br>（3）Full GC：清理整个堆空间，包括年轻代和老年代。当老年代内存不足时触发</p><h2 id="HotSpot-虚拟机详解："><a href="#HotSpot-虚拟机详解：" class="headerlink" title="HotSpot 虚拟机详解："></a>HotSpot 虚拟机详解：</h2><p>1、 Java对象创建过程：<br>（1）虚拟机遇到一条new指令时，首先检查这个指令的参数能否在常量池中定位到一个类的符号引用，并检查这个符号引用代表的类是否已经加载、连接和初始化。如果没有，就执行该类的加载过程。<br>（2）为该对象分配内存。<br>A、假设Java堆是规整的，所有用过的内存放在一边，空闲的内存放在另外一边，中间放着一个指针作为分界点的指示器。那分配内存只是把指针向空闲空间那边挪动与对象大小相等的距离，这种分配称为“指针碰撞”<br>B、假设Java堆不是规整的，用过的内存和空闲的内存相互交错，那就没办法进行“指针碰撞”。虚拟机通过维护一个列表，记录哪些内存块是可用的，在分配的时候找出一块足够大的空间分配给对象实例，并更新表上的记录。这种分配方式称为“空闲列表“。<br>C、使用哪种分配方式由Java堆是否规整决定。Java堆是否规整由所采用的垃圾收集器是否带有压缩整理功能决定。<br>D、分配对象保证线程安全的做法：虚拟机使用CAS失败重试的方式保证更新操作的原子性。（实际上还有另外一种方案：每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲，TLAB。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才进行同步锁定。虚拟机是否使用TLAB，由-XX:+/-UseTLAB参数决定）<br>（3）虚拟机为分配的内存空间初始化为零值（默认值）<br>（4）虚拟机对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到对象的元数据信息、对象的Hash码、对象的GC分代年龄等信息。这些信息存放在对象的对象头中。<br>（5） 执行<init>方法，把对象按照程序员的意愿进行初始化。<br>2、 对象的定位访问的方式（通过引用如何去定位到堆上的具体对象的位置）：<br>（1）句柄：使用句柄的方式，Java堆中将会划分出一块内存作为作为句柄池，引用中存储的就是对象的句柄的地址。而句柄中包含了对象实例数据和对象类型数据的地址。</init></p><img src="/2017/11/03/深入理解JVM/5.png"><p>（2）直接指针：使用直接指针的方式，引用中存储的就是对象的地址。Java堆对象的布局必须必须考虑如何去访问对象类型数据。</p><img src="/2017/11/03/深入理解JVM/6.png"><p>（3）两种方式各有优点：<br>A、使用句柄访问的好处是引用中存放的是稳定的句柄地址，当对象被移动（比如说垃圾回收时移动对象），只会改变句柄中实例数据指针，而引用本身不会被修改。<br>B、使用直接指针，节省了一次指针定位的时间开销。<br>3、HotSpot的GC算法实现：<br>（1）HotSpot怎么快速找到GC Root？<br>HotSpot使用一组称为OopMap的数据结构。在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在栈和寄存器中哪些位置是引用。这样子，在GC扫描的时候，就可以直接知道哪些是可达对象了。<br>（2）安全点：<br>A、HotSpot只在特定的位置生成OopMap，这些位置称为安全点。<br>B、程序执行过程中并非所有地方都可以停下来开始GC，只有在到达安全点是才可以暂停。<br>C、安全点的选定基本上以“是否具有让程序长时间执行“的特征选定的。比如说方法调用、循环跳转、异常跳转等。具有这些功能的指令才会产生Safepoint。<br>（3）中断方式：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">A</span>、抢占式中断：在GC发生时，首先把所有线程中断，如果发现有线程不在安全点上，就恢复线程，让它跑到安全点上。</span><br><span class="line">B、主动式中断：GC需要中断线程时，不直接对线程操作，仅仅设置一个标志，各个线程执行时主动去轮询这个标志，当发现中断标记为真就自己中断挂起。轮询标记的地方和安全点是重合的。</span><br></pre></td></tr></table></figure><p>（5）安全区域：一段代码片段中，对象的引用关系不会发生变化，在这个区域中任何地方开始GC都是安全的。在线程进入安全区域时，它首先标志自己已经进入安全区域，在这段时间里，当JVM发起GC时，就不用管进入安全区域的线程了。在线程将要离开安全区域时，它检查系统是否完成了GC过程，如果完成了，它就继续前行。否则，它就必须等待直到收到可以离开安全区域的信号。<br>4、 GC时为什么要停顿所有Java线程？<br>因为GC先进行可达性分析。可达性分析是判断GC Root对象到其他对象是否可达，假如分析过程中对象的引用关系在不断变化，分析结果的准确性就无法得到保证。<br>5、 CMS收集器：<br>（1）一种以获取最短回收停顿时间为目标的收集器。<br>（2）一般用于互联网站或者B/S系统的服务端<br>（3）基于标记-清除算法的实现，不过更为复杂，整个过程为4个步骤：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A、初始标记：标记GC <span class="keyword">Root</span>能直接引用的对象</span><br><span class="line">B、并发标记：利用多线程对每个GC <span class="keyword">Root</span>对象进行tracing搜索，在堆中查找其下所有能关联到的对象。</span><br><span class="line"><span class="keyword">C</span>、重新标记：为了修正并发标记期间，用户程序继续运作而导致标志产生变动的那一部分对象的标记记录。</span><br><span class="line"><span class="keyword">D</span>、并发清除：利用多个线程对标记的对象进行清除</span><br></pre></td></tr></table></figure><p>（4）由于耗时最长的并发标记和并发清除操作都是用户线程一起工作，所以总体来说，CMS的内存回收工作是和用户线程一起并发执行的。<br>（5）缺点：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A、对CPU资源占用比较多。可能因为占用一部分CPU资源导致应用程序响应变慢。</span><br><span class="line">B、CMS无法处理浮动垃圾。在并发清除阶段，用户程序继续运行，可能产生新的内存垃圾，这一部分垃圾出现在标记过程之后，因此，CMS无法清除。这部分垃圾称为“浮动垃圾“</span><br><span class="line">C、需要预留一部分内存，在垃圾回收时，给用户程序使用。</span><br><span class="line">D、基于标记-清除算法，容易产生大量内存碎片，导致<span class="literal">full</span> GC（<span class="literal">full</span> GC进行内存碎片的整理）</span><br></pre></td></tr></table></figure><p>6、 对象头部分的内存布局：HotSpot的对象头分为两部分，第一部分用于存储对象自身的运行时数据，比如哈希码、GC分代年龄等。另外一部分用于指向方法区对象类型数据的指针。<br>7、 偏向锁：偏向锁偏向于第一个获取它的线程，如果在接下来的执行过程，没有其他线程获取该锁，则持有偏向锁的线程永远不需要同步。（当一个线程获取偏向锁，它每次进入这个锁相关的同步块，虚拟机不在进行任何同步操作。当有另外一个线程尝试获取这个锁时，偏向模式宣告结束）</p><h2 id="JVM优化："><a href="#JVM优化：" class="headerlink" title="JVM优化："></a>JVM优化：</h2><p>1、一般来说，当survivor区不够大或者占用量达到50%，就会把一些对象放到老年区。通过设置合理的eden区，survivor区及使用率，可以将年轻对象保存在年轻代，从而避免full GC，使用<code>-Xmn</code>设置年轻代的大小</p><p>2、对于占用内存比较多的大对象，一般会选择在老年代分配内存。如果在年轻代给大对象分配内存，年轻代内存不够了，就要在eden区移动大量对象到老年代，然后这些移动的对象可能很快消亡，因此导致full GC。通过设置参数：<code>-XX:PetenureSizeThreshold=1000000</code>，单位为B，标明对象大小超过1M时，在老年代(tenured)分配内存空间。</p><p>3、一般情况下，年轻对象放在eden区，当第一次GC后，如果对象还存活，放到survivor区，此后，每GC一次，年龄增加1，当对象的年龄达到阈值，就被放到tenured老年区。这个阈值可以同构<code>-XX:MaxTenuringThreshold</code>设置。如果想让对象留在年轻代，可以设置比较大的阈值。</p><p>4、设置最小堆和最大堆：<code>-Xmx</code>和<code>-Xms</code>稳定的堆大小堆垃圾回收是有利的，获得一个稳定的堆大小的方法是设置-Xms和-Xmx的值一样，即最大堆和最小堆一样，如果这样子设置，系统在运行时堆大小理论上是恒定的，稳定的堆空间可以减少GC次数，因此，很多服务端都会将这两个参数设置为一样的数值。稳定的堆大小虽然减少GC次数，但是增加每次GC的时间，因为每次GC要把堆的大小维持在一个区间内。</p><p>5、一个不稳定的堆并非毫无用处。在系统不需要使用大内存的时候，压缩堆空间，使得GC每次应对一个较小的堆空间，加快单次GC次数。基于这种考虑，JVM提供两个参数，用于压缩和扩展堆空间。<br>（1）<code>-XX:MinHeapFreeRatio</code> 参数用于设置堆空间的最小空闲比率。默认值是40，当堆空间的空闲内存比率小于40，JVM便会扩展堆空间<br>（2）<code>-XX:MaxHeapFreeRatio</code> 参数用于设置堆空间的最大空闲比率。默认值是70， 当堆空间的空闲内存比率大于70，JVM便会压缩堆空间。<br>（3）当-Xmx和-Xmx相等时，上面两个参数无效</p><p>6、通过增大吞吐量提高系统性能，可以通过设置并行垃圾回收收集器。<br>（1）<code>-XX:+UseParallelGC</code>:年轻代使用并行垃圾回收收集器。这是一个关注吞吐量的收集器，可以尽可能的减少垃圾回收时间。<br>（2）<code>-XX:+UseParallelOldGC</code>:设置老年代使用并行垃圾回收收集器。</p><p>7、尝试使用大的内存分页：使用大的内存分页增加CPU的内存寻址能力，从而系统的性能。<code>-XX:+LargePageSizeInBytes</code>设置内存页的大小</p><p>8、使用非占用的垃圾收集器。<code>-XX:+UseConcMarkSweepGC</code>老年代使用CMS收集器降低停顿。</p><p>9、<code>-XXSurvivorRatio=3</code>，表示年轻代中的分配比率：survivor:eden = 2:3</p><p>10、JVM性能调优的工具：<br>（1）jps（Java Process Status）：输出JVM中运行的进程状态信息(现在一般使用jconsole)<br>（2）jstack：查看java进程内线程的堆栈信息。<br>（3）jmap：用于生成堆转存快照<br>（4）jhat：用于分析jmap生成的堆转存快照（一般不推荐使用，而是使用Ecplise Memory Analyzer）<br>（3）jstat是JVM统计监测工具。可以用来显示垃圾回收信息、类加载信息、新生代统计信息等。<br>（4）VisualVM：故障处理工具</p><h2 id="类加载机制："><a href="#类加载机制：" class="headerlink" title="类加载机制："></a>类加载机制：</h2><p>一、 概念：类加载器把class文件中的二进制数据读入到内存中，存放在方法区，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类加载的步骤如下：<br>1、加载：查找并加载类的二进制数据（把class文件里面的信息加载到内存里面）<br>2、连接：把内存中类的二进制数据合并到虚拟机的运行时环境中<br>（1）验证：确保被加载的类的正确性。包括：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A、类文件的结构检查：检查是否满足<span class="keyword">Java类文件的固定格式</span></span><br><span class="line"><span class="keyword">B、语义检查：确保类本身符合Java的语法规范</span></span><br><span class="line"><span class="keyword">C、字节码验证：确保字节码流可以被Java虚拟机安全的执行。字节码流是操作码组成的序列。每一个操作码后面都会跟着一个或者多个操作数。字节码检查这个步骤会检查每一个操作码是否合法。</span></span><br><span class="line"><span class="keyword">D、二进制兼容性验证：确保相互引用的类之间是协调一致的。</span></span><br></pre></td></tr></table></figure><p>（2）准备：为类的静态变量分配内存，并将其初始化为默认值<br>（3）解析：把类中的符号引用转化为直接引用（比如说方法的符号引用，是有方法名和相关描述符组成，在解析阶段，JVM把符号引用替换成一个指针，这个指针就是直接引用，它指向该类的该方法在方法区中的内存位置）<br>3、初始化：为类的静态变量赋予正确的初始值。当静态变量的等号右边的值是一个常量表达式时，不会调用static代码块进行初始化。只有等号右边的值是一个运行时运算出来的值，才会调用static初始化。</p><p>二、双亲委派模型：<br>1、当一个类加载器收到类加载请求的时候，它首先不会自己去加载这个类的信息，而是把该<br>请求转发给父类加载器，依次向上。所以所有的类加载请求都会被传递到父类加载器中，只有当父类加载器中无法加载到所需的类，子类加载器才会自己尝试去加载该类。当当前类加载器和所有父类加载器都无法加载该类时，抛出ClassNotFindException异常。<br>2、意义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">提高系统的安全性。用户自定义的类加载器不可能加载应该由父加载器加载的可靠类。（比如用户定义了一个恶意代码，自定义的类加载器首先让系统加载器去加载，系统加载器检查该代码不符合规范，于是就不继续加载了）</span><br></pre></td></tr></table></figure><p>3、定义类加载器：如果某个类加载器能够加载一个类，那么这个类加载器就叫做定义类加载器<br>4、初始类加载器：定义类加载器及其所有子加载器都称作初始类加载器。<br>5、运行时包：<br>（1）由同一个类加载器加载并且拥有相同包名的类组成运行时包<br>（2）只有属于同一个运行时包的类，才能访问包可见（default）的类和类成员。作用是 限制用户自定义的类冒充核心类库的类去访问核心类库的包可见成员。<br>6、加载两份相同的class对象的情况：A和B不属于父子类加载器关系，并且各自都加载了同一个类。</p><p>三、特点：<br>1、全盘负责：当一个类加载器加载一个类时，该类所依赖的其他类也会被这个类加载器加载到内存中。<br>2、缓存机制：所有的Class对象都会被缓存，当程序需要使用某个Class时，类加载器先从缓存中查找，找不到，才从class文件中读取数据，转化成Class对象，存入缓存中。</p><p>三、 类加载器：<br>两种类型的类加载器：<br>1、 JVM自带的类加载器（3种）：<br>（1）根类加载器（Bootstrap）：<br>a、C++编写的，程序员无法在程序中获取该类<br>b、负责加载虚拟机的核心库，比如java.lang.Object<br>c、没有继承ClassLoader类<br>（2）扩展类加载器（Extension）：<br>a、Java编写的，从指定目录中加载类库<br>b、父加载器是根类加载器<br>c、是ClassLoader的子类<br>d、如果用户把创建的jar文件放到指定目录中，也会被扩展加载器加载。<br>（3）系统加载器（System）或者应用加载器(App)：<br>a、Java编写的<br>b、父加载器是扩展类加载器<br>c、从环境变量或者class.path中加载类<br>d、是用户自定义类加载的默认父加载器<br>e、是ClassLoader的子类</p><p>2、用户自定义的类加载器：<br>（1）Java.lang.ClassLoader类的子类<br>（2）用户可以定制类的加载方式<br>（3）父类加载器是系统加载器<br>（4）编写步骤：<br>A、继承ClassLoader<br>B、重写findClass方法。从特定位置加载class文件，得到字节数组，然后利用defineClass把字节数组转化为Class对象<br>（5）为什么要自定义类加载器？<br>A、可以从指定位置加载class文件，比如说从数据库、云端加载class文件<br>B、加密：Java代码可以被轻易的反编译，因此，如果需要对代码进行加密，那么加密以后的代码，就不能使用Java自带的ClassLoader来加载这个类了，需要自定义ClassLoader，对这个类进行解密，然后加载。</p><p>问题：Java程序对类的执行有几种方式：<br>1、 主动使用（6种情况）：<br>JVM必须在每个类“首次 主动使用”的时候，才会初始化这些类。<br>（1） 创建类的实例<br>（2） 读写某个类或者接口的静态变量<br>（3） 调用类的静态方法<br>（4） 同过反射的API（Class.forName()）获取类<br>（5） 初始化一个类的子类<br>（6） JVM启动的时候，被标明启动类的类（包含Main方法的类）<br>只有当程序使用的静态变量或者静态方法确实在该类中定义时，该可以认为是对该类或者接口的主动使用。<br>2、 被动使用：除了主动使用的6种情况，其他情况都是被动使用，都不会导致类的初始化。<br>3、 JVM规范允许类加载器在预料某个类将要被使用的时候，就预先加载它。如果该class文件缺失或者存在错误，则在程序“首次 主动使用”的时候，才报告这个错误。（Linkage Error错误）。如果这个类一直没有被程序“主动使用”，就不会报错。</p><p>类加载机制与接口：<br>1、 当Java虚拟机初始化一个类时，不会初始化该类实现的接口。<br>2、 在初始化一个接口时，不会初始化这个接口父接口。<br>3、 只有当程序首次使用该接口的静态变量时，才导致该接口的初始化。</p><p>ClassLoader：<br>1、 调用Classloader的loadClass方法去加载一个类，不是主动使用，因此不会进行类的初始化。</p><p>类的卸载：<br>1、 有JVM自带的三种类加载器（根、扩展、系统）加载的类始终不会卸载。因为JVM始终引用这些类加载器，这些类加载器使用引用他们所加载的类，因此这些Class类对象始终是可到达的。<br>2、 由用户自定义类加载器加载的类，是可以被卸载的。</p><p>补充：</p><ul><li>JDK和JRK</li></ul><p>（1）JDK ： Java Development Kit，开发的时候用到的类包。<br>（2）JRE ： Java Runtime Environment，Java运行的基础，包含运行时需要的所有类库。</p><ul><li>图解java文件转化成机器码</li></ul><img src="/2017/11/03/深入理解JVM/7.png"><p>JVM虚拟机先将java文件编译成class文件（字节码文件），然后再将class文件转换成所有操作系统都能运行的机器指令。</p>]]></content>
    
    <summary type="html">
    
      本文从Java运行时数据区、内存模型、堆内存划分、GC垃圾回收、JVM优化、类加载机制等几个方面对JVM做了一个全面的剖析。
    
    </summary>
    
      <category term="JVM" scheme="https://gjtmaster.github.io/categories/JVM/"/>
    
    
      <category term="JVM" scheme="https://gjtmaster.github.io/tags/JVM/"/>
    
      <category term="内存回收" scheme="https://gjtmaster.github.io/tags/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6/"/>
    
  </entry>
  
  <entry>
    <title>JVM垃圾回收底层原理</title>
    <link href="https://gjtmaster.github.io/2017/11/03/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/"/>
    <id>https://gjtmaster.github.io/2017/11/03/JVM垃圾回收底层原理/</id>
    <published>2017-11-03T04:39:51.000Z</published>
    <updated>2019-08-03T14:39:41.724Z</updated>
    
    <content type="html"><![CDATA[<h2 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h2><h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h3><p>最基础的收集算法是“标记-清除”(Mark-Sweep)算法，分两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。</p><p>不足：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能导致以后在程序运行过程需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一个的垃圾收集动作。</p><h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3><p>为了解决效率问题，一种称为复制(Copying)的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块内存用完了，就将还存活着的对象复制到另外一块上，然后再把已经使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。代价是内存缩小为原来的一半。</p><p>商业虚拟机用这个回收算法来回收新生代。IBM研究表明98%的对象是“朝生夕死“，不需要按照1-1的比例来划分内存空间，而是将内存分为一块较大的”Eden“空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性复制到另外一个Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。Hotspot虚拟机默认Eden和Survivor的比例是8-1.即每次可用整个新生代的90%, 只有一个survivor，即1/10被”浪费“。当然，98%的对象回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够时，需要依赖其他内存(老年代)进行分配担保(Handle Promotion).</p><p>如果另外一块survivor空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。</p><h3 id="eden-survivor复制过程概述"><a href="#eden-survivor复制过程概述" class="headerlink" title="eden survivor复制过程概述"></a>eden survivor复制过程概述</h3><p>Eden Space字面意思是伊甸园，对象被创建的时候首先放到这个区域，进行垃圾回收后，不能被回收的对象被放入到空的survivor区域。</p><p>Survivor Space幸存者区，用于保存在eden space内存区域中经过垃圾回收后没有被回收的对象。Survivor有两个，分别为To Survivor、 From Survivor，这个两个区域的空间大小是一样的。执行垃圾回收的时候Eden区域不能被回收的对象被放入到空的survivor（也就是To Survivor，同时Eden区域的内存会在垃圾回收的过程中全部释放），另一个survivor（即From Survivor）里不能被回收的对象也会被放入这个survivor（即To Survivor），然后To Survivor 和 From Survivor的标记会互换，始终保证一个survivor是空的。</p><p>为啥需要两个survivor？因为需要一个完整的空间来复制过来。当满的时候晋升。每次都往标记为to的里面放，然后互换，这时from已经被清空，可以当作to了。</p><h3 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h3><p>复制收集算法在对象成活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以，老年代一般不能直接选用这种算法。</p><p>根据老年代的特点，有人提出一种”标记-整理“Mark-Compact算法，标记过程仍然和标记-清除一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理端边界以外的内存.</p><h3 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h3><p>当前商业虚拟机的垃圾收集都采用”分代收集“(Generational Collection)算法，这种算法根据对象存活周期的不同将内存划分为几块。一般把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代，每次垃圾收集时都发现大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率较高，没有额外的空间对它进行分配担保，就必须使用”标记-清理“和”标记-整理“算法来进行回收。</p><h2 id="HotSpot算法实现"><a href="#HotSpot算法实现" class="headerlink" title="HotSpot算法实现"></a>HotSpot算法实现</h2><p>在Java语言中，可作为GC Roots的对象包括下面几种：</p><ul><li>虚拟机栈(栈帧中的本地变量表)中引用的对象</li><li>方法去中类静态属性引用的对象</li><li>方法区中常量引用的对象</li><li>本地方法栈中JNI(即一般说的Native方法)引用的对象</li></ul><p>从可达性分析中从GC Roots节点找引用链这个操作为例，可作为GC Roots的节点主要在全局性的引用(例如常量或类静态属性)与执行上下文(例如栈帧中的本地变量表)中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查里面的引用，必然消耗很多时间。</p><p>可达性分析对执行时间的敏感还体现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行–这里”一致性“的意思是指整个分析期间整个执行系统看起来就像被冻结在某个时间点，不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话分析结果准确性就无法得到保证。这点是导致GC进行时必须停顿所有Java执行线程(Sun公司将这件事情称为”Stop The World“)的一个重要原因，即使是在号称(几乎)不会发生停顿的CMS收集器中，枚举根节点时也必须停顿的。</p><p>安全点，Safepoint</p><h2 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h2><h3 id="Serial-收集器"><a href="#Serial-收集器" class="headerlink" title="Serial 收集器"></a>Serial 收集器</h3><p>标记-复制。</p><p>单线程，一个CPU或一条收集线程去完成垃圾收集工作，收集时必须暂停其他所有的工作线程，直到它结束。</p><p>虽然如此，它依然是虚拟机运行在Client模式下的默认<strong>新生代</strong>收集器。简单而高效。</p><h3 id="ParNew-收集器"><a href="#ParNew-收集器" class="headerlink" title="ParNew 收集器"></a>ParNew 收集器</h3><p>ParNew是Serial收集器的多线程版本。Server模式下默认<strong>新生代</strong>收集器，除了Serial收集器之外，只有它能与CMS收集器配合工作。</p><h3 id="并行-Parallel"><a href="#并行-Parallel" class="headerlink" title="并行 Parallel"></a>并行 Parallel</h3><p>指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。</p><h3 id="并发-Concurrent"><a href="#并发-Concurrent" class="headerlink" title="并发 Concurrent"></a>并发 Concurrent</h3><p>指用户线程与垃圾收集线程同时执行(但不一定是并行的，可能会交替执行)，用户程序再继续运行，而垃圾收集程序运行于另一个CPU上。</p><h3 id="Parallel-Scavenge-收集器"><a href="#Parallel-Scavenge-收集器" class="headerlink" title="Parallel Scavenge 收集器"></a>Parallel Scavenge 收集器</h3><p>Parallel Scavenge 收集器是一个<strong>新生代</strong>收集器，它也是使用复制算法的收集器。看上去来ParNew一样，有什么特别？</p><p>Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS等收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间。而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量(Throughput)。所谓吞吐量就是CPU用于运行用户代码的时间和CPU总小号时间的比值，即吞吐量 = 运行用户代码时间 / (运行用户代码时间+垃圾收集时间)，虚拟机总共运行了100min，其中垃圾收集花费了1min，那吞吐量就是99%.</p><p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效地利用CPU时间，主要适合在后台运算而不需要太多交互的任务。</p><p>Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间 <code>-XX:MaxGCPauseMillis</code>以及直接设置吞吐量大小的<code>-XX:GCTimeRatio</code>。</p><h3 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h3><p>Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器。给Client模式下的虚拟机使用。</p><p>新生代采用复制算法，暂停所有用户线程；</p><p>老年代采用标记-整理算法，暂停所有用户线程；</p><h3 id="Parallel-Old-收集器"><a href="#Parallel-Old-收集器" class="headerlink" title="Parallel Old 收集器"></a>Parallel Old 收集器</h3><p>这里注意，Parallel Scavage 收集器架构中本身有PS MarkSweep收集器来收集老年代，并非直接使用了Serial Old,但二者接近。本人win10 64位系统，jdk1.8.0_102，测试默认垃圾收集器为：<strong>PS MarkSweep *<em>和 *</em>PS Scavenge</strong>。 也就是说Java8的默认并不是G1。</p><p>这是”吞吐量优先“，注重吞吐量以及CPU资源敏感的场合都可以优先考虑Parallel Scavenge和Parallel Old(PS Mark Sweep)。Java8 默认就是这个。</p><h3 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h3><p>CMS(Concurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类尤其重视服务的响应速度，希望系统停顿时间最短。CMS收集器就非常符合这类应用的需求。</p><p>CMS基于 <code>标记-清除</code>算法实现。整个过程分为4个步骤：</p><ol><li>初始标记(CMS initial mark) -stop the world</li><li>并发标记(CMS concurrent mark)</li><li>重新标记(CMS remark) -stop the world</li><li>并发清除(CMS concurrent sweep)</li></ol><p>初始标记，重新标记这两个步骤仍然需要Stop The World, 初始标记仅仅标记以下GC Roots能直接关联的对象，速度很快。</p><p>并发标记就是进行GC Roots Tracing的过程；</p><p>而重新标记阶段则是为了修正并发标记期间因为用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。这个阶段停顿比初始标记稍微长，但远比并发标记的时间短。</p><p>整个过程耗时最长的并发标记和并发清除过程，收集器都可以与用户线程一起工作。总体上来说，CMS收集器的内存回收过程与用户线程一起并发执行的。</p><p>CMS特点：并发收集，低停顿。</p><p><strong>缺点</strong></p><p>1.CMS收集器对CPU资源非常敏感。默认启动的回收线程数是(CPU+3)/4. 当CPU 4个以上时，并发回收垃圾收集线程不少于25%的CPU资源。</p><p>2.CMS收集器无法处理浮动垃圾(Floating Garbage), 可能出现”Concurrent Mode Failure“失败而导致另一次Full GC的产生。由于CMS并发清理时，用户线程还在运行，伴随产生新垃圾，而这一部分出现在标记之后，只能下次GC时再清理。这一部分垃圾就称为”浮动垃圾“。</p><p>由于CMS运行时还需要给用户空间继续运行，则不能等老年代几乎被填满再进行收集，需要预留一部分空间提供并发收集时，用户程序运行。JDK1.6中，CMS启动阈值为92%. 若预留内存不够用户使用，则出现一次<code>Concurent Mode Failure</code>失败。这时虚拟机启动后备预案，临时启用Serial Old收集老年代，这样停顿时间很长。</p><p>3.CMS基于”标记-清除“算法实现的，则会产生大量空间碎片，空间碎片过多时，没有连续空间分配给大对象，不得不提前触发一次FUll GC。当然可以开启-XX:+UseCMSCompactAtFullCollection(默认开)，在CMS顶不住要FullGC时开启内存碎片合并整理过程。内存整理过程是无法并发的，空间碎片问题没了，但停顿时间变长。</p><p><strong>面试题：CMS一共会有几次STW</strong></p><p>首先，回答两次，初始标记和重新标记需要。</p><p>然后，CMS并发的代价是预留空间给用户，预留不足的时候触发FUllGC，这时Serail Old会STW.</p><p>然后，CMS是标记-清除算法，导致空间碎片，则没有连续空间分配大对象时，FUllGC, 而FUllGC会开始碎片整理， STW.</p><p>即2次或多次。</p><h2 id="CMS什么时候FUll-GC"><a href="#CMS什么时候FUll-GC" class="headerlink" title="CMS什么时候FUll GC"></a>CMS什么时候FUll GC</h2><p>除直接调用System.gc外，触发Full GC执行的情况有如下四种。</p><h3 id="1-旧生代空间不足"><a href="#1-旧生代空间不足" class="headerlink" title="1. 旧生代空间不足"></a>1. 旧生代空间不足</h3><p>旧生代空间只有在新生代对象转入及创建为大对象、大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出如下错误： java.lang.OutOfMemoryError: Java heap space 为避免以上两种状况引起的FullGC，调优时应尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。</p><h3 id="2-Permanet-Generation空间满"><a href="#2-Permanet-Generation空间满" class="headerlink" title="2. Permanet Generation空间满"></a>2. Permanet Generation空间满</h3><p>PermanetGeneration中存放的为一些class的信息等，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation可能会被占满，在未配置为采用CMS GC的情况下会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息： java.lang.OutOfMemoryError: PermGen space 为避免Perm Gen占满造成Full GC现象，可采用的方法为增大Perm Gen空间或转为使用CMS GC。</p><h3 id="3-CMS-GC时出现promotion-failed和concurrent-mode-failure"><a href="#3-CMS-GC时出现promotion-failed和concurrent-mode-failure" class="headerlink" title="3. CMS GC时出现promotion failed和concurrent mode failure"></a>3. CMS GC时出现promotion failed和concurrent mode failure</h3><p>对于采用CMS进行旧生代GC的程序而言，尤其要注意GC日志中是否有promotion failed和concurrent mode failure两种状况，当这两种状况出现时可能会触发Full GC。 promotionfailed是在进行Minor GC时，survivor space放不下、对象只能放入旧生代，而此时旧生代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入旧生代，而此时旧生代空间不足造成的。 应对措施为：增大survivorspace、旧生代空间或调低触发并发GC的比率，但在JDK 5.0+、6.0+的版本中有可能会由于JDK的bug29导致CMS在remark完毕后很久才触发sweeping动作。对于这种状况，可通过设置-XX:CMSMaxAbortablePrecleanTime=5（单位为ms）来避免。</p><h3 id="4-统计得到的Minor-GC晋升到旧生代的平均大小大于旧生代的剩余空间"><a href="#4-统计得到的Minor-GC晋升到旧生代的平均大小大于旧生代的剩余空间" class="headerlink" title="4. 统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间"></a>4. 统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间</h3><p>这是一个较为复杂的触发情况，Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。 例如程序第一次触发MinorGC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB，则执行Full GC。 当新生代采用PSGC时，方式稍有不同，PS GC是在Minor GC后也会检查，例如上面的例子中第一次Minor GC后，PS GC会检查此时旧生代的剩余空间是否大于6MB，如小于，则触发对旧生代的回收。 除了以上4种状况外，对于使用RMI来进行RPC或管理的Sun JDK应用而言，默认情况下会一小时执行一次Full GC。可通过在启动时通过- java-Dsun.rmi.dgc.client.gcInterval=3600000来设置Full GC执行的间隔时间或通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。</p><h2 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h2><h3 id="什么是垃圾回收"><a href="#什么是垃圾回收" class="headerlink" title="什么是垃圾回收"></a>什么是垃圾回收</h3><p>首先，在了解G1之前，我们需要清楚的知道，垃圾回收是什么？简单的说垃圾回收就是回收内存中不再使用的对象。</p><p>垃圾回收的基本步骤</p><p>回收的步骤有2步：</p><p>1.查找内存中不再使用的对象</p><p>2.释放这些对象占用的内存</p><h4 id="1-查找内存中不再使用的对象"><a href="#1-查找内存中不再使用的对象" class="headerlink" title="1,查找内存中不再使用的对象"></a>1,查找内存中不再使用的对象</h4><p>那么问题来了，如何判断哪些对象不再被使用呢？我们也有2个方法：</p><p><strong>1.引用计数法</strong> 引用计数法就是如果一个对象没有被任何引用指向，则可视之为垃圾。这种方法的缺点就是不能检测到环的存在。</p><p><strong>2.根搜索算法</strong></p><p>根搜索算法的基本思路就是通过一系列名为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。</p><p>现在我们已经知道如何找出垃圾对象了，如何把这些对象清理掉呢？</p><h4 id="2-释放这些对象占用的内存"><a href="#2-释放这些对象占用的内存" class="headerlink" title="2. 释放这些对象占用的内存"></a>2. 释放这些对象占用的内存</h4><p>常见的方式有复制或者直接清理，但是直接清理会存在内存碎片，于是就会产生了清理再压缩的方式。</p><p>总得来说就产生了三种类型的回收算法。</p><p>1.标记-复制</p><p>2.标记-清理</p><p>3.标记-整理</p><p>基于分代的假设</p><p>由于对象的存活时间有长有短，所以对于存活时间长的对象，减少被gc的次数可以避免不必要的开销。这样我们就把内存分成新生代和老年代，新生代存放刚创建的和存活时间比较短的对象，老年代存放存活时间比较长的对象。这样每次仅仅清理年轻代，老年代仅在必要时时再做清理可以极大的提高GC效率，节省GC时间。</p><h3 id="Java垃圾收集器的历史"><a href="#Java垃圾收集器的历史" class="headerlink" title="Java垃圾收集器的历史"></a>Java垃圾收集器的历史</h3><p>第一阶段，Serial（串行）收集器</p><p>在jdk1.3.1之前，java虚拟机仅仅能使用Serial收集器。 Serial收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅是说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。</p><p>PS：开启Serial收集器的方式</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseSerialGC</span></span><br></pre></td></tr></table></figure><p>第二阶段，Parallel（并行）收集器</p><p>Parallel收集器也称吞吐量收集器，相比Serial收集器，Parallel最主要的优势在于使用多线程去完成垃圾清理工作，这样可以充分利用多核的特性，大幅降低gc时间。</p><p>PS:开启Parallel收集器的方式</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseParallelGC</span> <span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseParallelOldGC</span></span><br></pre></td></tr></table></figure><p>第三阶段，CMS（并发）收集器</p><p>CMS收集器在Minor GC时会暂停所有的应用线程，并以多线程的方式进行垃圾回收。在Full GC时不再暂停应用线程，而是使用若干个后台线程定期的对老年代空间进行扫描，及时回收其中不再使用的对象。</p><p>PS:开启CMS收集器的方式</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseParNewGC</span> <span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseConcMarkSweepGC</span></span><br></pre></td></tr></table></figure><p>第四阶段，G1（并发）收集器</p><p>G1收集器（或者垃圾优先收集器）的设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。相对于CMS的优势而言是内存碎片的产生率大大降低。</p><p>PS:开启G1收集器的方式</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseG1GC</span></span><br></pre></td></tr></table></figure><h3 id="了解G1"><a href="#了解G1" class="headerlink" title="了解G1"></a>了解G1</h3><p>G1的第一篇paper（附录1）发表于2004年，在2012年才在jdk1.7u4中可用。oracle官方计划在jdk9中将G1变成默认的垃圾收集器，以替代CMS。为何oracle要极力推荐G1呢，G1有哪些优点</p><blockquote><p> <strong>首先，G1的设计原则就是简单可行的性能调优</strong> </p></blockquote><p>开发人员仅仅需要声明以下参数即可：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-<span class="string">XX:</span>+UseG1GC -Xmx32g -<span class="string">XX:</span>MaxGCPauseMillis=<span class="number">200</span></span><br></pre></td></tr></table></figure><p>其中-XX:+UseG1GC为开启G1垃圾收集器，-Xmx32g 设计堆内存的最大内存为32G，-XX:MaxGCPauseMillis=200设置GC的最大暂停时间为200ms。如果我们需要调优，在内存大小一定的情况下，我们只需要修改最大暂停时间即可。</p><blockquote><p> <strong>其次，G1将新生代，老年代的物理空间划分取消了。</strong> </p></blockquote><p>这样我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。</p><img src="/2017/11/03/JVM垃圾回收底层原理/1.png"><p>取而代之的是，G1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。不过，这些区域的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间。老年代也分成很多区域，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。</p><img src="/2017/11/03/JVM垃圾回收底层原理/2.png"><p>在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。</p><blockquote><p> PS：在java 8中，持久代也移动到了普通的堆内存空间中，改为元空间。 </p></blockquote><h3 id="对象分配策略"><a href="#对象分配策略" class="headerlink" title="对象分配策略"></a>对象分配策略</h3><p>说起大对象的分配，我们不得不谈谈对象的分配策略。它分为3个阶段：</p><p>1.TLAB(Thread Local Allocation Buffer)线程本地分配缓冲区 2.Eden区中分配 3.Humongous区分配</p><p>TLAB为线程本地分配缓冲区，它的目的为了使对象尽可能快的分配出来。如果对象在一个共享的空间中分配，我们需要采用一些同步机制来管理这些空间内的空闲空间指针。在Eden空间中，每一个线程都有一个固定的分区用于分配对象，即一个TLAB。分配对象时，线程之间不再需要进行任何的同步。</p><p>对TLAB空间中无法分配的对象，JVM会尝试在Eden空间中进行分配。如果Eden空间无法容纳该对象，就只能在老年代中进行分配空间。</p><p>最后，G1提供了两种GC模式，Young GC和Mixed GC，两种都是Stop The World(STW)的。下面我们将分别介绍一下这2种模式。</p><h3 id="G1-Young-GC"><a href="#G1-Young-GC" class="headerlink" title="G1 Young GC"></a>G1 Young GC</h3><p>Young GC主要是对Eden区进行GC，它在Eden空间耗尽时会被触发。在这种情况下，Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到年老代空间。Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。最终Eden空间的数据为空，GC停止工作，应用线程继续执行。</p><img src="/2017/11/03/JVM垃圾回收底层原理/3.png"><img src="/2017/11/03/JVM垃圾回收底层原理/4.png"><p>这时，我们需要考虑一个问题，如果仅仅GC 新生代对象，我们如何找到所有的根对象呢？ 老年代的所有对象都是根么？那这样扫描下来会耗费大量的时间。于是，G1引进了RSet的概念。它的全称是Remembered Set，作用是跟踪指向某个heap区内的对象引用。</p><img src="/2017/11/03/JVM垃圾回收底层原理/5.png"><p>在CMS中，也有RSet的概念，在老年代中有一块区域用来记录指向新生代的引用。这是一种point-out，在进行Young GC时，扫描根时，仅仅需要扫描这一块区域，而不需要扫描整个老年代。</p><p>但在G1中，并没有使用point-out，这是由于一个分区太小，分区数量太多，如果是用point-out的话，会造成大量的扫描浪费，有些根本不需要GC的分区引用也扫描了。于是G1中使用point-in来解决。point-in的意思是哪些分区引用了当前分区中的对象。这样，仅仅将这些对象当做根来扫描就避免了无效的扫描。由于新生代有多个，那么我们需要在新生代之间记录引用吗？这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录老年代到新生代之间的引用即可。</p><p>需要注意的是，如果引用的对象很多，赋值器需要对每个引用做处理，赋值器开销会很大，为了解决赋值器开销这个问题，在G1 中又引入了另外一个概念，卡表（Card Table）。一个Card Table将一个分区在逻辑上划分为固定大小的连续区域，每个区域称之为卡。卡通常较小，介于128到512字节之间。Card Table通常为字节数组，由Card的索引（即数组下标）来标识每个分区的空间地址。默认情况下，每个卡都未被引用。当一个地址空间被引用时，这个地址空间对应的数组索引的值被标记为”0″，即标记为脏被引用，此外RSet也将这个数组下标记录下来。一般情况下，这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。</p><p><strong>Young GC 阶段</strong>：</p><p><strong>阶段1：根扫描</strong></p><p>静态和本地对象被扫描</p><p><strong>阶段2：更新RS</strong></p><p>处理dirty card队列更新RS</p><p><strong>阶段3：处理RS</strong></p><p>检测从年轻代指向年老代的对象</p><p><strong>阶段4：对象拷贝</strong></p><p>拷贝存活的对象到survivor/old区域</p><p><strong>阶段5：处理引用队列</strong></p><p>软引用，弱引用，虚引用处理</p><h3 id="G1-Mix-GC"><a href="#G1-Mix-GC" class="headerlink" title="G1 Mix GC"></a>G1 Mix GC</h3><p>Mix GC不仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的老年代分区。</p><p>它的GC步骤分2步：</p><p>1.全局并发标记（global concurrent marking） 2.拷贝存活对象（evacuation）</p><p>在进行Mix GC之前，会先进行global concurrent marking（全局并发标记）。 global concurrent marking的执行过程是怎样的呢？</p><p>在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为五个步骤：</p><p><strong>初始标记（initial mark，STW）</strong></p><p>在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。</p><p><strong>根区域扫描（root region scan</strong></p><p>G1 GC 在初始标记的存活区扫描对老年代的引用，并标记被引用的对象。该阶段与应用程序（非 STW）同时运行，并且只有完成该阶段后，才能开始下一次 STW 年轻代垃圾回收。</p><p><strong>并发标记（Concurrent Marking）</strong></p><p>G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 STW 年轻代垃圾回收中断</p><p><strong>最终标记（Remark，STW）</strong></p><p>该阶段是 STW 回收，帮助完成标记周期。G1 GC 清空 SATB 缓冲区，跟踪未被访问的存活对象，并执行引用处理。</p><p><strong>清除垃圾（Cleanup，STW）</strong></p><p>在这个最后阶段，G1 GC 执行统计和 RSet 净化的 STW 操作。在统计期间，G1 GC 会识别完全空闲的区域和可供进行混合垃圾回收的区域。清理阶段在将空白区域重置并返回到空闲列表时为部分并发。</p><h3 id="三色标记算法"><a href="#三色标记算法" class="headerlink" title="三色标记算法"></a>三色标记算法</h3><p>提到并发标记，我们不得不了解并发标记的三色标记算法。它是描述追踪式回收器的一种有用的方法，利用它可以推演回收器的正确性。 首先，我们将对象分成三种类型的。</p><p><strong>黑色</strong>:根对象，或者该对象与它的子对象都被扫描</p><p><strong>灰色</strong>:对象本身被扫描,但还没扫描完该对象中的子对象</p><p><strong>白色</strong>:未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象</p><p>当GC开始扫描对象时，按照如下图步骤进行对象的扫描：</p><p>根对象被置为黑色，子对象被置为灰色。</p><img src="/2017/11/03/JVM垃圾回收底层原理/6.png"><p>继续由灰色遍历,将已扫描了子对象的对象置为黑色。</p><img src="/2017/11/03/JVM垃圾回收底层原理/7.png"><p>遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理。</p><img src="/2017/11/03/JVM垃圾回收底层原理/8.png"><p>这看起来很美好，但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题</p><p>我们看下面一种情况，当垃圾收集器扫描到下面情况时:</p><img src="/2017/11/03/JVM垃圾回收底层原理/9.png"><p>这时候应用程序执行了以下操作：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">A.c</span>=C</span><br><span class="line"><span class="attr">B.c</span>=null</span><br></pre></td></tr></table></figure><p>这样，对象的状态图变成如下情形：</p><img src="/2017/11/03/JVM垃圾回收底层原理/10.png"><p>这时候垃圾收集器再标记扫描的时候就会下图成这样：</p><img src="/2017/11/03/JVM垃圾回收底层原理/11.png"><p>很显然，此时C是白色，被认为是垃圾需要清理掉，显然这是不合理的。那么我们如何保证应用程序在运行的时候，GC标记的对象不丢失呢？有如下2中可行的方式：</p><p>1.在插入的时候记录对象 2.在删除的时候记录对象</p><p>刚好这对应CMS和G1的2种不同实现方式：</p><p>在CMS采用的是增量更新（Incremental update），只要在写屏障（write barrier）里发现要有一个白对象的引用被赋值到一个黑对象 的字段里，那就把这个白对象变成灰色的。即插入的时候记录下来。</p><p>在G1中，使用的是STAB（snapshot-at-the-beginning）的方式，删除的时候记录所有的对象，它有3个步骤：</p><p>1.在开始标记的时候生成一个快照图标记存活对象</p><p>2.在并发标记的时候所有被改变的对象入队（在write barrier里把所有旧的引用所指向的对象都变成非白的）</p><p>3.可能存在游离的垃圾，将在下次被收集</p><p>这样，G1到现在可以知道哪些老的分区可回收垃圾最多。 当全局并发标记完成后，在某个时刻，就开始了Mix GC。这些垃圾回收被称作“混合式”是因为他们不仅仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的分区。混合式垃圾收集如下图：</p><img src="/2017/11/03/JVM垃圾回收底层原理/12.png"><p>混合式GC也是采用的复制的清理策略，当GC完成后，会重新释放空间。 </p><img src="/2017/11/03/JVM垃圾回收底层原理/13.png"><h3 id="调优实践"><a href="#调优实践" class="headerlink" title="调优实践"></a>调优实践</h3><p><strong>MaxGCPauseMillis</strong>调优</p><p>前面介绍过使用GC的最基本的参数：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-<span class="string">XX:</span>+UseG1GC -Xmx32g -<span class="string">XX:</span>MaxGCPauseMillis=<span class="number">200</span></span><br></pre></td></tr></table></figure><p>前面2个参数都好理解，后面这个MaxGCPauseMillis参数该怎么配置呢？这个参数从字面的意思上看，就是允许的GC最大的暂停时间。G1尽量确保每次GC暂停的时间都在设置的MaxGCPauseMillis范围内。 那G1是如何做到最大暂停时间的呢？这涉及到另一个概念，CSet(collection set)。它的意思是在一次垃圾收集器中被收集的区域集合。</p><p>Young GC：选定所有新生代里的region。通过控制新生代的region个数来控制young GC的开销。</p><p>Mixed GC：选定所有新生代里的region，外加根据global concurrent marking统计得出收集收益高的若干老年代region。在用户指定的开销目标范围内尽可能选择收益高的老年代region。</p><p>在理解了这些后，我们再设置最大暂停时间就好办了。 首先，我们能容忍的最大暂停时间是有一个限度的，我们需要在这个限度范围内设置。但是应该设置的值是多少呢？我们需要在吞吐量跟MaxGCPauseMillis之间做一个平衡。如果MaxGCPauseMillis设置的过小，那么GC就会频繁，吞吐量就会下降。如果MaxGCPauseMillis设置的过大，应用程序暂停时间就会变长。G1的默认暂停时间是200毫秒，我们可以从这里入手，调整合适的时间。</p><p><strong>其他调优参数</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:<span class="attribute">G1HeapRegionSize</span>=n</span><br></pre></td></tr></table></figure><p>设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:<span class="attribute">ParallelGCThreads</span>=n</span><br></pre></td></tr></table></figure><p>设置 STW 工作线程数的值。将 n 的值设置为逻辑处理器的数量。n 的值与逻辑处理器的数量相同，最多为 8。</p><p>如果逻辑处理器不止八个，则将 n 的值设置为逻辑处理器数的 5/8 左右。这适用于大多数情况，除非是较大的 SPARC 系统，其中 n 的值可以是逻辑处理器数的 5/16 左右。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:<span class="attribute">ConcGCThreads</span>=n</span><br></pre></td></tr></table></figure><p>设置并行标记的线程数。将 n 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:<span class="attribute">InitiatingHeapOccupancyPercent</span>=45</span><br></pre></td></tr></table></figure><p>设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</p><p>避免使用以下参数：</p><p>避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。</p><h3 id="触发Full-GC"><a href="#触发Full-GC" class="headerlink" title="触发Full GC"></a>触发Full GC</h3><p>在某些情况下，G1触发了Full GC，这时G1会退化使用Serial收集器来完成垃圾的清理工作，它仅仅使用单线程来完成GC工作，GC暂停时间将达到秒级别的。整个应用处于假死状态，不能处理任何请求，我们的程序当然不希望看到这些。那么发生Full GC的情况有哪些呢？</p><h4 id="并发模式失败"><a href="#并发模式失败" class="headerlink" title="并发模式失败"></a>并发模式失败</h4><p>G1启动标记周期，但在Mix GC之前，老年代就被填满，这时候G1会放弃标记周期。这种情形下，需要增加堆大小，或者调整周期（例如增加线程数-XX:ConcGCThreads等）。</p><h4 id="晋升失败或者疏散失败"><a href="#晋升失败或者疏散失败" class="headerlink" title="晋升失败或者疏散失败"></a>晋升失败或者疏散失败</h4><p>G1在进行GC的时候没有足够的内存供存活对象或晋升对象使用，由此触发了Full GC。可以在日志中看到(to-space exhausted)或者（to-space overflow）。解决这种问题的方式是：</p><p>a. 增加 <code>-XX:G1ReservePercent</code> 选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。</p><p>b. 通过减少<code>-XX:InitiatingHeapOccupancyPercent</code> 提前启动标记周期。</p><p>c. 也可以通过增加 <code>-XX:ConcGCThreads</code> 选项的值来增加并行标记线程的数目。</p><h4 id="巨型对象分配失败"><a href="#巨型对象分配失败" class="headerlink" title="巨型对象分配失败"></a>巨型对象分配失败</h4><p>当巨型对象找不到合适的空间进行分配时，就会启动Full GC，来释放空间。这种情况下，应该避免分配大量的巨型对象，增加内存或者增大-XX:G1HeapRegionSize，使巨型对象不再是巨型对象。</p>]]></content>
    
    <summary type="html">
    
      本文主要讲述了Java的垃圾收集算法及常见的垃圾收集器。
    
    </summary>
    
      <category term="JVM" scheme="https://gjtmaster.github.io/categories/JVM/"/>
    
    
      <category term="JVM" scheme="https://gjtmaster.github.io/tags/JVM/"/>
    
      <category term="内存回收" scheme="https://gjtmaster.github.io/tags/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6/"/>
    
  </entry>
  
</feed>
